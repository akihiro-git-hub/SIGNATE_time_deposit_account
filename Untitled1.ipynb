{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso,Ridge\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers.advanced_activations import ReLU, PReLU\n",
    "from keras.optimizers import SGD, Adam\n",
    "from scipy.stats import mode\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\train.csv')\n",
    "test = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\test.csv')\n",
    "submit = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\head_submit_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv(model,train_x,train_y,test_x):\n",
    "    \n",
    "    scores = []\n",
    "    preds_test = []\n",
    "    \n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "    for i, (tr_idx,va_idx) in enumerate(kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x,tr_y,va_x,va_y)\n",
    "        va_pred = model.predict(va_x)\n",
    "        score = log_loss(va_y,va_pred)\n",
    "        scores.append(score)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_y = va_y\n",
    "    \n",
    "    \n",
    "    scores_mean = np.mean(scores)\n",
    "    preds_test = np.mean(preds_test, axis=0)\n",
    "    va_last_pred = va_pred\n",
    "    \n",
    "    return scores_mean, preds_test, va_y,va_last_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv_classfier(model,train_x, train_y, test_x):\n",
    "    \n",
    "\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state= 71)\n",
    "    for i , (tr_idx, va_idx) in enumerate (kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "\n",
    "    tmp = np.stack(preds_test, axis =1)\n",
    "    mode_test, mode_counts = mode(tmp, axis=1)\n",
    "\n",
    "    preds_test = mode_test\n",
    "    preds_size = preds_test.shape[0]\n",
    "    preds_test = preds_test.reshape(preds_size,)\n",
    "    \n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Model1xgb,Model1xgb2,Model1xgb3, Model1NNproba,Model1NN2proba,Model1ramdom,Model2KMeans,Model2KNN,Model3logistic,Model3NNproba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x = pd.concat([train,test])\n",
    "cat_cols = ['job','marital','education','default','housing','loan','contact','month','poutcome']\n",
    "#LabelEncording\n",
    "for c in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(all_x[c])\n",
    "    all_x[c] = le.transform(all_x[c])\n",
    "    \n",
    "train = all_x.iloc[:train.shape[0],:].reset_index(drop=True)\n",
    "test = all_x.iloc[train.shape[0]:,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(['y'], axis=1)\n",
    "train_y = train.y\n",
    "test_x = test.drop(['y'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:13:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06780\teval-error:0.07026\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06824\teval-error:0.06952\n",
      "[2]\ttrain-error:0.06790\teval-error:0.06922\n",
      "[3]\ttrain-error:0.06799\teval-error:0.06937\n",
      "[4]\ttrain-error:0.06770\teval-error:0.06952\n",
      "[5]\ttrain-error:0.06780\teval-error:0.06937\n",
      "[6]\ttrain-error:0.06775\teval-error:0.06864\n",
      "[7]\ttrain-error:0.06681\teval-error:0.06937\n",
      "[8]\ttrain-error:0.06657\teval-error:0.06952\n",
      "[9]\ttrain-error:0.06637\teval-error:0.06967\n",
      "[10]\ttrain-error:0.06642\teval-error:0.06937\n",
      "[11]\ttrain-error:0.06627\teval-error:0.06908\n",
      "[12]\ttrain-error:0.06617\teval-error:0.06908\n",
      "[13]\ttrain-error:0.06632\teval-error:0.06878\n",
      "[14]\ttrain-error:0.06637\teval-error:0.06878\n",
      "[15]\ttrain-error:0.06627\teval-error:0.06819\n",
      "[16]\ttrain-error:0.06632\teval-error:0.06775\n",
      "[17]\ttrain-error:0.06617\teval-error:0.06790\n",
      "[18]\ttrain-error:0.06617\teval-error:0.06804\n",
      "[19]\ttrain-error:0.06642\teval-error:0.06760\n",
      "[20]\ttrain-error:0.06662\teval-error:0.06701\n",
      "[21]\ttrain-error:0.06662\teval-error:0.06716\n",
      "[22]\ttrain-error:0.06637\teval-error:0.06672\n",
      "[23]\ttrain-error:0.06647\teval-error:0.06672\n",
      "[24]\ttrain-error:0.06657\teval-error:0.06701\n",
      "[25]\ttrain-error:0.06647\teval-error:0.06701\n",
      "[26]\ttrain-error:0.06637\teval-error:0.06686\n",
      "[27]\ttrain-error:0.06608\teval-error:0.06686\n",
      "[28]\ttrain-error:0.06603\teval-error:0.06701\n",
      "[29]\ttrain-error:0.06637\teval-error:0.06686\n",
      "[30]\ttrain-error:0.06622\teval-error:0.06627\n",
      "[31]\ttrain-error:0.06608\teval-error:0.06613\n",
      "[32]\ttrain-error:0.06598\teval-error:0.06627\n",
      "[33]\ttrain-error:0.06563\teval-error:0.06598\n",
      "[34]\ttrain-error:0.06553\teval-error:0.06598\n",
      "[35]\ttrain-error:0.06553\teval-error:0.06598\n",
      "[36]\ttrain-error:0.06549\teval-error:0.06598\n",
      "[37]\ttrain-error:0.06549\teval-error:0.06583\n",
      "[38]\ttrain-error:0.06514\teval-error:0.06568\n",
      "[39]\ttrain-error:0.06504\teval-error:0.06598\n",
      "[40]\ttrain-error:0.06460\teval-error:0.06583\n",
      "[41]\ttrain-error:0.06421\teval-error:0.06598\n",
      "[42]\ttrain-error:0.06401\teval-error:0.06627\n",
      "[43]\ttrain-error:0.06376\teval-error:0.06598\n",
      "[44]\ttrain-error:0.06357\teval-error:0.06583\n",
      "[45]\ttrain-error:0.06337\teval-error:0.06598\n",
      "[46]\ttrain-error:0.06317\teval-error:0.06627\n",
      "[47]\ttrain-error:0.06308\teval-error:0.06627\n",
      "[48]\ttrain-error:0.06303\teval-error:0.06627\n",
      "[49]\ttrain-error:0.06268\teval-error:0.06568\n",
      "[50]\ttrain-error:0.06248\teval-error:0.06598\n",
      "[51]\ttrain-error:0.06239\teval-error:0.06627\n",
      "[52]\ttrain-error:0.06199\teval-error:0.06613\n",
      "[53]\ttrain-error:0.06189\teval-error:0.06642\n",
      "[54]\ttrain-error:0.06189\teval-error:0.06627\n",
      "[55]\ttrain-error:0.06150\teval-error:0.06642\n",
      "[56]\ttrain-error:0.06155\teval-error:0.06613\n",
      "[57]\ttrain-error:0.06111\teval-error:0.06627\n",
      "[58]\ttrain-error:0.06076\teval-error:0.06598\n",
      "Stopping. Best iteration:\n",
      "[38]\ttrain-error:0.06514\teval-error:0.06568\n",
      "\n",
      "[10:13:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06829\teval-error:0.07218\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06780\teval-error:0.07129\n",
      "[2]\ttrain-error:0.06770\teval-error:0.07070\n",
      "[3]\ttrain-error:0.06765\teval-error:0.07070\n",
      "[4]\ttrain-error:0.06799\teval-error:0.07055\n",
      "[5]\ttrain-error:0.06799\teval-error:0.07055\n",
      "[6]\ttrain-error:0.06795\teval-error:0.07070\n",
      "[7]\ttrain-error:0.06760\teval-error:0.07041\n",
      "[8]\ttrain-error:0.06741\teval-error:0.07026\n",
      "[9]\ttrain-error:0.06721\teval-error:0.07011\n",
      "[10]\ttrain-error:0.06731\teval-error:0.07041\n",
      "[11]\ttrain-error:0.06672\teval-error:0.07041\n",
      "[12]\ttrain-error:0.06642\teval-error:0.07011\n",
      "[13]\ttrain-error:0.06662\teval-error:0.06967\n",
      "[14]\ttrain-error:0.06662\teval-error:0.06967\n",
      "[15]\ttrain-error:0.06667\teval-error:0.06937\n",
      "[16]\ttrain-error:0.06677\teval-error:0.06937\n",
      "[17]\ttrain-error:0.06686\teval-error:0.06982\n",
      "[18]\ttrain-error:0.06677\teval-error:0.06952\n",
      "[19]\ttrain-error:0.06681\teval-error:0.06952\n",
      "[20]\ttrain-error:0.06657\teval-error:0.06982\n",
      "[21]\ttrain-error:0.06657\teval-error:0.06996\n",
      "[22]\ttrain-error:0.06642\teval-error:0.06967\n",
      "[23]\ttrain-error:0.06657\teval-error:0.06967\n",
      "[24]\ttrain-error:0.06667\teval-error:0.07011\n",
      "[25]\ttrain-error:0.06662\teval-error:0.06982\n",
      "[26]\ttrain-error:0.06657\teval-error:0.07026\n",
      "[27]\ttrain-error:0.06632\teval-error:0.06982\n",
      "[28]\ttrain-error:0.06603\teval-error:0.07026\n",
      "[29]\ttrain-error:0.06603\teval-error:0.07026\n",
      "[30]\ttrain-error:0.06593\teval-error:0.07026\n",
      "[31]\ttrain-error:0.06573\teval-error:0.07011\n",
      "[32]\ttrain-error:0.06553\teval-error:0.06952\n",
      "[33]\ttrain-error:0.06563\teval-error:0.06952\n",
      "[34]\ttrain-error:0.06544\teval-error:0.06922\n",
      "[35]\ttrain-error:0.06544\teval-error:0.06952\n",
      "[36]\ttrain-error:0.06495\teval-error:0.06967\n",
      "[37]\ttrain-error:0.06465\teval-error:0.06967\n",
      "[38]\ttrain-error:0.06440\teval-error:0.06982\n",
      "[39]\ttrain-error:0.06416\teval-error:0.06922\n",
      "[40]\ttrain-error:0.06376\teval-error:0.06908\n",
      "[41]\ttrain-error:0.06342\teval-error:0.06937\n",
      "[42]\ttrain-error:0.06327\teval-error:0.06937\n",
      "[43]\ttrain-error:0.06317\teval-error:0.06908\n",
      "[44]\ttrain-error:0.06253\teval-error:0.06908\n",
      "[45]\ttrain-error:0.06219\teval-error:0.06922\n",
      "[46]\ttrain-error:0.06204\teval-error:0.06908\n",
      "[47]\ttrain-error:0.06189\teval-error:0.06922\n",
      "[48]\ttrain-error:0.06155\teval-error:0.06922\n",
      "[49]\ttrain-error:0.06155\teval-error:0.06922\n",
      "[50]\ttrain-error:0.06140\teval-error:0.06908\n",
      "[51]\ttrain-error:0.06125\teval-error:0.06864\n",
      "[52]\ttrain-error:0.06111\teval-error:0.06864\n",
      "[53]\ttrain-error:0.06096\teval-error:0.06878\n",
      "[54]\ttrain-error:0.06066\teval-error:0.06893\n",
      "[55]\ttrain-error:0.06066\teval-error:0.06893\n",
      "[56]\ttrain-error:0.06062\teval-error:0.06878\n",
      "[57]\ttrain-error:0.06057\teval-error:0.06878\n",
      "[58]\ttrain-error:0.06037\teval-error:0.06878\n",
      "[59]\ttrain-error:0.06027\teval-error:0.06849\n",
      "[60]\ttrain-error:0.06012\teval-error:0.06864\n",
      "[61]\ttrain-error:0.05983\teval-error:0.06878\n",
      "[62]\ttrain-error:0.05978\teval-error:0.06878\n",
      "[63]\ttrain-error:0.05973\teval-error:0.06878\n",
      "[64]\ttrain-error:0.05973\teval-error:0.06849\n",
      "[65]\ttrain-error:0.05943\teval-error:0.06849\n",
      "[66]\ttrain-error:0.05943\teval-error:0.06834\n",
      "[67]\ttrain-error:0.05924\teval-error:0.06878\n",
      "[68]\ttrain-error:0.05914\teval-error:0.06819\n",
      "[69]\ttrain-error:0.05894\teval-error:0.06864\n",
      "[70]\ttrain-error:0.05884\teval-error:0.06819\n",
      "[71]\ttrain-error:0.05884\teval-error:0.06819\n",
      "[72]\ttrain-error:0.05884\teval-error:0.06804\n",
      "[73]\ttrain-error:0.05865\teval-error:0.06760\n",
      "[74]\ttrain-error:0.05865\teval-error:0.06731\n",
      "[75]\ttrain-error:0.05835\teval-error:0.06745\n",
      "[76]\ttrain-error:0.05825\teval-error:0.06745\n",
      "[77]\ttrain-error:0.05791\teval-error:0.06731\n",
      "[78]\ttrain-error:0.05776\teval-error:0.06745\n",
      "[79]\ttrain-error:0.05776\teval-error:0.06731\n",
      "[80]\ttrain-error:0.05776\teval-error:0.06716\n",
      "[81]\ttrain-error:0.05761\teval-error:0.06716\n",
      "[82]\ttrain-error:0.05751\teval-error:0.06731\n",
      "[83]\ttrain-error:0.05747\teval-error:0.06731\n",
      "[84]\ttrain-error:0.05697\teval-error:0.06760\n",
      "[85]\ttrain-error:0.05683\teval-error:0.06790\n",
      "[86]\ttrain-error:0.05678\teval-error:0.06760\n",
      "[87]\ttrain-error:0.05648\teval-error:0.06775\n",
      "[88]\ttrain-error:0.05634\teval-error:0.06760\n",
      "[89]\ttrain-error:0.05604\teval-error:0.06745\n",
      "[90]\ttrain-error:0.05599\teval-error:0.06731\n",
      "[91]\ttrain-error:0.05594\teval-error:0.06701\n",
      "[92]\ttrain-error:0.05574\teval-error:0.06701\n",
      "[93]\ttrain-error:0.05565\teval-error:0.06701\n",
      "[94]\ttrain-error:0.05560\teval-error:0.06731\n",
      "[95]\ttrain-error:0.05515\teval-error:0.06731\n",
      "[96]\ttrain-error:0.05496\teval-error:0.06760\n",
      "[97]\ttrain-error:0.05456\teval-error:0.06745\n",
      "[98]\ttrain-error:0.05466\teval-error:0.06745\n",
      "[99]\ttrain-error:0.05456\teval-error:0.06745\n",
      "[100]\ttrain-error:0.05451\teval-error:0.06745\n",
      "[101]\ttrain-error:0.05456\teval-error:0.06760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102]\ttrain-error:0.05451\teval-error:0.06745\n",
      "[103]\ttrain-error:0.05451\teval-error:0.06745\n",
      "[104]\ttrain-error:0.05432\teval-error:0.06745\n",
      "[105]\ttrain-error:0.05427\teval-error:0.06731\n",
      "[106]\ttrain-error:0.05407\teval-error:0.06745\n",
      "[107]\ttrain-error:0.05397\teval-error:0.06745\n",
      "[108]\ttrain-error:0.05387\teval-error:0.06745\n",
      "[109]\ttrain-error:0.05382\teval-error:0.06745\n",
      "[110]\ttrain-error:0.05368\teval-error:0.06745\n",
      "[111]\ttrain-error:0.05363\teval-error:0.06731\n",
      "Stopping. Best iteration:\n",
      "[91]\ttrain-error:0.05594\teval-error:0.06701\n",
      "\n",
      "[10:13:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06770\teval-error:0.07188\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06765\teval-error:0.07203\n",
      "[2]\ttrain-error:0.06770\teval-error:0.07188\n",
      "[3]\ttrain-error:0.06760\teval-error:0.07173\n",
      "[4]\ttrain-error:0.06770\teval-error:0.07159\n",
      "[5]\ttrain-error:0.06760\teval-error:0.07159\n",
      "[6]\ttrain-error:0.06775\teval-error:0.07129\n",
      "[7]\ttrain-error:0.06741\teval-error:0.07100\n",
      "[8]\ttrain-error:0.06741\teval-error:0.07114\n",
      "[9]\ttrain-error:0.06745\teval-error:0.07055\n",
      "[10]\ttrain-error:0.06721\teval-error:0.07026\n",
      "[11]\ttrain-error:0.06686\teval-error:0.07055\n",
      "[12]\ttrain-error:0.06726\teval-error:0.07026\n",
      "[13]\ttrain-error:0.06667\teval-error:0.07055\n",
      "[14]\ttrain-error:0.06672\teval-error:0.07070\n",
      "[15]\ttrain-error:0.06647\teval-error:0.07070\n",
      "[16]\ttrain-error:0.06647\teval-error:0.07041\n",
      "[17]\ttrain-error:0.06642\teval-error:0.07055\n",
      "[18]\ttrain-error:0.06627\teval-error:0.07100\n",
      "[19]\ttrain-error:0.06622\teval-error:0.07085\n",
      "[20]\ttrain-error:0.06603\teval-error:0.07055\n",
      "[21]\ttrain-error:0.06603\teval-error:0.07041\n",
      "[22]\ttrain-error:0.06613\teval-error:0.07055\n",
      "[23]\ttrain-error:0.06613\teval-error:0.07041\n",
      "[24]\ttrain-error:0.06583\teval-error:0.07041\n",
      "[25]\ttrain-error:0.06563\teval-error:0.07055\n",
      "[26]\ttrain-error:0.06563\teval-error:0.07055\n",
      "[27]\ttrain-error:0.06558\teval-error:0.07011\n",
      "[28]\ttrain-error:0.06563\teval-error:0.07011\n",
      "[29]\ttrain-error:0.06563\teval-error:0.07011\n",
      "[30]\ttrain-error:0.06553\teval-error:0.07011\n",
      "[31]\ttrain-error:0.06549\teval-error:0.07011\n",
      "[32]\ttrain-error:0.06529\teval-error:0.06996\n",
      "[33]\ttrain-error:0.06524\teval-error:0.07011\n",
      "[34]\ttrain-error:0.06519\teval-error:0.06996\n",
      "[35]\ttrain-error:0.06499\teval-error:0.07026\n",
      "[36]\ttrain-error:0.06485\teval-error:0.07041\n",
      "[37]\ttrain-error:0.06460\teval-error:0.07041\n",
      "[38]\ttrain-error:0.06440\teval-error:0.07055\n",
      "[39]\ttrain-error:0.06435\teval-error:0.07055\n",
      "[40]\ttrain-error:0.06411\teval-error:0.07041\n",
      "[41]\ttrain-error:0.06386\teval-error:0.07041\n",
      "[42]\ttrain-error:0.06391\teval-error:0.07055\n",
      "[43]\ttrain-error:0.06381\teval-error:0.07026\n",
      "[44]\ttrain-error:0.06362\teval-error:0.06996\n",
      "[45]\ttrain-error:0.06332\teval-error:0.06996\n",
      "[46]\ttrain-error:0.06337\teval-error:0.07011\n",
      "[47]\ttrain-error:0.06322\teval-error:0.06996\n",
      "[48]\ttrain-error:0.06293\teval-error:0.07011\n",
      "[49]\ttrain-error:0.06268\teval-error:0.06967\n",
      "[50]\ttrain-error:0.06263\teval-error:0.06967\n",
      "[51]\ttrain-error:0.06258\teval-error:0.06967\n",
      "[52]\ttrain-error:0.06258\teval-error:0.06952\n",
      "[53]\ttrain-error:0.06219\teval-error:0.06996\n",
      "[54]\ttrain-error:0.06214\teval-error:0.06952\n",
      "[55]\ttrain-error:0.06189\teval-error:0.06952\n",
      "[56]\ttrain-error:0.06184\teval-error:0.06982\n",
      "[57]\ttrain-error:0.06165\teval-error:0.06952\n",
      "[58]\ttrain-error:0.06150\teval-error:0.06952\n",
      "[59]\ttrain-error:0.06140\teval-error:0.06952\n",
      "[60]\ttrain-error:0.06125\teval-error:0.06952\n",
      "[61]\ttrain-error:0.06086\teval-error:0.06937\n",
      "[62]\ttrain-error:0.06096\teval-error:0.06952\n",
      "[63]\ttrain-error:0.06086\teval-error:0.06952\n",
      "[64]\ttrain-error:0.06037\teval-error:0.06937\n",
      "[65]\ttrain-error:0.06003\teval-error:0.06937\n",
      "[66]\ttrain-error:0.05978\teval-error:0.06922\n",
      "[67]\ttrain-error:0.05968\teval-error:0.06908\n",
      "[68]\ttrain-error:0.05939\teval-error:0.06893\n",
      "[69]\ttrain-error:0.05929\teval-error:0.06922\n",
      "[70]\ttrain-error:0.05924\teval-error:0.06922\n",
      "[71]\ttrain-error:0.05880\teval-error:0.06908\n",
      "[72]\ttrain-error:0.05880\teval-error:0.06878\n",
      "[73]\ttrain-error:0.05845\teval-error:0.06864\n",
      "[74]\ttrain-error:0.05830\teval-error:0.06878\n",
      "[75]\ttrain-error:0.05825\teval-error:0.06878\n",
      "[76]\ttrain-error:0.05830\teval-error:0.06849\n",
      "[77]\ttrain-error:0.05806\teval-error:0.06878\n",
      "[78]\ttrain-error:0.05811\teval-error:0.06893\n",
      "[79]\ttrain-error:0.05811\teval-error:0.06908\n",
      "[80]\ttrain-error:0.05801\teval-error:0.06908\n",
      "[81]\ttrain-error:0.05791\teval-error:0.06908\n",
      "[82]\ttrain-error:0.05742\teval-error:0.06908\n",
      "[83]\ttrain-error:0.05722\teval-error:0.06908\n",
      "[84]\ttrain-error:0.05693\teval-error:0.06893\n",
      "[85]\ttrain-error:0.05668\teval-error:0.06893\n",
      "[86]\ttrain-error:0.05658\teval-error:0.06893\n",
      "[87]\ttrain-error:0.05643\teval-error:0.06878\n",
      "[88]\ttrain-error:0.05604\teval-error:0.06893\n",
      "[89]\ttrain-error:0.05584\teval-error:0.06878\n",
      "[90]\ttrain-error:0.05560\teval-error:0.06878\n",
      "[91]\ttrain-error:0.05570\teval-error:0.06849\n",
      "[92]\ttrain-error:0.05540\teval-error:0.06864\n",
      "[93]\ttrain-error:0.05530\teval-error:0.06878\n",
      "[94]\ttrain-error:0.05511\teval-error:0.06893\n",
      "[95]\ttrain-error:0.05481\teval-error:0.06878\n",
      "[96]\ttrain-error:0.05486\teval-error:0.06864\n",
      "Stopping. Best iteration:\n",
      "[76]\ttrain-error:0.05830\teval-error:0.06849\n",
      "\n",
      "[10:13:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06731\teval-error:0.07705\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06750\teval-error:0.07616\n",
      "[2]\ttrain-error:0.06686\teval-error:0.07439\n",
      "[3]\ttrain-error:0.06750\teval-error:0.07542\n",
      "[4]\ttrain-error:0.06696\teval-error:0.07528\n",
      "[5]\ttrain-error:0.06741\teval-error:0.07469\n",
      "[6]\ttrain-error:0.06627\teval-error:0.07321\n",
      "[7]\ttrain-error:0.06598\teval-error:0.07277\n",
      "[8]\ttrain-error:0.06613\teval-error:0.07424\n",
      "[9]\ttrain-error:0.06568\teval-error:0.07365\n",
      "[10]\ttrain-error:0.06568\teval-error:0.07321\n",
      "[11]\ttrain-error:0.06534\teval-error:0.07380\n",
      "[12]\ttrain-error:0.06524\teval-error:0.07454\n",
      "[13]\ttrain-error:0.06499\teval-error:0.07498\n",
      "[14]\ttrain-error:0.06519\teval-error:0.07498\n",
      "[15]\ttrain-error:0.06495\teval-error:0.07498\n",
      "[16]\ttrain-error:0.06485\teval-error:0.07439\n",
      "[17]\ttrain-error:0.06485\teval-error:0.07410\n",
      "[18]\ttrain-error:0.06435\teval-error:0.07410\n",
      "[19]\ttrain-error:0.06470\teval-error:0.07395\n",
      "[20]\ttrain-error:0.06480\teval-error:0.07410\n",
      "[21]\ttrain-error:0.06450\teval-error:0.07410\n",
      "[22]\ttrain-error:0.06445\teval-error:0.07395\n",
      "[23]\ttrain-error:0.06445\teval-error:0.07395\n",
      "[24]\ttrain-error:0.06445\teval-error:0.07380\n",
      "[25]\ttrain-error:0.06440\teval-error:0.07410\n",
      "[26]\ttrain-error:0.06401\teval-error:0.07380\n",
      "[27]\ttrain-error:0.06396\teval-error:0.07380\n",
      "Stopping. Best iteration:\n",
      "[7]\ttrain-error:0.06598\teval-error:0.07277\n",
      "\n",
      "0.20938009303304578\n"
     ]
    }
   ],
   "source": [
    "model1 = Model1xgb()\n",
    "scores_mean_1, preds_test_1, va_y_1,va_last_pred_1  = predict_cv(model1, train_x, train_y,test_x)\n",
    "print(scores_mean_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(va_y_1,va_last_pred_1)\n",
    "auc_score = roc_auc_score(va_y_1,va_last_pred_1)\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC curve/AUC Score : {auc_score}')\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nn = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\train.csv')\n",
    "test_nn = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\test.csv')\n",
    "submit__nn = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\head_submit_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['job','marital','education','default','housing','loan','contact','month','poutcome']\n",
    "all_x_nn = pd.concat([train_nn,test_nn])\n",
    "all_x = pd.get_dummies(all_x, columns=cat_cols)\n",
    "\n",
    "train_x_nn = all_x.iloc[:train_x.shape[0], :].reset_index(drop=True)\n",
    "test_x_nn = all_x.iloc[train_x.shape[0]:, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_nn = test_x_nn.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_nn = train_x_nn['y']\n",
    "train_x_nn = train_x_nn.drop(['y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2373 - accuracy: 0.9264 - val_loss: 0.2097 - val_accuracy: 0.9333\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2163 - accuracy: 0.9287 - val_loss: 0.2083 - val_accuracy: 0.9342\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9298 - val_loss: 0.2080 - val_accuracy: 0.9311\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9305 - val_loss: 0.2087 - val_accuracy: 0.9324\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9313 - val_loss: 0.2083 - val_accuracy: 0.9320\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9318 - val_loss: 0.2064 - val_accuracy: 0.9339\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1996 - accuracy: 0.9326 - val_loss: 0.2073 - val_accuracy: 0.9318\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1992 - accuracy: 0.9323 - val_loss: 0.2126 - val_accuracy: 0.9302\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1960 - accuracy: 0.9343 - val_loss: 0.2094 - val_accuracy: 0.9333\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1933 - accuracy: 0.9342 - val_loss: 0.2108 - val_accuracy: 0.9336\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1915 - accuracy: 0.9338 - val_loss: 0.2102 - val_accuracy: 0.9346\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1882 - accuracy: 0.9352 - val_loss: 0.2104 - val_accuracy: 0.9345\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1854 - accuracy: 0.9362 - val_loss: 0.2120 - val_accuracy: 0.9320\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1832 - accuracy: 0.9370 - val_loss: 0.2152 - val_accuracy: 0.9330\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1827 - accuracy: 0.9372 - val_loss: 0.2144 - val_accuracy: 0.9328\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1776 - accuracy: 0.9380 - val_loss: 0.2187 - val_accuracy: 0.9314\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1748 - accuracy: 0.9380 - val_loss: 0.2198 - val_accuracy: 0.9311\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1733 - accuracy: 0.9390 - val_loss: 0.2192 - val_accuracy: 0.9327\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1697 - accuracy: 0.9409 - val_loss: 0.2179 - val_accuracy: 0.9337\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1653 - accuracy: 0.9409 - val_loss: 0.2232 - val_accuracy: 0.9323\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1646 - accuracy: 0.9412 - val_loss: 0.2254 - val_accuracy: 0.9303\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1598 - accuracy: 0.9428 - val_loss: 0.2260 - val_accuracy: 0.9321\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1579 - accuracy: 0.9437 - val_loss: 0.2289 - val_accuracy: 0.9312\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1533 - accuracy: 0.9446 - val_loss: 0.2329 - val_accuracy: 0.9312\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1524 - accuracy: 0.9458 - val_loss: 0.2364 - val_accuracy: 0.9324\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1484 - accuracy: 0.9462 - val_loss: 0.2348 - val_accuracy: 0.9302\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2400 - accuracy: 0.9258 - val_loss: 0.2188 - val_accuracy: 0.9300\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2129 - accuracy: 0.9298 - val_loss: 0.2147 - val_accuracy: 0.9305\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9308 - val_loss: 0.2147 - val_accuracy: 0.9300\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9320 - val_loss: 0.2145 - val_accuracy: 0.9309\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2006 - accuracy: 0.9328 - val_loss: 0.2153 - val_accuracy: 0.9292\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1980 - accuracy: 0.9331 - val_loss: 0.2164 - val_accuracy: 0.9303\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1961 - accuracy: 0.9323 - val_loss: 0.2168 - val_accuracy: 0.9280\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1952 - accuracy: 0.9335 - val_loss: 0.2199 - val_accuracy: 0.9293\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1929 - accuracy: 0.9342 - val_loss: 0.2171 - val_accuracy: 0.9292\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1887 - accuracy: 0.9355 - val_loss: 0.2204 - val_accuracy: 0.9275\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1872 - accuracy: 0.9354 - val_loss: 0.2220 - val_accuracy: 0.9274\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1865 - accuracy: 0.9363 - val_loss: 0.2189 - val_accuracy: 0.9283\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1843 - accuracy: 0.9361 - val_loss: 0.2213 - val_accuracy: 0.9281\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1817 - accuracy: 0.9377 - val_loss: 0.2258 - val_accuracy: 0.9277\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1780 - accuracy: 0.9382 - val_loss: 0.2283 - val_accuracy: 0.9266\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1750 - accuracy: 0.9391 - val_loss: 0.2296 - val_accuracy: 0.9259\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1719 - accuracy: 0.9402 - val_loss: 0.2333 - val_accuracy: 0.9275\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1695 - accuracy: 0.9404 - val_loss: 0.2319 - val_accuracy: 0.9275\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1667 - accuracy: 0.9415 - val_loss: 0.2355 - val_accuracy: 0.9266\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1632 - accuracy: 0.9422 - val_loss: 0.2350 - val_accuracy: 0.9243\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1602 - accuracy: 0.9437 - val_loss: 0.2389 - val_accuracy: 0.9252\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1575 - accuracy: 0.9436 - val_loss: 0.2399 - val_accuracy: 0.9230\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1539 - accuracy: 0.9444 - val_loss: 0.2447 - val_accuracy: 0.9238\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1511 - accuracy: 0.9469 - val_loss: 0.2496 - val_accuracy: 0.9246\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2425 - accuracy: 0.9239 - val_loss: 0.2172 - val_accuracy: 0.9294\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2112 - accuracy: 0.9313 - val_loss: 0.2185 - val_accuracy: 0.9299\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9316 - val_loss: 0.2180 - val_accuracy: 0.9297\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9318 - val_loss: 0.2161 - val_accuracy: 0.9317\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2022 - accuracy: 0.9328 - val_loss: 0.2189 - val_accuracy: 0.9309\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1982 - accuracy: 0.9337 - val_loss: 0.2194 - val_accuracy: 0.9297\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1978 - accuracy: 0.9328 - val_loss: 0.2200 - val_accuracy: 0.9315\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1958 - accuracy: 0.9335 - val_loss: 0.2212 - val_accuracy: 0.9303\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1937 - accuracy: 0.9345 - val_loss: 0.2209 - val_accuracy: 0.9302\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1914 - accuracy: 0.9353 - val_loss: 0.2205 - val_accuracy: 0.9300\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1891 - accuracy: 0.9354 - val_loss: 0.2233 - val_accuracy: 0.9299\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1870 - accuracy: 0.9363 - val_loss: 0.2234 - val_accuracy: 0.9306\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1858 - accuracy: 0.9369 - val_loss: 0.2257 - val_accuracy: 0.9280\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1835 - accuracy: 0.9367 - val_loss: 0.2284 - val_accuracy: 0.9303\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1810 - accuracy: 0.9366 - val_loss: 0.2294 - val_accuracy: 0.9287\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1761 - accuracy: 0.9377 - val_loss: 0.2309 - val_accuracy: 0.9306\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1737 - accuracy: 0.9400 - val_loss: 0.2338 - val_accuracy: 0.9290\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1727 - accuracy: 0.9407 - val_loss: 0.2334 - val_accuracy: 0.9287\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1691 - accuracy: 0.9406 - val_loss: 0.2350 - val_accuracy: 0.9277\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1638 - accuracy: 0.9420 - val_loss: 0.2371 - val_accuracy: 0.9275\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1620 - accuracy: 0.9419 - val_loss: 0.2398 - val_accuracy: 0.9294\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1584 - accuracy: 0.9421 - val_loss: 0.2429 - val_accuracy: 0.9287\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1579 - accuracy: 0.9444 - val_loss: 0.2414 - val_accuracy: 0.9289\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1544 - accuracy: 0.9458 - val_loss: 0.2468 - val_accuracy: 0.9271\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2340 - accuracy: 0.9286 - val_loss: 0.2207 - val_accuracy: 0.9266\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2120 - accuracy: 0.9304 - val_loss: 0.2142 - val_accuracy: 0.9278\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9316 - val_loss: 0.2145 - val_accuracy: 0.9289\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9333 - val_loss: 0.2136 - val_accuracy: 0.9283\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9332 - val_loss: 0.2147 - val_accuracy: 0.9266\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1996 - accuracy: 0.9346 - val_loss: 0.2168 - val_accuracy: 0.9280\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1976 - accuracy: 0.9343 - val_loss: 0.2213 - val_accuracy: 0.9272\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1955 - accuracy: 0.9357 - val_loss: 0.2164 - val_accuracy: 0.9269\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1927 - accuracy: 0.9349 - val_loss: 0.2214 - val_accuracy: 0.9249\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1902 - accuracy: 0.9362 - val_loss: 0.2236 - val_accuracy: 0.9249\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1887 - accuracy: 0.9370 - val_loss: 0.2215 - val_accuracy: 0.9258\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1860 - accuracy: 0.9374 - val_loss: 0.2267 - val_accuracy: 0.9253\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1821 - accuracy: 0.9379 - val_loss: 0.2244 - val_accuracy: 0.9244\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1806 - accuracy: 0.9388 - val_loss: 0.2268 - val_accuracy: 0.9256\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1758 - accuracy: 0.9403 - val_loss: 0.2279 - val_accuracy: 0.9246\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1758 - accuracy: 0.9402 - val_loss: 0.2331 - val_accuracy: 0.9237\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1726 - accuracy: 0.9411 - val_loss: 0.2293 - val_accuracy: 0.9259\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1682 - accuracy: 0.9418 - val_loss: 0.2367 - val_accuracy: 0.9249\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1677 - accuracy: 0.9427 - val_loss: 0.2398 - val_accuracy: 0.9244\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1645 - accuracy: 0.9446 - val_loss: 0.2371 - val_accuracy: 0.9237\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1613 - accuracy: 0.9444 - val_loss: 0.2403 - val_accuracy: 0.9241\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1588 - accuracy: 0.9448 - val_loss: 0.2428 - val_accuracy: 0.9232\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1555 - accuracy: 0.9466 - val_loss: 0.2439 - val_accuracy: 0.9222\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1571 - accuracy: 0.9453 - val_loss: 0.2444 - val_accuracy: 0.9247\n",
      "0.21262300780679905\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model1NNproba()\n",
    "scores_mean_2, preds_test_2, va_y_2,va_last_pred_2  = predict_cv(model_2, train_x_nn, train_y_nn,test_x_nn)\n",
    "print(scores_mean_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(va_y_2,va_last_pred_2)\n",
    "auc_score = roc_auc_score(va_y_2,va_last_pred_2)\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC curve/AUC Score : {auc_score}')\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv(model, train_x, train_y, test_x):\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "    \n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "    for i , (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "        \n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "    \n",
    "    preds_test = np.mean(preds_test, axis=0)\n",
    "    \n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.1681\n",
      "logloss: 6.5234\n"
     ]
    }
   ],
   "source": [
    "model1_a = Model2KNN()\n",
    "pred_train_1a , preds_test_1a = predict_cv_classfier(model1_a, train_x, train_y, test_x)\n",
    "\n",
    "model1_b = Model2KMeans()\n",
    "pred_train_1b, preds_test_1b = predict_cv_classfier(model1_b, train_x, train_y, test_x)\n",
    "\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1a, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1b, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:43:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06780\teval-error:0.07026\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06824\teval-error:0.06952\n",
      "[2]\ttrain-error:0.06790\teval-error:0.06922\n",
      "[3]\ttrain-error:0.06799\teval-error:0.06937\n",
      "[4]\ttrain-error:0.06770\teval-error:0.06952\n",
      "[5]\ttrain-error:0.06780\teval-error:0.06937\n",
      "[6]\ttrain-error:0.06775\teval-error:0.06864\n",
      "[7]\ttrain-error:0.06681\teval-error:0.06937\n",
      "[8]\ttrain-error:0.06657\teval-error:0.06952\n",
      "[9]\ttrain-error:0.06637\teval-error:0.06967\n",
      "[10]\ttrain-error:0.06642\teval-error:0.06937\n",
      "[11]\ttrain-error:0.06627\teval-error:0.06908\n",
      "[12]\ttrain-error:0.06617\teval-error:0.06908\n",
      "[13]\ttrain-error:0.06632\teval-error:0.06878\n",
      "[14]\ttrain-error:0.06637\teval-error:0.06878\n",
      "[15]\ttrain-error:0.06627\teval-error:0.06819\n",
      "[16]\ttrain-error:0.06632\teval-error:0.06775\n",
      "[17]\ttrain-error:0.06617\teval-error:0.06790\n",
      "[18]\ttrain-error:0.06617\teval-error:0.06804\n",
      "[19]\ttrain-error:0.06642\teval-error:0.06760\n",
      "[20]\ttrain-error:0.06662\teval-error:0.06701\n",
      "[21]\ttrain-error:0.06662\teval-error:0.06716\n",
      "[22]\ttrain-error:0.06637\teval-error:0.06672\n",
      "[23]\ttrain-error:0.06647\teval-error:0.06672\n",
      "[24]\ttrain-error:0.06657\teval-error:0.06701\n",
      "[25]\ttrain-error:0.06647\teval-error:0.06701\n",
      "[26]\ttrain-error:0.06637\teval-error:0.06686\n",
      "[27]\ttrain-error:0.06608\teval-error:0.06686\n",
      "[28]\ttrain-error:0.06603\teval-error:0.06701\n",
      "[29]\ttrain-error:0.06637\teval-error:0.06686\n",
      "[30]\ttrain-error:0.06622\teval-error:0.06627\n",
      "[31]\ttrain-error:0.06608\teval-error:0.06613\n",
      "[32]\ttrain-error:0.06598\teval-error:0.06627\n",
      "[33]\ttrain-error:0.06563\teval-error:0.06598\n",
      "[34]\ttrain-error:0.06553\teval-error:0.06598\n",
      "[35]\ttrain-error:0.06553\teval-error:0.06598\n",
      "[36]\ttrain-error:0.06549\teval-error:0.06598\n",
      "[37]\ttrain-error:0.06549\teval-error:0.06583\n",
      "[38]\ttrain-error:0.06514\teval-error:0.06568\n",
      "[39]\ttrain-error:0.06504\teval-error:0.06598\n",
      "[40]\ttrain-error:0.06460\teval-error:0.06583\n",
      "[41]\ttrain-error:0.06421\teval-error:0.06598\n",
      "[42]\ttrain-error:0.06401\teval-error:0.06627\n",
      "[43]\ttrain-error:0.06376\teval-error:0.06598\n",
      "[44]\ttrain-error:0.06357\teval-error:0.06583\n",
      "[45]\ttrain-error:0.06337\teval-error:0.06598\n",
      "[46]\ttrain-error:0.06317\teval-error:0.06627\n",
      "[47]\ttrain-error:0.06308\teval-error:0.06627\n",
      "[48]\ttrain-error:0.06303\teval-error:0.06627\n",
      "[49]\ttrain-error:0.06268\teval-error:0.06568\n",
      "[50]\ttrain-error:0.06248\teval-error:0.06598\n",
      "[51]\ttrain-error:0.06239\teval-error:0.06627\n",
      "[52]\ttrain-error:0.06199\teval-error:0.06613\n",
      "[53]\ttrain-error:0.06189\teval-error:0.06642\n",
      "[54]\ttrain-error:0.06189\teval-error:0.06627\n",
      "[55]\ttrain-error:0.06150\teval-error:0.06642\n",
      "[56]\ttrain-error:0.06155\teval-error:0.06613\n",
      "[57]\ttrain-error:0.06111\teval-error:0.06627\n",
      "[58]\ttrain-error:0.06076\teval-error:0.06598\n",
      "Stopping. Best iteration:\n",
      "[38]\ttrain-error:0.06514\teval-error:0.06568\n",
      "\n",
      "[10:43:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06829\teval-error:0.07218\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06780\teval-error:0.07129\n",
      "[2]\ttrain-error:0.06770\teval-error:0.07070\n",
      "[3]\ttrain-error:0.06765\teval-error:0.07070\n",
      "[4]\ttrain-error:0.06799\teval-error:0.07055\n",
      "[5]\ttrain-error:0.06799\teval-error:0.07055\n",
      "[6]\ttrain-error:0.06795\teval-error:0.07070\n",
      "[7]\ttrain-error:0.06760\teval-error:0.07041\n",
      "[8]\ttrain-error:0.06741\teval-error:0.07026\n",
      "[9]\ttrain-error:0.06721\teval-error:0.07011\n",
      "[10]\ttrain-error:0.06731\teval-error:0.07041\n",
      "[11]\ttrain-error:0.06672\teval-error:0.07041\n",
      "[12]\ttrain-error:0.06642\teval-error:0.07011\n",
      "[13]\ttrain-error:0.06662\teval-error:0.06967\n",
      "[14]\ttrain-error:0.06662\teval-error:0.06967\n",
      "[15]\ttrain-error:0.06667\teval-error:0.06937\n",
      "[16]\ttrain-error:0.06677\teval-error:0.06937\n",
      "[17]\ttrain-error:0.06686\teval-error:0.06982\n",
      "[18]\ttrain-error:0.06677\teval-error:0.06952\n",
      "[19]\ttrain-error:0.06681\teval-error:0.06952\n",
      "[20]\ttrain-error:0.06657\teval-error:0.06982\n",
      "[21]\ttrain-error:0.06657\teval-error:0.06996\n",
      "[22]\ttrain-error:0.06642\teval-error:0.06967\n",
      "[23]\ttrain-error:0.06657\teval-error:0.06967\n",
      "[24]\ttrain-error:0.06667\teval-error:0.07011\n",
      "[25]\ttrain-error:0.06662\teval-error:0.06982\n",
      "[26]\ttrain-error:0.06657\teval-error:0.07026\n",
      "[27]\ttrain-error:0.06632\teval-error:0.06982\n",
      "[28]\ttrain-error:0.06603\teval-error:0.07026\n",
      "[29]\ttrain-error:0.06603\teval-error:0.07026\n",
      "[30]\ttrain-error:0.06593\teval-error:0.07026\n",
      "[31]\ttrain-error:0.06573\teval-error:0.07011\n",
      "[32]\ttrain-error:0.06553\teval-error:0.06952\n",
      "[33]\ttrain-error:0.06563\teval-error:0.06952\n",
      "[34]\ttrain-error:0.06544\teval-error:0.06922\n",
      "[35]\ttrain-error:0.06544\teval-error:0.06952\n",
      "[36]\ttrain-error:0.06495\teval-error:0.06967\n",
      "[37]\ttrain-error:0.06465\teval-error:0.06967\n",
      "[38]\ttrain-error:0.06440\teval-error:0.06982\n",
      "[39]\ttrain-error:0.06416\teval-error:0.06922\n",
      "[40]\ttrain-error:0.06376\teval-error:0.06908\n",
      "[41]\ttrain-error:0.06342\teval-error:0.06937\n",
      "[42]\ttrain-error:0.06327\teval-error:0.06937\n",
      "[43]\ttrain-error:0.06317\teval-error:0.06908\n",
      "[44]\ttrain-error:0.06253\teval-error:0.06908\n",
      "[45]\ttrain-error:0.06219\teval-error:0.06922\n",
      "[46]\ttrain-error:0.06204\teval-error:0.06908\n",
      "[47]\ttrain-error:0.06189\teval-error:0.06922\n",
      "[48]\ttrain-error:0.06155\teval-error:0.06922\n",
      "[49]\ttrain-error:0.06155\teval-error:0.06922\n",
      "[50]\ttrain-error:0.06140\teval-error:0.06908\n",
      "[51]\ttrain-error:0.06125\teval-error:0.06864\n",
      "[52]\ttrain-error:0.06111\teval-error:0.06864\n",
      "[53]\ttrain-error:0.06096\teval-error:0.06878\n",
      "[54]\ttrain-error:0.06066\teval-error:0.06893\n",
      "[55]\ttrain-error:0.06066\teval-error:0.06893\n",
      "[56]\ttrain-error:0.06062\teval-error:0.06878\n",
      "[57]\ttrain-error:0.06057\teval-error:0.06878\n",
      "[58]\ttrain-error:0.06037\teval-error:0.06878\n",
      "[59]\ttrain-error:0.06027\teval-error:0.06849\n",
      "[60]\ttrain-error:0.06012\teval-error:0.06864\n",
      "[61]\ttrain-error:0.05983\teval-error:0.06878\n",
      "[62]\ttrain-error:0.05978\teval-error:0.06878\n",
      "[63]\ttrain-error:0.05973\teval-error:0.06878\n",
      "[64]\ttrain-error:0.05973\teval-error:0.06849\n",
      "[65]\ttrain-error:0.05943\teval-error:0.06849\n",
      "[66]\ttrain-error:0.05943\teval-error:0.06834\n",
      "[67]\ttrain-error:0.05924\teval-error:0.06878\n",
      "[68]\ttrain-error:0.05914\teval-error:0.06819\n",
      "[69]\ttrain-error:0.05894\teval-error:0.06864\n",
      "[70]\ttrain-error:0.05884\teval-error:0.06819\n",
      "[71]\ttrain-error:0.05884\teval-error:0.06819\n",
      "[72]\ttrain-error:0.05884\teval-error:0.06804\n",
      "[73]\ttrain-error:0.05865\teval-error:0.06760\n",
      "[74]\ttrain-error:0.05865\teval-error:0.06731\n",
      "[75]\ttrain-error:0.05835\teval-error:0.06745\n",
      "[76]\ttrain-error:0.05825\teval-error:0.06745\n",
      "[77]\ttrain-error:0.05791\teval-error:0.06731\n",
      "[78]\ttrain-error:0.05776\teval-error:0.06745\n",
      "[79]\ttrain-error:0.05776\teval-error:0.06731\n",
      "[80]\ttrain-error:0.05776\teval-error:0.06716\n",
      "[81]\ttrain-error:0.05761\teval-error:0.06716\n",
      "[82]\ttrain-error:0.05751\teval-error:0.06731\n",
      "[83]\ttrain-error:0.05747\teval-error:0.06731\n",
      "[84]\ttrain-error:0.05697\teval-error:0.06760\n",
      "[85]\ttrain-error:0.05683\teval-error:0.06790\n",
      "[86]\ttrain-error:0.05678\teval-error:0.06760\n",
      "[87]\ttrain-error:0.05648\teval-error:0.06775\n",
      "[88]\ttrain-error:0.05634\teval-error:0.06760\n",
      "[89]\ttrain-error:0.05604\teval-error:0.06745\n",
      "[90]\ttrain-error:0.05599\teval-error:0.06731\n",
      "[91]\ttrain-error:0.05594\teval-error:0.06701\n",
      "[92]\ttrain-error:0.05574\teval-error:0.06701\n",
      "[93]\ttrain-error:0.05565\teval-error:0.06701\n",
      "[94]\ttrain-error:0.05560\teval-error:0.06731\n",
      "[95]\ttrain-error:0.05515\teval-error:0.06731\n",
      "[96]\ttrain-error:0.05496\teval-error:0.06760\n",
      "[97]\ttrain-error:0.05456\teval-error:0.06745\n",
      "[98]\ttrain-error:0.05466\teval-error:0.06745\n",
      "[99]\ttrain-error:0.05456\teval-error:0.06745\n",
      "[100]\ttrain-error:0.05451\teval-error:0.06745\n",
      "[101]\ttrain-error:0.05456\teval-error:0.06760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102]\ttrain-error:0.05451\teval-error:0.06745\n",
      "[103]\ttrain-error:0.05451\teval-error:0.06745\n",
      "[104]\ttrain-error:0.05432\teval-error:0.06745\n",
      "[105]\ttrain-error:0.05427\teval-error:0.06731\n",
      "[106]\ttrain-error:0.05407\teval-error:0.06745\n",
      "[107]\ttrain-error:0.05397\teval-error:0.06745\n",
      "[108]\ttrain-error:0.05387\teval-error:0.06745\n",
      "[109]\ttrain-error:0.05382\teval-error:0.06745\n",
      "[110]\ttrain-error:0.05368\teval-error:0.06745\n",
      "[111]\ttrain-error:0.05363\teval-error:0.06731\n",
      "Stopping. Best iteration:\n",
      "[91]\ttrain-error:0.05594\teval-error:0.06701\n",
      "\n",
      "[10:43:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06770\teval-error:0.07188\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06765\teval-error:0.07203\n",
      "[2]\ttrain-error:0.06770\teval-error:0.07188\n",
      "[3]\ttrain-error:0.06760\teval-error:0.07173\n",
      "[4]\ttrain-error:0.06770\teval-error:0.07159\n",
      "[5]\ttrain-error:0.06760\teval-error:0.07159\n",
      "[6]\ttrain-error:0.06775\teval-error:0.07129\n",
      "[7]\ttrain-error:0.06741\teval-error:0.07100\n",
      "[8]\ttrain-error:0.06741\teval-error:0.07114\n",
      "[9]\ttrain-error:0.06745\teval-error:0.07055\n",
      "[10]\ttrain-error:0.06721\teval-error:0.07026\n",
      "[11]\ttrain-error:0.06686\teval-error:0.07055\n",
      "[12]\ttrain-error:0.06726\teval-error:0.07026\n",
      "[13]\ttrain-error:0.06667\teval-error:0.07055\n",
      "[14]\ttrain-error:0.06672\teval-error:0.07070\n",
      "[15]\ttrain-error:0.06647\teval-error:0.07070\n",
      "[16]\ttrain-error:0.06647\teval-error:0.07041\n",
      "[17]\ttrain-error:0.06642\teval-error:0.07055\n",
      "[18]\ttrain-error:0.06627\teval-error:0.07100\n",
      "[19]\ttrain-error:0.06622\teval-error:0.07085\n",
      "[20]\ttrain-error:0.06603\teval-error:0.07055\n",
      "[21]\ttrain-error:0.06603\teval-error:0.07041\n",
      "[22]\ttrain-error:0.06613\teval-error:0.07055\n",
      "[23]\ttrain-error:0.06613\teval-error:0.07041\n",
      "[24]\ttrain-error:0.06583\teval-error:0.07041\n",
      "[25]\ttrain-error:0.06563\teval-error:0.07055\n",
      "[26]\ttrain-error:0.06563\teval-error:0.07055\n",
      "[27]\ttrain-error:0.06558\teval-error:0.07011\n",
      "[28]\ttrain-error:0.06563\teval-error:0.07011\n",
      "[29]\ttrain-error:0.06563\teval-error:0.07011\n",
      "[30]\ttrain-error:0.06553\teval-error:0.07011\n",
      "[31]\ttrain-error:0.06549\teval-error:0.07011\n",
      "[32]\ttrain-error:0.06529\teval-error:0.06996\n",
      "[33]\ttrain-error:0.06524\teval-error:0.07011\n",
      "[34]\ttrain-error:0.06519\teval-error:0.06996\n",
      "[35]\ttrain-error:0.06499\teval-error:0.07026\n",
      "[36]\ttrain-error:0.06485\teval-error:0.07041\n",
      "[37]\ttrain-error:0.06460\teval-error:0.07041\n",
      "[38]\ttrain-error:0.06440\teval-error:0.07055\n",
      "[39]\ttrain-error:0.06435\teval-error:0.07055\n",
      "[40]\ttrain-error:0.06411\teval-error:0.07041\n",
      "[41]\ttrain-error:0.06386\teval-error:0.07041\n",
      "[42]\ttrain-error:0.06391\teval-error:0.07055\n",
      "[43]\ttrain-error:0.06381\teval-error:0.07026\n",
      "[44]\ttrain-error:0.06362\teval-error:0.06996\n",
      "[45]\ttrain-error:0.06332\teval-error:0.06996\n",
      "[46]\ttrain-error:0.06337\teval-error:0.07011\n",
      "[47]\ttrain-error:0.06322\teval-error:0.06996\n",
      "[48]\ttrain-error:0.06293\teval-error:0.07011\n",
      "[49]\ttrain-error:0.06268\teval-error:0.06967\n",
      "[50]\ttrain-error:0.06263\teval-error:0.06967\n",
      "[51]\ttrain-error:0.06258\teval-error:0.06967\n",
      "[52]\ttrain-error:0.06258\teval-error:0.06952\n",
      "[53]\ttrain-error:0.06219\teval-error:0.06996\n",
      "[54]\ttrain-error:0.06214\teval-error:0.06952\n",
      "[55]\ttrain-error:0.06189\teval-error:0.06952\n",
      "[56]\ttrain-error:0.06184\teval-error:0.06982\n",
      "[57]\ttrain-error:0.06165\teval-error:0.06952\n",
      "[58]\ttrain-error:0.06150\teval-error:0.06952\n",
      "[59]\ttrain-error:0.06140\teval-error:0.06952\n",
      "[60]\ttrain-error:0.06125\teval-error:0.06952\n",
      "[61]\ttrain-error:0.06086\teval-error:0.06937\n",
      "[62]\ttrain-error:0.06096\teval-error:0.06952\n",
      "[63]\ttrain-error:0.06086\teval-error:0.06952\n",
      "[64]\ttrain-error:0.06037\teval-error:0.06937\n",
      "[65]\ttrain-error:0.06003\teval-error:0.06937\n",
      "[66]\ttrain-error:0.05978\teval-error:0.06922\n",
      "[67]\ttrain-error:0.05968\teval-error:0.06908\n",
      "[68]\ttrain-error:0.05939\teval-error:0.06893\n",
      "[69]\ttrain-error:0.05929\teval-error:0.06922\n",
      "[70]\ttrain-error:0.05924\teval-error:0.06922\n",
      "[71]\ttrain-error:0.05880\teval-error:0.06908\n",
      "[72]\ttrain-error:0.05880\teval-error:0.06878\n",
      "[73]\ttrain-error:0.05845\teval-error:0.06864\n",
      "[74]\ttrain-error:0.05830\teval-error:0.06878\n",
      "[75]\ttrain-error:0.05825\teval-error:0.06878\n",
      "[76]\ttrain-error:0.05830\teval-error:0.06849\n",
      "[77]\ttrain-error:0.05806\teval-error:0.06878\n",
      "[78]\ttrain-error:0.05811\teval-error:0.06893\n",
      "[79]\ttrain-error:0.05811\teval-error:0.06908\n",
      "[80]\ttrain-error:0.05801\teval-error:0.06908\n",
      "[81]\ttrain-error:0.05791\teval-error:0.06908\n",
      "[82]\ttrain-error:0.05742\teval-error:0.06908\n",
      "[83]\ttrain-error:0.05722\teval-error:0.06908\n",
      "[84]\ttrain-error:0.05693\teval-error:0.06893\n",
      "[85]\ttrain-error:0.05668\teval-error:0.06893\n",
      "[86]\ttrain-error:0.05658\teval-error:0.06893\n",
      "[87]\ttrain-error:0.05643\teval-error:0.06878\n",
      "[88]\ttrain-error:0.05604\teval-error:0.06893\n",
      "[89]\ttrain-error:0.05584\teval-error:0.06878\n",
      "[90]\ttrain-error:0.05560\teval-error:0.06878\n",
      "[91]\ttrain-error:0.05570\teval-error:0.06849\n",
      "[92]\ttrain-error:0.05540\teval-error:0.06864\n",
      "[93]\ttrain-error:0.05530\teval-error:0.06878\n",
      "[94]\ttrain-error:0.05511\teval-error:0.06893\n",
      "[95]\ttrain-error:0.05481\teval-error:0.06878\n",
      "[96]\ttrain-error:0.05486\teval-error:0.06864\n",
      "Stopping. Best iteration:\n",
      "[76]\ttrain-error:0.05830\teval-error:0.06849\n",
      "\n",
      "[10:43:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06731\teval-error:0.07705\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06750\teval-error:0.07616\n",
      "[2]\ttrain-error:0.06686\teval-error:0.07439\n",
      "[3]\ttrain-error:0.06750\teval-error:0.07542\n",
      "[4]\ttrain-error:0.06696\teval-error:0.07528\n",
      "[5]\ttrain-error:0.06741\teval-error:0.07469\n",
      "[6]\ttrain-error:0.06627\teval-error:0.07321\n",
      "[7]\ttrain-error:0.06598\teval-error:0.07277\n",
      "[8]\ttrain-error:0.06613\teval-error:0.07424\n",
      "[9]\ttrain-error:0.06568\teval-error:0.07365\n",
      "[10]\ttrain-error:0.06568\teval-error:0.07321\n",
      "[11]\ttrain-error:0.06534\teval-error:0.07380\n",
      "[12]\ttrain-error:0.06524\teval-error:0.07454\n",
      "[13]\ttrain-error:0.06499\teval-error:0.07498\n",
      "[14]\ttrain-error:0.06519\teval-error:0.07498\n",
      "[15]\ttrain-error:0.06495\teval-error:0.07498\n",
      "[16]\ttrain-error:0.06485\teval-error:0.07439\n",
      "[17]\ttrain-error:0.06485\teval-error:0.07410\n",
      "[18]\ttrain-error:0.06435\teval-error:0.07410\n",
      "[19]\ttrain-error:0.06470\teval-error:0.07395\n",
      "[20]\ttrain-error:0.06480\teval-error:0.07410\n",
      "[21]\ttrain-error:0.06450\teval-error:0.07410\n",
      "[22]\ttrain-error:0.06445\teval-error:0.07395\n",
      "[23]\ttrain-error:0.06445\teval-error:0.07395\n",
      "[24]\ttrain-error:0.06445\teval-error:0.07380\n",
      "[25]\ttrain-error:0.06440\teval-error:0.07410\n",
      "[26]\ttrain-error:0.06401\teval-error:0.07380\n",
      "[27]\ttrain-error:0.06396\teval-error:0.07380\n",
      "Stopping. Best iteration:\n",
      "[7]\ttrain-error:0.06598\teval-error:0.07277\n",
      "\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2398 - accuracy: 0.9257 - val_loss: 0.2091 - val_accuracy: 0.9311\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2162 - accuracy: 0.9291 - val_loss: 0.2090 - val_accuracy: 0.9327\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2109 - accuracy: 0.9299 - val_loss: 0.2097 - val_accuracy: 0.9324\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9307 - val_loss: 0.2084 - val_accuracy: 0.9342\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9310 - val_loss: 0.2078 - val_accuracy: 0.9327\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2031 - accuracy: 0.9312 - val_loss: 0.2093 - val_accuracy: 0.9336\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1996 - accuracy: 0.9327 - val_loss: 0.2087 - val_accuracy: 0.9328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1977 - accuracy: 0.9335 - val_loss: 0.2073 - val_accuracy: 0.9339\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1955 - accuracy: 0.9339 - val_loss: 0.2094 - val_accuracy: 0.9328\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1935 - accuracy: 0.9336 - val_loss: 0.2068 - val_accuracy: 0.9349\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1910 - accuracy: 0.9347 - val_loss: 0.2104 - val_accuracy: 0.9333\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1893 - accuracy: 0.9349 - val_loss: 0.2099 - val_accuracy: 0.9321\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1868 - accuracy: 0.9352 - val_loss: 0.2103 - val_accuracy: 0.9339\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1838 - accuracy: 0.9377 - val_loss: 0.2152 - val_accuracy: 0.9311\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1820 - accuracy: 0.9366 - val_loss: 0.2110 - val_accuracy: 0.9330\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1787 - accuracy: 0.9376 - val_loss: 0.2169 - val_accuracy: 0.9312\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1762 - accuracy: 0.9389 - val_loss: 0.2187 - val_accuracy: 0.9333\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1729 - accuracy: 0.9400 - val_loss: 0.2173 - val_accuracy: 0.9325\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1716 - accuracy: 0.9406 - val_loss: 0.2174 - val_accuracy: 0.9315\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1674 - accuracy: 0.9410 - val_loss: 0.2218 - val_accuracy: 0.9303\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1656 - accuracy: 0.9406 - val_loss: 0.2256 - val_accuracy: 0.9275\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1645 - accuracy: 0.9412 - val_loss: 0.2234 - val_accuracy: 0.9306\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1590 - accuracy: 0.9427 - val_loss: 0.2270 - val_accuracy: 0.9286\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1565 - accuracy: 0.9438 - val_loss: 0.2319 - val_accuracy: 0.9321\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1547 - accuracy: 0.9446 - val_loss: 0.2328 - val_accuracy: 0.9300\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1521 - accuracy: 0.9447 - val_loss: 0.2353 - val_accuracy: 0.9287\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1486 - accuracy: 0.9452 - val_loss: 0.2325 - val_accuracy: 0.9308\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1454 - accuracy: 0.9484 - val_loss: 0.2377 - val_accuracy: 0.9263\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1440 - accuracy: 0.9478 - val_loss: 0.2390 - val_accuracy: 0.9238\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1386 - accuracy: 0.9501 - val_loss: 0.2427 - val_accuracy: 0.9306\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2464 - accuracy: 0.9194 - val_loss: 0.2156 - val_accuracy: 0.9293\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2123 - accuracy: 0.9307 - val_loss: 0.2140 - val_accuracy: 0.9283\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9309 - val_loss: 0.2142 - val_accuracy: 0.9311\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9320 - val_loss: 0.2157 - val_accuracy: 0.9309\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2018 - accuracy: 0.9320 - val_loss: 0.2128 - val_accuracy: 0.9306\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2006 - accuracy: 0.9323 - val_loss: 0.2148 - val_accuracy: 0.9284\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1966 - accuracy: 0.9333 - val_loss: 0.2190 - val_accuracy: 0.9294\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1945 - accuracy: 0.9350 - val_loss: 0.2184 - val_accuracy: 0.9280\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1936 - accuracy: 0.9350 - val_loss: 0.2217 - val_accuracy: 0.9299\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1913 - accuracy: 0.9356 - val_loss: 0.2201 - val_accuracy: 0.9283\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1900 - accuracy: 0.9349 - val_loss: 0.2252 - val_accuracy: 0.9284\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1867 - accuracy: 0.9369 - val_loss: 0.2239 - val_accuracy: 0.9272\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1832 - accuracy: 0.9375 - val_loss: 0.2334 - val_accuracy: 0.9262\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1812 - accuracy: 0.9367 - val_loss: 0.2288 - val_accuracy: 0.9246\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1796 - accuracy: 0.9378 - val_loss: 0.2288 - val_accuracy: 0.9261\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1749 - accuracy: 0.9394 - val_loss: 0.2288 - val_accuracy: 0.9268\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1745 - accuracy: 0.9393 - val_loss: 0.2351 - val_accuracy: 0.9250\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1709 - accuracy: 0.9418 - val_loss: 0.2300 - val_accuracy: 0.9255\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1665 - accuracy: 0.9418 - val_loss: 0.2360 - val_accuracy: 0.9256\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1650 - accuracy: 0.9423 - val_loss: 0.2450 - val_accuracy: 0.9268\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1618 - accuracy: 0.9434 - val_loss: 0.2441 - val_accuracy: 0.9259\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1575 - accuracy: 0.9452 - val_loss: 0.2436 - val_accuracy: 0.9258\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1553 - accuracy: 0.9464 - val_loss: 0.2520 - val_accuracy: 0.9244\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1508 - accuracy: 0.9476 - val_loss: 0.2505 - val_accuracy: 0.9244\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1493 - accuracy: 0.9474 - val_loss: 0.2530 - val_accuracy: 0.9235\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2407 - accuracy: 0.9256 - val_loss: 0.2218 - val_accuracy: 0.9284\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.9300 - val_loss: 0.2174 - val_accuracy: 0.9303\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9312 - val_loss: 0.2210 - val_accuracy: 0.9283\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9329 - val_loss: 0.2185 - val_accuracy: 0.9302\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2024 - accuracy: 0.9328 - val_loss: 0.2175 - val_accuracy: 0.9311\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1975 - accuracy: 0.9339 - val_loss: 0.2235 - val_accuracy: 0.9303\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1959 - accuracy: 0.9344 - val_loss: 0.2215 - val_accuracy: 0.9299\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1942 - accuracy: 0.9330 - val_loss: 0.2255 - val_accuracy: 0.9309\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1932 - accuracy: 0.9354 - val_loss: 0.2228 - val_accuracy: 0.9287\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1917 - accuracy: 0.9347 - val_loss: 0.2236 - val_accuracy: 0.9314\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1880 - accuracy: 0.9350 - val_loss: 0.2236 - val_accuracy: 0.9293\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1871 - accuracy: 0.9357 - val_loss: 0.2269 - val_accuracy: 0.9294\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1836 - accuracy: 0.9360 - val_loss: 0.2275 - val_accuracy: 0.9297\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1819 - accuracy: 0.9376 - val_loss: 0.2301 - val_accuracy: 0.9292\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1792 - accuracy: 0.9374 - val_loss: 0.2307 - val_accuracy: 0.9287\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1756 - accuracy: 0.9375 - val_loss: 0.2341 - val_accuracy: 0.9308\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1727 - accuracy: 0.9389 - val_loss: 0.2339 - val_accuracy: 0.9261\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1716 - accuracy: 0.9406 - val_loss: 0.2362 - val_accuracy: 0.9299\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1675 - accuracy: 0.9421 - val_loss: 0.2364 - val_accuracy: 0.9300\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1651 - accuracy: 0.9413 - val_loss: 0.2404 - val_accuracy: 0.9266\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1635 - accuracy: 0.9423 - val_loss: 0.2444 - val_accuracy: 0.9271\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1610 - accuracy: 0.9435 - val_loss: 0.2424 - val_accuracy: 0.9272\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2367 - accuracy: 0.9276 - val_loss: 0.2175 - val_accuracy: 0.9255\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2123 - accuracy: 0.9318 - val_loss: 0.2182 - val_accuracy: 0.9263\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9312 - val_loss: 0.2146 - val_accuracy: 0.9278\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9324 - val_loss: 0.2178 - val_accuracy: 0.9272\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2006 - accuracy: 0.9335 - val_loss: 0.2179 - val_accuracy: 0.9259\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1985 - accuracy: 0.9342 - val_loss: 0.2174 - val_accuracy: 0.9271\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1959 - accuracy: 0.9346 - val_loss: 0.2195 - val_accuracy: 0.9265\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1923 - accuracy: 0.9361 - val_loss: 0.2181 - val_accuracy: 0.9269\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.1910 - accuracy: 0.9359 - val_loss: 0.2210 - val_accuracy: 0.9258\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1897 - accuracy: 0.9364 - val_loss: 0.2233 - val_accuracy: 0.9263\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1867 - accuracy: 0.9378 - val_loss: 0.2233 - val_accuracy: 0.9265\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1850 - accuracy: 0.9365 - val_loss: 0.2230 - val_accuracy: 0.9249\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1821 - accuracy: 0.9387 - val_loss: 0.2286 - val_accuracy: 0.9255\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1809 - accuracy: 0.9392 - val_loss: 0.2309 - val_accuracy: 0.9224\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1762 - accuracy: 0.9396 - val_loss: 0.2305 - val_accuracy: 0.9247\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1730 - accuracy: 0.9405 - val_loss: 0.2349 - val_accuracy: 0.9247\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1709 - accuracy: 0.9416 - val_loss: 0.2327 - val_accuracy: 0.9259\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1678 - accuracy: 0.9414 - val_loss: 0.2379 - val_accuracy: 0.9235\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1662 - accuracy: 0.9428 - val_loss: 0.2374 - val_accuracy: 0.9241\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1621 - accuracy: 0.9436 - val_loss: 0.2347 - val_accuracy: 0.9237\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1603 - accuracy: 0.9444 - val_loss: 0.2453 - val_accuracy: 0.9230\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1586 - accuracy: 0.9450 - val_loss: 0.2429 - val_accuracy: 0.9200\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1551 - accuracy: 0.9453 - val_loss: 0.2434 - val_accuracy: 0.9218\n",
      "[10:45:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.07838\teval-error:0.07439\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.07459\teval-error:0.07026\n",
      "[2]\ttrain-error:0.07695\teval-error:0.07218\n",
      "[3]\ttrain-error:0.07316\teval-error:0.06878\n",
      "[4]\ttrain-error:0.07242\teval-error:0.06819\n",
      "[5]\ttrain-error:0.07233\teval-error:0.06804\n",
      "[6]\ttrain-error:0.07213\teval-error:0.06804\n",
      "[7]\ttrain-error:0.07233\teval-error:0.06804\n",
      "[8]\ttrain-error:0.07228\teval-error:0.06819\n",
      "[9]\ttrain-error:0.07223\teval-error:0.06804\n",
      "[10]\ttrain-error:0.07233\teval-error:0.06790\n",
      "[11]\ttrain-error:0.07233\teval-error:0.06790\n",
      "[12]\ttrain-error:0.07218\teval-error:0.06790\n",
      "[13]\ttrain-error:0.07208\teval-error:0.06804\n",
      "[14]\ttrain-error:0.07198\teval-error:0.06819\n",
      "[15]\ttrain-error:0.07218\teval-error:0.06775\n",
      "[16]\ttrain-error:0.07203\teval-error:0.06745\n",
      "[17]\ttrain-error:0.07198\teval-error:0.06760\n",
      "[18]\ttrain-error:0.07208\teval-error:0.06760\n",
      "[19]\ttrain-error:0.07208\teval-error:0.06760\n",
      "[20]\ttrain-error:0.07203\teval-error:0.06760\n",
      "[21]\ttrain-error:0.07188\teval-error:0.06745\n",
      "[22]\ttrain-error:0.07198\teval-error:0.06745\n",
      "[23]\ttrain-error:0.07183\teval-error:0.06731\n",
      "[24]\ttrain-error:0.07183\teval-error:0.06672\n",
      "[25]\ttrain-error:0.07188\teval-error:0.06672\n",
      "[26]\ttrain-error:0.07178\teval-error:0.06672\n",
      "[27]\ttrain-error:0.07173\teval-error:0.06657\n",
      "[28]\ttrain-error:0.07159\teval-error:0.06657\n",
      "[29]\ttrain-error:0.07119\teval-error:0.06657\n",
      "[30]\ttrain-error:0.07095\teval-error:0.06642\n",
      "[31]\ttrain-error:0.07090\teval-error:0.06613\n",
      "[32]\ttrain-error:0.07055\teval-error:0.06627\n",
      "[33]\ttrain-error:0.07041\teval-error:0.06613\n",
      "[34]\ttrain-error:0.06991\teval-error:0.06598\n",
      "[35]\ttrain-error:0.06967\teval-error:0.06583\n",
      "[36]\ttrain-error:0.06957\teval-error:0.06583\n",
      "[37]\ttrain-error:0.06952\teval-error:0.06583\n",
      "[38]\ttrain-error:0.06942\teval-error:0.06583\n",
      "[39]\ttrain-error:0.06918\teval-error:0.06583\n",
      "[40]\ttrain-error:0.06908\teval-error:0.06598\n",
      "[41]\ttrain-error:0.06932\teval-error:0.06583\n",
      "[42]\ttrain-error:0.06908\teval-error:0.06598\n",
      "[43]\ttrain-error:0.06888\teval-error:0.06568\n",
      "[44]\ttrain-error:0.06873\teval-error:0.06539\n",
      "[45]\ttrain-error:0.06873\teval-error:0.06553\n",
      "[46]\ttrain-error:0.06849\teval-error:0.06539\n",
      "[47]\ttrain-error:0.06854\teval-error:0.06553\n",
      "[48]\ttrain-error:0.06829\teval-error:0.06583\n",
      "[49]\ttrain-error:0.06814\teval-error:0.06598\n",
      "[50]\ttrain-error:0.06799\teval-error:0.06539\n",
      "[51]\ttrain-error:0.06809\teval-error:0.06509\n",
      "[52]\ttrain-error:0.06799\teval-error:0.06539\n",
      "[53]\ttrain-error:0.06785\teval-error:0.06524\n",
      "[54]\ttrain-error:0.06760\teval-error:0.06524\n",
      "[55]\ttrain-error:0.06750\teval-error:0.06509\n",
      "[56]\ttrain-error:0.06755\teval-error:0.06524\n",
      "[57]\ttrain-error:0.06770\teval-error:0.06495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58]\ttrain-error:0.06755\teval-error:0.06480\n",
      "[59]\ttrain-error:0.06735\teval-error:0.06495\n",
      "[60]\ttrain-error:0.06755\teval-error:0.06509\n",
      "[61]\ttrain-error:0.06755\teval-error:0.06509\n",
      "[62]\ttrain-error:0.06741\teval-error:0.06509\n",
      "[63]\ttrain-error:0.06726\teval-error:0.06539\n",
      "[64]\ttrain-error:0.06711\teval-error:0.06524\n",
      "[65]\ttrain-error:0.06701\teval-error:0.06480\n",
      "[66]\ttrain-error:0.06686\teval-error:0.06495\n",
      "[67]\ttrain-error:0.06677\teval-error:0.06539\n",
      "[68]\ttrain-error:0.06677\teval-error:0.06465\n",
      "[69]\ttrain-error:0.06672\teval-error:0.06480\n",
      "[70]\ttrain-error:0.06667\teval-error:0.06495\n",
      "[71]\ttrain-error:0.06672\teval-error:0.06495\n",
      "[72]\ttrain-error:0.06662\teval-error:0.06495\n",
      "[73]\ttrain-error:0.06672\teval-error:0.06509\n",
      "[74]\ttrain-error:0.06657\teval-error:0.06539\n",
      "[75]\ttrain-error:0.06647\teval-error:0.06524\n",
      "[76]\ttrain-error:0.06647\teval-error:0.06524\n",
      "[77]\ttrain-error:0.06637\teval-error:0.06509\n",
      "[78]\ttrain-error:0.06642\teval-error:0.06539\n",
      "[79]\ttrain-error:0.06637\teval-error:0.06524\n",
      "[80]\ttrain-error:0.06622\teval-error:0.06524\n",
      "[81]\ttrain-error:0.06608\teval-error:0.06495\n",
      "[82]\ttrain-error:0.06613\teval-error:0.06480\n",
      "[83]\ttrain-error:0.06603\teval-error:0.06465\n",
      "[84]\ttrain-error:0.06613\teval-error:0.06480\n",
      "[85]\ttrain-error:0.06603\teval-error:0.06465\n",
      "[86]\ttrain-error:0.06583\teval-error:0.06480\n",
      "[87]\ttrain-error:0.06578\teval-error:0.06539\n",
      "[88]\ttrain-error:0.06603\teval-error:0.06539\n",
      "Stopping. Best iteration:\n",
      "[68]\ttrain-error:0.06677\teval-error:0.06465\n",
      "\n",
      "[10:45:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.07646\teval-error:0.07675\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.07370\teval-error:0.07291\n",
      "[2]\ttrain-error:0.07606\teval-error:0.07601\n",
      "[3]\ttrain-error:0.07272\teval-error:0.07306\n",
      "[4]\ttrain-error:0.07173\teval-error:0.07233\n",
      "[5]\ttrain-error:0.07114\teval-error:0.07188\n",
      "[6]\ttrain-error:0.07100\teval-error:0.07188\n",
      "[7]\ttrain-error:0.07139\teval-error:0.07262\n",
      "[8]\ttrain-error:0.07129\teval-error:0.07218\n",
      "[9]\ttrain-error:0.07114\teval-error:0.07203\n",
      "[10]\ttrain-error:0.07095\teval-error:0.07188\n",
      "[11]\ttrain-error:0.07095\teval-error:0.07188\n",
      "[12]\ttrain-error:0.07105\teval-error:0.07188\n",
      "[13]\ttrain-error:0.07090\teval-error:0.07218\n",
      "[14]\ttrain-error:0.07090\teval-error:0.07218\n",
      "[15]\ttrain-error:0.07095\teval-error:0.07247\n",
      "[16]\ttrain-error:0.07090\teval-error:0.07203\n",
      "[17]\ttrain-error:0.07075\teval-error:0.07188\n",
      "[18]\ttrain-error:0.07055\teval-error:0.07203\n",
      "[19]\ttrain-error:0.07060\teval-error:0.07203\n",
      "[20]\ttrain-error:0.07060\teval-error:0.07203\n",
      "[21]\ttrain-error:0.07070\teval-error:0.07218\n",
      "[22]\ttrain-error:0.07065\teval-error:0.07218\n",
      "[23]\ttrain-error:0.07055\teval-error:0.07203\n",
      "[24]\ttrain-error:0.07055\teval-error:0.07203\n",
      "[25]\ttrain-error:0.07050\teval-error:0.07203\n",
      "Stopping. Best iteration:\n",
      "[5]\ttrain-error:0.07114\teval-error:0.07188\n",
      "\n",
      "[10:45:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.07685\teval-error:0.07631\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.07287\teval-error:0.07247\n",
      "[2]\ttrain-error:0.07636\teval-error:0.07601\n",
      "[3]\ttrain-error:0.07287\teval-error:0.07291\n",
      "[4]\ttrain-error:0.07114\teval-error:0.07144\n",
      "[5]\ttrain-error:0.07110\teval-error:0.07100\n",
      "[6]\ttrain-error:0.07119\teval-error:0.07085\n",
      "[7]\ttrain-error:0.07129\teval-error:0.07100\n",
      "[8]\ttrain-error:0.07129\teval-error:0.07114\n",
      "[9]\ttrain-error:0.07100\teval-error:0.07085\n",
      "[10]\ttrain-error:0.07110\teval-error:0.07070\n",
      "[11]\ttrain-error:0.07105\teval-error:0.07085\n",
      "[12]\ttrain-error:0.07110\teval-error:0.07085\n",
      "[13]\ttrain-error:0.07090\teval-error:0.07100\n",
      "[14]\ttrain-error:0.07105\teval-error:0.07100\n",
      "[15]\ttrain-error:0.07100\teval-error:0.07114\n",
      "[16]\ttrain-error:0.07100\teval-error:0.07085\n",
      "[17]\ttrain-error:0.07110\teval-error:0.07055\n",
      "[18]\ttrain-error:0.07090\teval-error:0.07085\n",
      "[19]\ttrain-error:0.07080\teval-error:0.07085\n",
      "[20]\ttrain-error:0.07075\teval-error:0.07070\n",
      "[21]\ttrain-error:0.07085\teval-error:0.07055\n",
      "[22]\ttrain-error:0.07055\teval-error:0.07055\n",
      "[23]\ttrain-error:0.07060\teval-error:0.07070\n",
      "[24]\ttrain-error:0.07036\teval-error:0.07070\n",
      "[25]\ttrain-error:0.07021\teval-error:0.07041\n",
      "[26]\ttrain-error:0.07011\teval-error:0.07070\n",
      "[27]\ttrain-error:0.07041\teval-error:0.07100\n",
      "[28]\ttrain-error:0.07011\teval-error:0.07085\n",
      "[29]\ttrain-error:0.07006\teval-error:0.07055\n",
      "[30]\ttrain-error:0.06986\teval-error:0.07100\n",
      "[31]\ttrain-error:0.06991\teval-error:0.07055\n",
      "[32]\ttrain-error:0.06962\teval-error:0.06982\n",
      "[33]\ttrain-error:0.06918\teval-error:0.07026\n",
      "[34]\ttrain-error:0.06893\teval-error:0.06996\n",
      "[35]\ttrain-error:0.06883\teval-error:0.07026\n",
      "[36]\ttrain-error:0.06883\teval-error:0.07055\n",
      "[37]\ttrain-error:0.06873\teval-error:0.07055\n",
      "[38]\ttrain-error:0.06849\teval-error:0.06996\n",
      "[39]\ttrain-error:0.06849\teval-error:0.06982\n",
      "[40]\ttrain-error:0.06824\teval-error:0.06982\n",
      "[41]\ttrain-error:0.06814\teval-error:0.06982\n",
      "[42]\ttrain-error:0.06819\teval-error:0.06967\n",
      "[43]\ttrain-error:0.06824\teval-error:0.06967\n",
      "[44]\ttrain-error:0.06804\teval-error:0.06967\n",
      "[45]\ttrain-error:0.06795\teval-error:0.06982\n",
      "[46]\ttrain-error:0.06790\teval-error:0.06982\n",
      "[47]\ttrain-error:0.06790\teval-error:0.06982\n",
      "[48]\ttrain-error:0.06775\teval-error:0.06996\n",
      "[49]\ttrain-error:0.06760\teval-error:0.06982\n",
      "[50]\ttrain-error:0.06745\teval-error:0.06996\n",
      "[51]\ttrain-error:0.06745\teval-error:0.06996\n",
      "[52]\ttrain-error:0.06741\teval-error:0.06996\n",
      "[53]\ttrain-error:0.06726\teval-error:0.06996\n",
      "[54]\ttrain-error:0.06716\teval-error:0.07011\n",
      "[55]\ttrain-error:0.06701\teval-error:0.07011\n",
      "[56]\ttrain-error:0.06686\teval-error:0.06996\n",
      "[57]\ttrain-error:0.06686\teval-error:0.06996\n",
      "[58]\ttrain-error:0.06662\teval-error:0.07041\n",
      "[59]\ttrain-error:0.06647\teval-error:0.07041\n",
      "[60]\ttrain-error:0.06662\teval-error:0.07026\n",
      "[61]\ttrain-error:0.06652\teval-error:0.07026\n",
      "[62]\ttrain-error:0.06647\teval-error:0.07041\n",
      "Stopping. Best iteration:\n",
      "[42]\ttrain-error:0.06819\teval-error:0.06967\n",
      "\n",
      "[10:45:32] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.07528\teval-error:0.08162\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.07031\teval-error:0.07675\n",
      "[2]\ttrain-error:0.07429\teval-error:0.08044\n",
      "[3]\ttrain-error:0.07080\teval-error:0.07631\n",
      "[4]\ttrain-error:0.07016\teval-error:0.07498\n",
      "[5]\ttrain-error:0.07001\teval-error:0.07498\n",
      "[6]\ttrain-error:0.06996\teval-error:0.07469\n",
      "[7]\ttrain-error:0.06996\teval-error:0.07469\n",
      "[8]\ttrain-error:0.07021\teval-error:0.07587\n",
      "[9]\ttrain-error:0.06996\teval-error:0.07439\n",
      "[10]\ttrain-error:0.06991\teval-error:0.07454\n",
      "[11]\ttrain-error:0.06991\teval-error:0.07483\n",
      "[12]\ttrain-error:0.06986\teval-error:0.07542\n",
      "[13]\ttrain-error:0.06996\teval-error:0.07587\n",
      "[14]\ttrain-error:0.07001\teval-error:0.07587\n",
      "[15]\ttrain-error:0.07021\teval-error:0.07646\n",
      "[16]\ttrain-error:0.06967\teval-error:0.07557\n",
      "[17]\ttrain-error:0.06947\teval-error:0.07483\n",
      "[18]\ttrain-error:0.06947\teval-error:0.07454\n",
      "[19]\ttrain-error:0.06952\teval-error:0.07483\n",
      "[20]\ttrain-error:0.06952\teval-error:0.07469\n",
      "[21]\ttrain-error:0.06947\teval-error:0.07513\n",
      "[22]\ttrain-error:0.06937\teval-error:0.07528\n",
      "[23]\ttrain-error:0.06908\teval-error:0.07513\n",
      "[24]\ttrain-error:0.06898\teval-error:0.07469\n",
      "[25]\ttrain-error:0.06893\teval-error:0.07469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\ttrain-error:0.06903\teval-error:0.07469\n",
      "[27]\ttrain-error:0.06873\teval-error:0.07483\n",
      "[28]\ttrain-error:0.06849\teval-error:0.07513\n",
      "[29]\ttrain-error:0.06839\teval-error:0.07483\n",
      "Stopping. Best iteration:\n",
      "[9]\ttrain-error:0.06996\teval-error:0.07439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1c = Model1xgb()\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_1c, train_x, train_y, test_x)\n",
    "\n",
    "model_1d = Model1NNproba()\n",
    "pred_train_1d, pred_test_1d = predict_cv(model_1d, train_x_nn, train_y, test_x_nn)\n",
    "\n",
    "\n",
    "model_1e = Model1ramdom()\n",
    "pred_train_1e, pred_test_1e = predict_cv(model_1e, train_x, train_y, test_x)\n",
    "\n",
    "\n",
    "model_1f = Model1xgb2()\n",
    "pred_train_1f, pred_test_1f = predict_cv(model_1f, train_x, train_y, test_x)\n",
    "\n",
    "model_1g = Model1NN2proba()\n",
    "pred_train_1g, pred_test_1g = predict_cv(model_1e, train_x_nn, train_y, test_x_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.2094\n",
      "logloss: 0.2129\n",
      "logloss: 0.2479\n",
      "logloss: 0.2179\n",
      "logloss: 0.2478\n"
     ]
    }
   ],
   "source": [
    "print(f'logloss: {log_loss(train_y, pred_train_1c, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1d, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1e, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1f, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1g, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_2 = pd.DataFrame({'pred_1a': pred_train_1a, 'pred_1b': pred_train_1b, 'pred_1c':pred_train_1c,'pred_1d':pred_train_1d, 'pred_1e':pred_train_1e, 'pred_1f': pred_train_1f,'pred_1g':pred_train_1g})\n",
    "test_x_2 = pd.DataFrame({'pred_1a': preds_test_1a, 'pred_1b': preds_test_1b, 'pred_1c': pred_test_1c,'pred_1d':pred_test_1d, 'pred_1e':pred_test_1e, 'pred_1f': pred_test_1f,'pred_1g':pred_test_1g})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2397 - accuracy: 0.9231 - val_loss: 0.2002 - val_accuracy: 0.9340\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2125 - accuracy: 0.9286 - val_loss: 0.2006 - val_accuracy: 0.9297\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9305 - val_loss: 0.1987 - val_accuracy: 0.9334\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2101 - accuracy: 0.9306 - val_loss: 0.2018 - val_accuracy: 0.9305\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9299 - val_loss: 0.2003 - val_accuracy: 0.9306\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9311 - val_loss: 0.2008 - val_accuracy: 0.9308\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9312 - val_loss: 0.2001 - val_accuracy: 0.9300\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9302 - val_loss: 0.2014 - val_accuracy: 0.9312\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9310 - val_loss: 0.2000 - val_accuracy: 0.9314\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9309 - val_loss: 0.2018 - val_accuracy: 0.9308\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9313 - val_loss: 0.2002 - val_accuracy: 0.9300\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9318 - val_loss: 0.2015 - val_accuracy: 0.9297\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9319 - val_loss: 0.2005 - val_accuracy: 0.9300\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9314 - val_loss: 0.2044 - val_accuracy: 0.9306\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9306 - val_loss: 0.2059 - val_accuracy: 0.9320\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9320 - val_loss: 0.2006 - val_accuracy: 0.9314\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9320 - val_loss: 0.2069 - val_accuracy: 0.9327\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9310 - val_loss: 0.2015 - val_accuracy: 0.9306\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9313 - val_loss: 0.1996 - val_accuracy: 0.9314\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9314 - val_loss: 0.2030 - val_accuracy: 0.9339\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9309 - val_loss: 0.2037 - val_accuracy: 0.9309\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9319 - val_loss: 0.2014 - val_accuracy: 0.9305\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9321 - val_loss: 0.2016 - val_accuracy: 0.9311\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2356 - accuracy: 0.9254 - val_loss: 0.2089 - val_accuracy: 0.9303\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2104 - accuracy: 0.9298 - val_loss: 0.2081 - val_accuracy: 0.9311\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9294 - val_loss: 0.2078 - val_accuracy: 0.9309\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2081 - accuracy: 0.9305 - val_loss: 0.2092 - val_accuracy: 0.9306\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9311 - val_loss: 0.2079 - val_accuracy: 0.9311\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9307 - val_loss: 0.2065 - val_accuracy: 0.9312\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9309 - val_loss: 0.2066 - val_accuracy: 0.9311\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9311 - val_loss: 0.2075 - val_accuracy: 0.9306\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9302 - val_loss: 0.2068 - val_accuracy: 0.9311\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9307 - val_loss: 0.2110 - val_accuracy: 0.9317\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9315 - val_loss: 0.2075 - val_accuracy: 0.9311\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9313 - val_loss: 0.2078 - val_accuracy: 0.9303\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9308 - val_loss: 0.2076 - val_accuracy: 0.9311\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9310 - val_loss: 0.2075 - val_accuracy: 0.9306\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9309 - val_loss: 0.2080 - val_accuracy: 0.9305\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9316 - val_loss: 0.2081 - val_accuracy: 0.9312\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9313 - val_loss: 0.2074 - val_accuracy: 0.9309\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9313 - val_loss: 0.2093 - val_accuracy: 0.9315\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9319 - val_loss: 0.2106 - val_accuracy: 0.9292\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9315 - val_loss: 0.2087 - val_accuracy: 0.9306\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9314 - val_loss: 0.2087 - val_accuracy: 0.9305\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9316 - val_loss: 0.2091 - val_accuracy: 0.9302\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9312 - val_loss: 0.2076 - val_accuracy: 0.9311\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9322 - val_loss: 0.2083 - val_accuracy: 0.9303\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9309 - val_loss: 0.2079 - val_accuracy: 0.9311\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9318 - val_loss: 0.2084 - val_accuracy: 0.9312\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2298 - accuracy: 0.9268 - val_loss: 0.2137 - val_accuracy: 0.9311\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9300 - val_loss: 0.2093 - val_accuracy: 0.9315\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9295 - val_loss: 0.2099 - val_accuracy: 0.9330\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9309 - val_loss: 0.2135 - val_accuracy: 0.9320\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9316 - val_loss: 0.2114 - val_accuracy: 0.9309\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9301 - val_loss: 0.2110 - val_accuracy: 0.9320\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9302 - val_loss: 0.2133 - val_accuracy: 0.9318\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9313 - val_loss: 0.2104 - val_accuracy: 0.9311\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2041 - accuracy: 0.9304 - val_loss: 0.2106 - val_accuracy: 0.9320\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9305 - val_loss: 0.2169 - val_accuracy: 0.9317\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9318 - val_loss: 0.2128 - val_accuracy: 0.9312\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9319 - val_loss: 0.2116 - val_accuracy: 0.9306\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9313 - val_loss: 0.2197 - val_accuracy: 0.9314\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9313 - val_loss: 0.2135 - val_accuracy: 0.9314\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9317 - val_loss: 0.2133 - val_accuracy: 0.9314\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9317 - val_loss: 0.2128 - val_accuracy: 0.9318\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9318 - val_loss: 0.2106 - val_accuracy: 0.9315\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9314 - val_loss: 0.2124 - val_accuracy: 0.9317\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9315 - val_loss: 0.2157 - val_accuracy: 0.9320\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9317 - val_loss: 0.2099 - val_accuracy: 0.9321\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9319 - val_loss: 0.2159 - val_accuracy: 0.9323\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9316 - val_loss: 0.2108 - val_accuracy: 0.9318\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2286 - accuracy: 0.9283 - val_loss: 0.2245 - val_accuracy: 0.9278\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2071 - accuracy: 0.9311 - val_loss: 0.2177 - val_accuracy: 0.9281\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9319 - val_loss: 0.2189 - val_accuracy: 0.9265\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9322 - val_loss: 0.2144 - val_accuracy: 0.9269\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2037 - accuracy: 0.9325 - val_loss: 0.2139 - val_accuracy: 0.9277\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2043 - accuracy: 0.9323 - val_loss: 0.2196 - val_accuracy: 0.9278\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9334 - val_loss: 0.2175 - val_accuracy: 0.9265\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9335 - val_loss: 0.2187 - val_accuracy: 0.9261\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9328 - val_loss: 0.2192 - val_accuracy: 0.9265\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9324 - val_loss: 0.2148 - val_accuracy: 0.9269\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2036 - accuracy: 0.9332 - val_loss: 0.2201 - val_accuracy: 0.9262\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2030 - accuracy: 0.9326 - val_loss: 0.2167 - val_accuracy: 0.9272\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9338 - val_loss: 0.2160 - val_accuracy: 0.9266\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2026 - accuracy: 0.9336 - val_loss: 0.2167 - val_accuracy: 0.9263\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2024 - accuracy: 0.9326 - val_loss: 0.2202 - val_accuracy: 0.9265\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2026 - accuracy: 0.9335 - val_loss: 0.2146 - val_accuracy: 0.9269\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9329 - val_loss: 0.2197 - val_accuracy: 0.9269\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2019 - accuracy: 0.9329 - val_loss: 0.2194 - val_accuracy: 0.9250\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2014 - accuracy: 0.9337 - val_loss: 0.2314 - val_accuracy: 0.9244\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9330 - val_loss: 0.2208 - val_accuracy: 0.9259\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2019 - accuracy: 0.9332 - val_loss: 0.2161 - val_accuracy: 0.9259\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2016 - accuracy: 0.9331 - val_loss: 0.2296 - val_accuracy: 0.9262\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9334 - val_loss: 0.2194 - val_accuracy: 0.9261\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2018 - accuracy: 0.9329 - val_loss: 0.2178 - val_accuracy: 0.9277\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2014 - accuracy: 0.9333 - val_loss: 0.2267 - val_accuracy: 0.9268\n",
      "logloss: 0.2071\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model1NNproba()\n",
    "pred_train_2, pred_test_2 = predict_cv(model_2, train_x_2, train_y, test_x_2)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(train_y,pred_train_2)\n",
    "auc_score = roc_auc_score(train_y,pred_train_2)\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC curve/AUC Score : {auc_score}')\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.2153\n"
     ]
    }
   ],
   "source": [
    "model2_2 = Model3logistic()\n",
    "pred_train_2_2, preds_test_2_2 = predict_cv_classfier(model2_2, train_x_2, train_y, test_x_2)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2_2, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2KMeans2:\n",
    "  def __init__(self):\n",
    "    self.model = None\n",
    "    self.scaler = None\n",
    "\n",
    "  def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "    self.scaler = StandardScaler()\n",
    "    self.scaler.fit(tr_x)\n",
    "    tr_x = self.scaler.transform(tr_x)\n",
    "    tr_x = pd.DataFrame(tr_x)\n",
    "\n",
    "    cust_array = []\n",
    "    for i in range (tr_x.shape[1]):\n",
    "      list_s = tr_x.iloc[:,1].tolist()\n",
    "      cust_array.append(list_s)\n",
    "\n",
    "\n",
    "    cust_array = np.array(cust_array)\n",
    "    cust_array = cust_array.T\n",
    "    self.model = KMeans(n_clusters = 2,ramdom_state=12),\n",
    "    self.model.fit(cust_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 6.1154\n"
     ]
    }
   ],
   "source": [
    "model1_h = Model2KMeans()\n",
    "pred_train_1h, preds_test_1h = predict_cv_classfier(model1_h, train_x, train_y, test_x)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1h, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_2_2 = pd.DataFrame({'pred_1a': pred_train_1a, 'pred_1b': pred_train_1b, 'pred_1c':pred_train_1c,'pred_1d':pred_train_1d, 'pred_1e':pred_train_1e, 'pred_1f': pred_train_1f,'pred_1g':pred_train_1g,'pred_1h':pred_train_1h})\n",
    "test_x_2_2 = pd.DataFrame({'pred_1a': preds_test_1a, 'pred_1b': preds_test_1b, 'pred_1c': pred_test_1c,'pred_1d':pred_test_1d, 'pred_1e':pred_test_1e, 'pred_1f': pred_test_1f,'pred_1g':pred_test_1g,'pred_1h':preds_test_1h})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2311 - accuracy: 0.9275 - val_loss: 0.1977 - val_accuracy: 0.9331\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2122 - accuracy: 0.9292 - val_loss: 0.2004 - val_accuracy: 0.9343\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9294 - val_loss: 0.1994 - val_accuracy: 0.9325\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2110 - accuracy: 0.9307 - val_loss: 0.1986 - val_accuracy: 0.9345\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9309 - val_loss: 0.1983 - val_accuracy: 0.9317\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9308 - val_loss: 0.1994 - val_accuracy: 0.9334\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9312 - val_loss: 0.1986 - val_accuracy: 0.9334\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9305 - val_loss: 0.1975 - val_accuracy: 0.9333\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9317 - val_loss: 0.1995 - val_accuracy: 0.9321\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9320 - val_loss: 0.2002 - val_accuracy: 0.9346\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9315 - val_loss: 0.1976 - val_accuracy: 0.9327\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9315 - val_loss: 0.2009 - val_accuracy: 0.9315\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9315 - val_loss: 0.2004 - val_accuracy: 0.9339\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9318 - val_loss: 0.1996 - val_accuracy: 0.9305\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9322 - val_loss: 0.1988 - val_accuracy: 0.9331\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9317 - val_loss: 0.1990 - val_accuracy: 0.9318\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9318 - val_loss: 0.1988 - val_accuracy: 0.9339\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9318 - val_loss: 0.2007 - val_accuracy: 0.9330\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9323 - val_loss: 0.1991 - val_accuracy: 0.9328\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9321 - val_loss: 0.1994 - val_accuracy: 0.9320\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9318 - val_loss: 0.1986 - val_accuracy: 0.9331\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9324 - val_loss: 0.2006 - val_accuracy: 0.9333\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9322 - val_loss: 0.2029 - val_accuracy: 0.9323\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2064 - accuracy: 0.9324 - val_loss: 0.2010 - val_accuracy: 0.9317\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9323 - val_loss: 0.2015 - val_accuracy: 0.9308\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9314 - val_loss: 0.1994 - val_accuracy: 0.9342\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9319 - val_loss: 0.2043 - val_accuracy: 0.9311\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9322 - val_loss: 0.1997 - val_accuracy: 0.9336\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2334 - accuracy: 0.9245 - val_loss: 0.2108 - val_accuracy: 0.9284\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9307 - val_loss: 0.2089 - val_accuracy: 0.9299\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9306 - val_loss: 0.2094 - val_accuracy: 0.9296\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9305 - val_loss: 0.2101 - val_accuracy: 0.9306\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9307 - val_loss: 0.2083 - val_accuracy: 0.9312\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9306 - val_loss: 0.2078 - val_accuracy: 0.9323\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9311 - val_loss: 0.2108 - val_accuracy: 0.9306\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9315 - val_loss: 0.2074 - val_accuracy: 0.9306\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9318 - val_loss: 0.2098 - val_accuracy: 0.9308\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9316 - val_loss: 0.2103 - val_accuracy: 0.9306\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9317 - val_loss: 0.2078 - val_accuracy: 0.9306\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9316 - val_loss: 0.2076 - val_accuracy: 0.9314\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9311 - val_loss: 0.2092 - val_accuracy: 0.9306\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9309 - val_loss: 0.2153 - val_accuracy: 0.9300\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9312 - val_loss: 0.2115 - val_accuracy: 0.9312\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9316 - val_loss: 0.2141 - val_accuracy: 0.9299\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9320 - val_loss: 0.2099 - val_accuracy: 0.9314\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9316 - val_loss: 0.2126 - val_accuracy: 0.9308\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9325 - val_loss: 0.2103 - val_accuracy: 0.9306\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9314 - val_loss: 0.2093 - val_accuracy: 0.9323\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9319 - val_loss: 0.2142 - val_accuracy: 0.9292\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9322 - val_loss: 0.2117 - val_accuracy: 0.9300\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9323 - val_loss: 0.2087 - val_accuracy: 0.9311\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2033 - accuracy: 0.9313 - val_loss: 0.2097 - val_accuracy: 0.9315\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9314 - val_loss: 0.2100 - val_accuracy: 0.9303\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2028 - accuracy: 0.9318 - val_loss: 0.2107 - val_accuracy: 0.9299\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2026 - accuracy: 0.9318 - val_loss: 0.2099 - val_accuracy: 0.9308\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2030 - accuracy: 0.9318 - val_loss: 0.2146 - val_accuracy: 0.9308\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2256 - accuracy: 0.9266 - val_loss: 0.2139 - val_accuracy: 0.9321\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9303 - val_loss: 0.2108 - val_accuracy: 0.9309\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9313 - val_loss: 0.2125 - val_accuracy: 0.9305\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9316 - val_loss: 0.2152 - val_accuracy: 0.9314\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9311 - val_loss: 0.2106 - val_accuracy: 0.9309\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9325 - val_loss: 0.2142 - val_accuracy: 0.9311\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2036 - accuracy: 0.9319 - val_loss: 0.2109 - val_accuracy: 0.9312\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9314 - val_loss: 0.2148 - val_accuracy: 0.9314\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9318 - val_loss: 0.2101 - val_accuracy: 0.9305\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2033 - accuracy: 0.9317 - val_loss: 0.2134 - val_accuracy: 0.9320\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2024 - accuracy: 0.9325 - val_loss: 0.2093 - val_accuracy: 0.9317\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9325 - val_loss: 0.2100 - val_accuracy: 0.9309\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2024 - accuracy: 0.9327 - val_loss: 0.2144 - val_accuracy: 0.9311\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9327 - val_loss: 0.2135 - val_accuracy: 0.9314\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2009 - accuracy: 0.9326 - val_loss: 0.2134 - val_accuracy: 0.9302\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9327 - val_loss: 0.2147 - val_accuracy: 0.9309\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2013 - accuracy: 0.9333 - val_loss: 0.2130 - val_accuracy: 0.9312\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9324 - val_loss: 0.2127 - val_accuracy: 0.9314\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2018 - accuracy: 0.9326 - val_loss: 0.2118 - val_accuracy: 0.9305\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2021 - accuracy: 0.9332 - val_loss: 0.2121 - val_accuracy: 0.9314\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2012 - accuracy: 0.9325 - val_loss: 0.2101 - val_accuracy: 0.9309\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2010 - accuracy: 0.9332 - val_loss: 0.2134 - val_accuracy: 0.9314\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.9327 - val_loss: 0.2174 - val_accuracy: 0.9300\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2013 - accuracy: 0.9331 - val_loss: 0.2123 - val_accuracy: 0.9305\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.9324 - val_loss: 0.2102 - val_accuracy: 0.9305\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2004 - accuracy: 0.9329 - val_loss: 0.2137 - val_accuracy: 0.9303\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2003 - accuracy: 0.9335 - val_loss: 0.2136 - val_accuracy: 0.9302\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2006 - accuracy: 0.9330 - val_loss: 0.2131 - val_accuracy: 0.9306\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1998 - accuracy: 0.9340 - val_loss: 0.2220 - val_accuracy: 0.9309\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2005 - accuracy: 0.9331 - val_loss: 0.2199 - val_accuracy: 0.9305\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2004 - accuracy: 0.9328 - val_loss: 0.2159 - val_accuracy: 0.9303\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2270 - accuracy: 0.9281 - val_loss: 0.2265 - val_accuracy: 0.9261\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2069 - accuracy: 0.9316 - val_loss: 0.2289 - val_accuracy: 0.9283\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9320 - val_loss: 0.2242 - val_accuracy: 0.9284\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9325 - val_loss: 0.2349 - val_accuracy: 0.9286\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9328 - val_loss: 0.2321 - val_accuracy: 0.9271\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9331 - val_loss: 0.2172 - val_accuracy: 0.9281\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9325 - val_loss: 0.2242 - val_accuracy: 0.9265\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9323 - val_loss: 0.2207 - val_accuracy: 0.9278\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9325 - val_loss: 0.2230 - val_accuracy: 0.9275\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9330 - val_loss: 0.2188 - val_accuracy: 0.9281\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2031 - accuracy: 0.9327 - val_loss: 0.2153 - val_accuracy: 0.9287\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2036 - accuracy: 0.9326 - val_loss: 0.2158 - val_accuracy: 0.9259\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9335 - val_loss: 0.2253 - val_accuracy: 0.9252\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9332 - val_loss: 0.2187 - val_accuracy: 0.9284\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9331 - val_loss: 0.2187 - val_accuracy: 0.9277\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9333 - val_loss: 0.2193 - val_accuracy: 0.9261\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9329 - val_loss: 0.2223 - val_accuracy: 0.9253\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9335 - val_loss: 0.2180 - val_accuracy: 0.9259\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2019 - accuracy: 0.9334 - val_loss: 0.2202 - val_accuracy: 0.9268\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9334 - val_loss: 0.2171 - val_accuracy: 0.9262\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9333 - val_loss: 0.2208 - val_accuracy: 0.9265\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9333 - val_loss: 0.2136 - val_accuracy: 0.9266\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9339 - val_loss: 0.2178 - val_accuracy: 0.9258\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2019 - accuracy: 0.9330 - val_loss: 0.2141 - val_accuracy: 0.9246\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2009 - accuracy: 0.9333 - val_loss: 0.2175 - val_accuracy: 0.9289\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2012 - accuracy: 0.9334 - val_loss: 0.2154 - val_accuracy: 0.9268\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2018 - accuracy: 0.9340 - val_loss: 0.2155 - val_accuracy: 0.9249\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2012 - accuracy: 0.9337 - val_loss: 0.2180 - val_accuracy: 0.9244\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2015 - accuracy: 0.9326 - val_loss: 0.2160 - val_accuracy: 0.9252\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2014 - accuracy: 0.9336 - val_loss: 0.2151 - val_accuracy: 0.9261\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2014 - accuracy: 0.9332 - val_loss: 0.2147 - val_accuracy: 0.9243\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2009 - accuracy: 0.9338 - val_loss: 0.2166 - val_accuracy: 0.9261\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2010 - accuracy: 0.9339 - val_loss: 0.2139 - val_accuracy: 0.9252\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2014 - accuracy: 0.9334 - val_loss: 0.2194 - val_accuracy: 0.9250\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2005 - accuracy: 0.9334 - val_loss: 0.2126 - val_accuracy: 0.9265\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2003 - accuracy: 0.9340 - val_loss: 0.2157 - val_accuracy: 0.9247\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2003 - accuracy: 0.9333 - val_loss: 0.2143 - val_accuracy: 0.9252\n",
      "Epoch 38/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2005 - accuracy: 0.9341 - val_loss: 0.2145 - val_accuracy: 0.9250\n",
      "Epoch 39/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2003 - accuracy: 0.9338 - val_loss: 0.2175 - val_accuracy: 0.9262\n",
      "Epoch 40/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2001 - accuracy: 0.9334 - val_loss: 0.2186 - val_accuracy: 0.9272\n",
      "Epoch 41/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1997 - accuracy: 0.9334 - val_loss: 0.2189 - val_accuracy: 0.9256\n",
      "Epoch 42/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1992 - accuracy: 0.9335 - val_loss: 0.2158 - val_accuracy: 0.9269\n",
      "Epoch 43/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2002 - accuracy: 0.9339 - val_loss: 0.2190 - val_accuracy: 0.9244\n",
      "Epoch 44/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2000 - accuracy: 0.9331 - val_loss: 0.2165 - val_accuracy: 0.9255\n",
      "Epoch 45/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1995 - accuracy: 0.9333 - val_loss: 0.2190 - val_accuracy: 0.9246\n",
      "Epoch 46/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1995 - accuracy: 0.9342 - val_loss: 0.2162 - val_accuracy: 0.9259\n",
      "Epoch 47/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1987 - accuracy: 0.9340 - val_loss: 0.2161 - val_accuracy: 0.9261\n",
      "Epoch 48/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1994 - accuracy: 0.9341 - val_loss: 0.2186 - val_accuracy: 0.9258\n",
      "Epoch 49/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1993 - accuracy: 0.9340 - val_loss: 0.2186 - val_accuracy: 0.9250\n",
      "Epoch 50/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1994 - accuracy: 0.9339 - val_loss: 0.2170 - val_accuracy: 0.9258\n",
      "Epoch 51/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1986 - accuracy: 0.9342 - val_loss: 0.2186 - val_accuracy: 0.9246\n",
      "Epoch 52/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1986 - accuracy: 0.9341 - val_loss: 0.2220 - val_accuracy: 0.9255\n",
      "Epoch 53/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1989 - accuracy: 0.9341 - val_loss: 0.2205 - val_accuracy: 0.9244\n",
      "Epoch 54/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1978 - accuracy: 0.9345 - val_loss: 0.2249 - val_accuracy: 0.9247\n",
      "Epoch 55/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1989 - accuracy: 0.9340 - val_loss: 0.2212 - val_accuracy: 0.9249\n",
      "logloss: 0.2067\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model1NNproba()\n",
    "pred_train_2_2, pred_test_2_2 = predict_cv(model_2, train_x_2_2, train_y, test_x_2_2)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2_2, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.2344\n"
     ]
    }
   ],
   "source": [
    "model2_2 = Model3logistic()\n",
    "pred_train_2_2, preds_test_2_2 = predict_cv_classfier(model2_2, train_x_2_2, train_y, test_x_2_2)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2_2, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.2627\n"
     ]
    }
   ],
   "source": [
    "model1_h = Model3logistic()\n",
    "pred_train_1h, preds_test_1h = predict_cv_classfier(model1_h, train_x, train_y, test_x)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1h, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_2_3 = pd.DataFrame({'pred_1a': pred_train_1a, 'pred_1b': pred_train_1b, 'pred_1c':pred_train_1c,'pred_1d':pred_train_1d, 'pred_1e':pred_train_1e, 'pred_1f': pred_train_1f,'pred_1g':pred_train_1g,'pred_1h':pred_train_1h})\n",
    "test_x_2_3 = pd.DataFrame({'pred_1a': preds_test_1a, 'pred_1b': preds_test_1b, 'pred_1c': pred_test_1c,'pred_1d':pred_test_1d, 'pred_1e':pred_test_1e, 'pred_1f': pred_test_1f,'pred_1g':pred_test_1g,'pred_1h':preds_test_1h})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2406 - accuracy: 0.9215 - val_loss: 0.2023 - val_accuracy: 0.9308\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.9290 - val_loss: 0.2020 - val_accuracy: 0.9296\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2114 - accuracy: 0.9303 - val_loss: 0.1998 - val_accuracy: 0.9296\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2101 - accuracy: 0.9301 - val_loss: 0.1980 - val_accuracy: 0.9334\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2108 - accuracy: 0.9301 - val_loss: 0.2010 - val_accuracy: 0.9327\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9316 - val_loss: 0.2006 - val_accuracy: 0.9311\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2108 - accuracy: 0.9297 - val_loss: 0.2006 - val_accuracy: 0.9314\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9310 - val_loss: 0.2072 - val_accuracy: 0.9286\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9303 - val_loss: 0.2003 - val_accuracy: 0.9323\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9307 - val_loss: 0.1997 - val_accuracy: 0.9324\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9313 - val_loss: 0.1999 - val_accuracy: 0.9314\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9314 - val_loss: 0.2003 - val_accuracy: 0.9315\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2073 - accuracy: 0.9310 - val_loss: 0.2002 - val_accuracy: 0.9318\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9316 - val_loss: 0.2016 - val_accuracy: 0.9321\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9315 - val_loss: 0.2033 - val_accuracy: 0.9327\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9316 - val_loss: 0.1992 - val_accuracy: 0.9336\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9318 - val_loss: 0.1997 - val_accuracy: 0.9315\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9320 - val_loss: 0.2005 - val_accuracy: 0.9320\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9321 - val_loss: 0.2070 - val_accuracy: 0.9323\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9317 - val_loss: 0.2037 - val_accuracy: 0.9323\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9319 - val_loss: 0.2033 - val_accuracy: 0.9323\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9312 - val_loss: 0.2030 - val_accuracy: 0.9324\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9310 - val_loss: 0.2002 - val_accuracy: 0.9323\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9314 - val_loss: 0.2036 - val_accuracy: 0.9317\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2317 - accuracy: 0.9282 - val_loss: 0.2173 - val_accuracy: 0.9250\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9298 - val_loss: 0.2139 - val_accuracy: 0.9286\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9300 - val_loss: 0.2082 - val_accuracy: 0.9308\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2093 - accuracy: 0.9310 - val_loss: 0.2088 - val_accuracy: 0.9314\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9319 - val_loss: 0.2063 - val_accuracy: 0.9314\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9306 - val_loss: 0.2077 - val_accuracy: 0.9312\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2060 - accuracy: 0.9309 - val_loss: 0.2118 - val_accuracy: 0.9300\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2064 - accuracy: 0.9306 - val_loss: 0.2102 - val_accuracy: 0.9315\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9314 - val_loss: 0.2069 - val_accuracy: 0.9315\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9306 - val_loss: 0.2075 - val_accuracy: 0.9306\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9313 - val_loss: 0.2068 - val_accuracy: 0.9308\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9311 - val_loss: 0.2087 - val_accuracy: 0.9299\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9314 - val_loss: 0.2070 - val_accuracy: 0.9293\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9310 - val_loss: 0.2085 - val_accuracy: 0.9311\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9316 - val_loss: 0.2120 - val_accuracy: 0.9274\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9314 - val_loss: 0.2086 - val_accuracy: 0.9309\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9315 - val_loss: 0.2096 - val_accuracy: 0.9312\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9316 - val_loss: 0.2082 - val_accuracy: 0.9309\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9310 - val_loss: 0.2087 - val_accuracy: 0.9299\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9312 - val_loss: 0.2098 - val_accuracy: 0.9284\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9315 - val_loss: 0.2101 - val_accuracy: 0.9302\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9315 - val_loss: 0.2082 - val_accuracy: 0.9302\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9315 - val_loss: 0.2107 - val_accuracy: 0.9296\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2036 - accuracy: 0.9316 - val_loss: 0.2084 - val_accuracy: 0.9297\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9317 - val_loss: 0.2084 - val_accuracy: 0.9297\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2312 - accuracy: 0.9282 - val_loss: 0.2176 - val_accuracy: 0.9284\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9294 - val_loss: 0.2138 - val_accuracy: 0.9309\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9304 - val_loss: 0.2110 - val_accuracy: 0.9320\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9304 - val_loss: 0.2127 - val_accuracy: 0.9308\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9296 - val_loss: 0.2138 - val_accuracy: 0.9317\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9307 - val_loss: 0.2181 - val_accuracy: 0.9315\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9307 - val_loss: 0.2198 - val_accuracy: 0.9314\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9314 - val_loss: 0.2098 - val_accuracy: 0.9323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2052 - accuracy: 0.9305 - val_loss: 0.2082 - val_accuracy: 0.9324\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2050 - accuracy: 0.9307 - val_loss: 0.2102 - val_accuracy: 0.9315\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9321 - val_loss: 0.2151 - val_accuracy: 0.9311\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9305 - val_loss: 0.2122 - val_accuracy: 0.9323\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9312 - val_loss: 0.2087 - val_accuracy: 0.9320\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9314 - val_loss: 0.2106 - val_accuracy: 0.9312\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2033 - accuracy: 0.9318 - val_loss: 0.2152 - val_accuracy: 0.9314\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9300 - val_loss: 0.2193 - val_accuracy: 0.9317\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9314 - val_loss: 0.2177 - val_accuracy: 0.9312\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2036 - accuracy: 0.9316 - val_loss: 0.2168 - val_accuracy: 0.9312\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9317 - val_loss: 0.2083 - val_accuracy: 0.9320\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9314 - val_loss: 0.2105 - val_accuracy: 0.9314\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9307 - val_loss: 0.2149 - val_accuracy: 0.9315\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9319 - val_loss: 0.2103 - val_accuracy: 0.9323\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2020 - accuracy: 0.9315 - val_loss: 0.2135 - val_accuracy: 0.9312\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9319 - val_loss: 0.2100 - val_accuracy: 0.9318\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2021 - accuracy: 0.9317 - val_loss: 0.2108 - val_accuracy: 0.9308\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2019 - accuracy: 0.9321 - val_loss: 0.2135 - val_accuracy: 0.9315\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9316 - val_loss: 0.2115 - val_accuracy: 0.9311\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2015 - accuracy: 0.9320 - val_loss: 0.2110 - val_accuracy: 0.9317\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2015 - accuracy: 0.9319 - val_loss: 0.2147 - val_accuracy: 0.9305\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2291 - accuracy: 0.9275 - val_loss: 0.2234 - val_accuracy: 0.9287\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2081 - accuracy: 0.9313 - val_loss: 0.2173 - val_accuracy: 0.9255\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9319 - val_loss: 0.2183 - val_accuracy: 0.9289\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9315 - val_loss: 0.2205 - val_accuracy: 0.9263\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9328 - val_loss: 0.2230 - val_accuracy: 0.9266\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9321 - val_loss: 0.2218 - val_accuracy: 0.9262\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2033 - accuracy: 0.9333 - val_loss: 0.2206 - val_accuracy: 0.9253\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9333 - val_loss: 0.2186 - val_accuracy: 0.9266\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2033 - accuracy: 0.9321 - val_loss: 0.2244 - val_accuracy: 0.9255\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9335 - val_loss: 0.2205 - val_accuracy: 0.9263\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9326 - val_loss: 0.2343 - val_accuracy: 0.9244\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2020 - accuracy: 0.9334 - val_loss: 0.2156 - val_accuracy: 0.9275\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9336 - val_loss: 0.2170 - val_accuracy: 0.9280\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9336 - val_loss: 0.2202 - val_accuracy: 0.9266\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9335 - val_loss: 0.2218 - val_accuracy: 0.9252\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9328 - val_loss: 0.2198 - val_accuracy: 0.9262\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2018 - accuracy: 0.9334 - val_loss: 0.2213 - val_accuracy: 0.9252\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9330 - val_loss: 0.2220 - val_accuracy: 0.9244\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2016 - accuracy: 0.9335 - val_loss: 0.2218 - val_accuracy: 0.9247\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2015 - accuracy: 0.9332 - val_loss: 0.2273 - val_accuracy: 0.9256\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2014 - accuracy: 0.9333 - val_loss: 0.2296 - val_accuracy: 0.9289\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2017 - accuracy: 0.9334 - val_loss: 0.2246 - val_accuracy: 0.9259\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2004 - accuracy: 0.9338 - val_loss: 0.2278 - val_accuracy: 0.9263\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2009 - accuracy: 0.9339 - val_loss: 0.2228 - val_accuracy: 0.9238\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2017 - accuracy: 0.9337 - val_loss: 0.2157 - val_accuracy: 0.9272\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1999 - accuracy: 0.9337 - val_loss: 0.2225 - val_accuracy: 0.9275\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2006 - accuracy: 0.9343 - val_loss: 0.2200 - val_accuracy: 0.9250\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2012 - accuracy: 0.9338 - val_loss: 0.2232 - val_accuracy: 0.9256\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1995 - accuracy: 0.9335 - val_loss: 0.2220 - val_accuracy: 0.9250\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2005 - accuracy: 0.9334 - val_loss: 0.2255 - val_accuracy: 0.9253\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2002 - accuracy: 0.9336 - val_loss: 0.2208 - val_accuracy: 0.9261\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.1998 - accuracy: 0.9335 - val_loss: 0.2237 - val_accuracy: 0.9252\n",
      "logloss: 0.2070\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model1NNproba()\n",
    "pred_train_2_3, pred_test_2_3 = predict_cv(model_2, train_x_2_3, train_y, test_x_2_3)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2_3, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_2_4 = pd.DataFrame({'pred_1c':pred_train_1c,'pred_1d':pred_train_1d})\n",
    "test_x_2_4 = pd.DataFrame({'pred_1c': pred_test_1c,'pred_1d':pred_test_1d,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2504 - accuracy: 0.9263 - val_loss: 0.2003 - val_accuracy: 0.9325\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2132 - accuracy: 0.9284 - val_loss: 0.1990 - val_accuracy: 0.9337\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2123 - accuracy: 0.9304 - val_loss: 0.2024 - val_accuracy: 0.9333\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2114 - accuracy: 0.9303 - val_loss: 0.2000 - val_accuracy: 0.9331\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2115 - accuracy: 0.9303 - val_loss: 0.2001 - val_accuracy: 0.9311\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2113 - accuracy: 0.9294 - val_loss: 0.1989 - val_accuracy: 0.9336\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2112 - accuracy: 0.9300 - val_loss: 0.1986 - val_accuracy: 0.9328\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9303 - val_loss: 0.1999 - val_accuracy: 0.9330\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9302 - val_loss: 0.1997 - val_accuracy: 0.9320\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2110 - accuracy: 0.9303 - val_loss: 0.1996 - val_accuracy: 0.9317\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9305 - val_loss: 0.1996 - val_accuracy: 0.9324\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2108 - accuracy: 0.9302 - val_loss: 0.1989 - val_accuracy: 0.9346\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.9303 - val_loss: 0.1988 - val_accuracy: 0.9348\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2103 - accuracy: 0.9303 - val_loss: 0.2015 - val_accuracy: 0.9340\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9299 - val_loss: 0.2016 - val_accuracy: 0.9324\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2110 - accuracy: 0.9312 - val_loss: 0.1983 - val_accuracy: 0.9331\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2103 - accuracy: 0.9308 - val_loss: 0.1978 - val_accuracy: 0.9342\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9303 - val_loss: 0.2018 - val_accuracy: 0.9323\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9311 - val_loss: 0.1998 - val_accuracy: 0.9325\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2108 - accuracy: 0.9309 - val_loss: 0.1988 - val_accuracy: 0.9345\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9305 - val_loss: 0.1982 - val_accuracy: 0.9323\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2101 - accuracy: 0.9308 - val_loss: 0.1978 - val_accuracy: 0.9340\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9305 - val_loss: 0.1980 - val_accuracy: 0.9346\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2103 - accuracy: 0.9300 - val_loss: 0.1988 - val_accuracy: 0.9337\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2100 - accuracy: 0.9304 - val_loss: 0.1985 - val_accuracy: 0.9321\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9307 - val_loss: 0.2009 - val_accuracy: 0.9325\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9302 - val_loss: 0.1984 - val_accuracy: 0.9330\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2104 - accuracy: 0.9308 - val_loss: 0.1978 - val_accuracy: 0.9334\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9304 - val_loss: 0.1998 - val_accuracy: 0.9318\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9311 - val_loss: 0.1989 - val_accuracy: 0.9342\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9311 - val_loss: 0.1972 - val_accuracy: 0.9328\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9307 - val_loss: 0.1999 - val_accuracy: 0.9318\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2099 - accuracy: 0.9304 - val_loss: 0.1996 - val_accuracy: 0.9317\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9307 - val_loss: 0.1984 - val_accuracy: 0.9333\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9307 - val_loss: 0.1972 - val_accuracy: 0.9340\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9307 - val_loss: 0.1986 - val_accuracy: 0.9321\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9308 - val_loss: 0.1984 - val_accuracy: 0.9348\n",
      "Epoch 38/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9307 - val_loss: 0.1985 - val_accuracy: 0.9327\n",
      "Epoch 39/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9307 - val_loss: 0.1987 - val_accuracy: 0.9339\n",
      "Epoch 40/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9309 - val_loss: 0.1982 - val_accuracy: 0.9336\n",
      "Epoch 41/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2099 - accuracy: 0.9303 - val_loss: 0.1990 - val_accuracy: 0.9337\n",
      "Epoch 42/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9302 - val_loss: 0.1980 - val_accuracy: 0.9331\n",
      "Epoch 43/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9307 - val_loss: 0.1985 - val_accuracy: 0.9339\n",
      "Epoch 44/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9305 - val_loss: 0.1990 - val_accuracy: 0.9340\n",
      "Epoch 45/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9307 - val_loss: 0.1983 - val_accuracy: 0.9331\n",
      "Epoch 46/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9307 - val_loss: 0.1983 - val_accuracy: 0.9325\n",
      "Epoch 47/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9305 - val_loss: 0.1982 - val_accuracy: 0.9340\n",
      "Epoch 48/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9309 - val_loss: 0.1980 - val_accuracy: 0.9323\n",
      "Epoch 49/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9310 - val_loss: 0.1982 - val_accuracy: 0.9336\n",
      "Epoch 50/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2100 - accuracy: 0.9307 - val_loss: 0.1979 - val_accuracy: 0.9333\n",
      "Epoch 51/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9306 - val_loss: 0.1989 - val_accuracy: 0.9330\n",
      "Epoch 52/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9312 - val_loss: 0.1979 - val_accuracy: 0.9337\n",
      "Epoch 53/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9302 - val_loss: 0.1973 - val_accuracy: 0.9348\n",
      "Epoch 54/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9308 - val_loss: 0.1981 - val_accuracy: 0.9331\n",
      "Epoch 55/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9306 - val_loss: 0.1985 - val_accuracy: 0.9333\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2465 - accuracy: 0.9254 - val_loss: 0.2099 - val_accuracy: 0.9306\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9295 - val_loss: 0.2081 - val_accuracy: 0.9312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9302 - val_loss: 0.2056 - val_accuracy: 0.9325\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9301 - val_loss: 0.2070 - val_accuracy: 0.9318\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9303 - val_loss: 0.2080 - val_accuracy: 0.9320\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9311 - val_loss: 0.2082 - val_accuracy: 0.9321\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9305 - val_loss: 0.2054 - val_accuracy: 0.9323\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9308 - val_loss: 0.2062 - val_accuracy: 0.9318\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9314 - val_loss: 0.2064 - val_accuracy: 0.9312\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9305 - val_loss: 0.2062 - val_accuracy: 0.9318\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9308 - val_loss: 0.2063 - val_accuracy: 0.9327\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9305 - val_loss: 0.2054 - val_accuracy: 0.9333\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9311 - val_loss: 0.2056 - val_accuracy: 0.9330\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2081 - accuracy: 0.9306 - val_loss: 0.2055 - val_accuracy: 0.9331\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9309 - val_loss: 0.2057 - val_accuracy: 0.9327\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9311 - val_loss: 0.2058 - val_accuracy: 0.9333\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9306 - val_loss: 0.2068 - val_accuracy: 0.9325\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9308 - val_loss: 0.2047 - val_accuracy: 0.9330\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9311 - val_loss: 0.2049 - val_accuracy: 0.9321\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9312 - val_loss: 0.2089 - val_accuracy: 0.9330\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9315 - val_loss: 0.2047 - val_accuracy: 0.9318\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9315 - val_loss: 0.2042 - val_accuracy: 0.9314\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9307 - val_loss: 0.2059 - val_accuracy: 0.9314\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9310 - val_loss: 0.2069 - val_accuracy: 0.9324\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9316 - val_loss: 0.2064 - val_accuracy: 0.9327\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9309 - val_loss: 0.2056 - val_accuracy: 0.9317\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9312 - val_loss: 0.2077 - val_accuracy: 0.9323\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9308 - val_loss: 0.2050 - val_accuracy: 0.9328\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9313 - val_loss: 0.2063 - val_accuracy: 0.9317\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9312 - val_loss: 0.2048 - val_accuracy: 0.9333\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9312 - val_loss: 0.2049 - val_accuracy: 0.9328\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9308 - val_loss: 0.2046 - val_accuracy: 0.9328\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9309 - val_loss: 0.2046 - val_accuracy: 0.9333\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9310 - val_loss: 0.2045 - val_accuracy: 0.9331\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9305 - val_loss: 0.2045 - val_accuracy: 0.9317\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9311 - val_loss: 0.2041 - val_accuracy: 0.9324\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9318 - val_loss: 0.2044 - val_accuracy: 0.9320\n",
      "Epoch 38/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9311 - val_loss: 0.2042 - val_accuracy: 0.9317\n",
      "Epoch 39/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9309 - val_loss: 0.2055 - val_accuracy: 0.9323\n",
      "Epoch 40/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9313 - val_loss: 0.2044 - val_accuracy: 0.9317\n",
      "Epoch 41/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9310 - val_loss: 0.2038 - val_accuracy: 0.9331\n",
      "Epoch 42/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9311 - val_loss: 0.2046 - val_accuracy: 0.9314\n",
      "Epoch 43/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9313 - val_loss: 0.2040 - val_accuracy: 0.9321\n",
      "Epoch 44/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9307 - val_loss: 0.2046 - val_accuracy: 0.9317\n",
      "Epoch 45/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9311 - val_loss: 0.2038 - val_accuracy: 0.9330\n",
      "Epoch 46/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9312 - val_loss: 0.2055 - val_accuracy: 0.9323\n",
      "Epoch 47/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9311 - val_loss: 0.2050 - val_accuracy: 0.9323\n",
      "Epoch 48/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9310 - val_loss: 0.2042 - val_accuracy: 0.9328\n",
      "Epoch 49/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9314 - val_loss: 0.2044 - val_accuracy: 0.9331\n",
      "Epoch 50/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9311 - val_loss: 0.2043 - val_accuracy: 0.9321\n",
      "Epoch 51/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9314 - val_loss: 0.2056 - val_accuracy: 0.9331\n",
      "Epoch 52/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9310 - val_loss: 0.2045 - val_accuracy: 0.9324\n",
      "Epoch 53/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9311 - val_loss: 0.2043 - val_accuracy: 0.9320\n",
      "Epoch 54/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2074 - accuracy: 0.9315 - val_loss: 0.2053 - val_accuracy: 0.9324\n",
      "Epoch 55/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9308 - val_loss: 0.2092 - val_accuracy: 0.9323\n",
      "Epoch 56/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9312 - val_loss: 0.2045 - val_accuracy: 0.9323\n",
      "Epoch 57/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9315 - val_loss: 0.2054 - val_accuracy: 0.9323\n",
      "Epoch 58/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9313 - val_loss: 0.2041 - val_accuracy: 0.9328\n",
      "Epoch 59/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9316 - val_loss: 0.2043 - val_accuracy: 0.9323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9310 - val_loss: 0.2041 - val_accuracy: 0.9330\n",
      "Epoch 61/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9315 - val_loss: 0.2041 - val_accuracy: 0.9328\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2485 - accuracy: 0.9244 - val_loss: 0.2118 - val_accuracy: 0.9317\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9298 - val_loss: 0.2148 - val_accuracy: 0.9299\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9303 - val_loss: 0.2103 - val_accuracy: 0.9305\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9303 - val_loss: 0.2130 - val_accuracy: 0.9318\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9306 - val_loss: 0.2102 - val_accuracy: 0.9309\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9304 - val_loss: 0.2111 - val_accuracy: 0.9315\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9307 - val_loss: 0.2104 - val_accuracy: 0.9315\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9311 - val_loss: 0.2089 - val_accuracy: 0.9324\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9314 - val_loss: 0.2101 - val_accuracy: 0.9321\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9324 - val_loss: 0.2102 - val_accuracy: 0.9315\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9317 - val_loss: 0.2148 - val_accuracy: 0.9317\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9318 - val_loss: 0.2105 - val_accuracy: 0.9323\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9318 - val_loss: 0.2086 - val_accuracy: 0.9318\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9315 - val_loss: 0.2102 - val_accuracy: 0.9317\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9313 - val_loss: 0.2101 - val_accuracy: 0.9321\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9308 - val_loss: 0.2131 - val_accuracy: 0.9318\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2064 - accuracy: 0.9317 - val_loss: 0.2146 - val_accuracy: 0.9327\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9319 - val_loss: 0.2104 - val_accuracy: 0.9320\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9317 - val_loss: 0.2099 - val_accuracy: 0.9318\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9316 - val_loss: 0.2097 - val_accuracy: 0.9314\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9316 - val_loss: 0.2169 - val_accuracy: 0.9318\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9315 - val_loss: 0.2129 - val_accuracy: 0.9315\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9318 - val_loss: 0.2112 - val_accuracy: 0.9320\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9316 - val_loss: 0.2088 - val_accuracy: 0.9317\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9314 - val_loss: 0.2122 - val_accuracy: 0.9321\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9318 - val_loss: 0.2098 - val_accuracy: 0.9311\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9314 - val_loss: 0.2101 - val_accuracy: 0.9321\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9316 - val_loss: 0.2091 - val_accuracy: 0.9317\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9311 - val_loss: 0.2116 - val_accuracy: 0.9318\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9313 - val_loss: 0.2114 - val_accuracy: 0.9311\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9317 - val_loss: 0.2091 - val_accuracy: 0.9321\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9315 - val_loss: 0.2107 - val_accuracy: 0.9315\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9318 - val_loss: 0.2112 - val_accuracy: 0.9314\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2453 - accuracy: 0.9277 - val_loss: 0.2218 - val_accuracy: 0.9262\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9317 - val_loss: 0.2204 - val_accuracy: 0.9277\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9318 - val_loss: 0.2161 - val_accuracy: 0.9284\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2049 - accuracy: 0.9320 - val_loss: 0.2170 - val_accuracy: 0.9283\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9322 - val_loss: 0.2171 - val_accuracy: 0.9275\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9315 - val_loss: 0.2216 - val_accuracy: 0.9283\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9328 - val_loss: 0.2230 - val_accuracy: 0.9286\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9320 - val_loss: 0.2189 - val_accuracy: 0.9277\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9323 - val_loss: 0.2192 - val_accuracy: 0.9280\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9318 - val_loss: 0.2143 - val_accuracy: 0.9271\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9327 - val_loss: 0.2210 - val_accuracy: 0.9275\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9330 - val_loss: 0.2203 - val_accuracy: 0.9286\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9330 - val_loss: 0.2151 - val_accuracy: 0.9275\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9320 - val_loss: 0.2237 - val_accuracy: 0.9272\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9324 - val_loss: 0.2166 - val_accuracy: 0.9272\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9325 - val_loss: 0.2201 - val_accuracy: 0.9274\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9328 - val_loss: 0.2250 - val_accuracy: 0.9272\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9330 - val_loss: 0.2205 - val_accuracy: 0.9277\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2036 - accuracy: 0.9333 - val_loss: 0.2276 - val_accuracy: 0.9271\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9328 - val_loss: 0.2228 - val_accuracy: 0.9274\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2031 - accuracy: 0.9325 - val_loss: 0.2195 - val_accuracy: 0.9269\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9327 - val_loss: 0.2138 - val_accuracy: 0.9272\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9333 - val_loss: 0.2208 - val_accuracy: 0.9277\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2030 - accuracy: 0.9333 - val_loss: 0.2192 - val_accuracy: 0.9277\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9328 - val_loss: 0.2214 - val_accuracy: 0.9271\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9329 - val_loss: 0.2279 - val_accuracy: 0.9258\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2033 - accuracy: 0.9328 - val_loss: 0.2231 - val_accuracy: 0.9277\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9330 - val_loss: 0.2151 - val_accuracy: 0.9275\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2030 - accuracy: 0.9338 - val_loss: 0.2220 - val_accuracy: 0.9275\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9330 - val_loss: 0.2169 - val_accuracy: 0.9274\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9330 - val_loss: 0.2206 - val_accuracy: 0.9277\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9328 - val_loss: 0.2229 - val_accuracy: 0.9278\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9331 - val_loss: 0.2290 - val_accuracy: 0.9272\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2030 - accuracy: 0.9332 - val_loss: 0.2252 - val_accuracy: 0.9269\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2031 - accuracy: 0.9329 - val_loss: 0.2197 - val_accuracy: 0.9275\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9331 - val_loss: 0.2247 - val_accuracy: 0.9277\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9331 - val_loss: 0.2245 - val_accuracy: 0.9272\n",
      "Epoch 38/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2033 - accuracy: 0.9327 - val_loss: 0.2202 - val_accuracy: 0.9277\n",
      "Epoch 39/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2031 - accuracy: 0.9327 - val_loss: 0.2214 - val_accuracy: 0.9259\n",
      "Epoch 40/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2028 - accuracy: 0.9331 - val_loss: 0.2225 - val_accuracy: 0.9277\n",
      "Epoch 41/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9324 - val_loss: 0.2267 - val_accuracy: 0.9259\n",
      "Epoch 42/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9319 - val_loss: 0.2257 - val_accuracy: 0.9272\n",
      "logloss: 0.2058\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model1NNproba()\n",
    "pred_train_2_4, pred_test_2_4 = predict_cv(model_2, train_x_2_4, train_y, test_x_2_4)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2_4, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.2108\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model3logistic()\n",
    "pred_train_2_4, pred_test_2_4 = predict_cv(model_2, train_x_2_4, train_y, test_x_2_4)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2_4, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_2_5 = pd.DataFrame({'pred_1a': pred_train_1a, 'pred_1b': pred_train_1b, 'pred_1c':pred_train_1c,'pred_1d':pred_train_1d,})\n",
    "test_x_2_5 = pd.DataFrame({'pred_1a': preds_test_1a, 'pred_1b': preds_test_1b, 'pred_1c': pred_test_1c,'pred_1d':pred_test_1d})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2385 - accuracy: 0.9271 - val_loss: 0.1995 - val_accuracy: 0.9348\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2128 - accuracy: 0.9292 - val_loss: 0.1993 - val_accuracy: 0.9325\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2113 - accuracy: 0.9308 - val_loss: 0.2026 - val_accuracy: 0.9303\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2113 - accuracy: 0.9305 - val_loss: 0.2014 - val_accuracy: 0.9311\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2112 - accuracy: 0.9307 - val_loss: 0.2026 - val_accuracy: 0.9312\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2103 - accuracy: 0.9302 - val_loss: 0.2015 - val_accuracy: 0.9334\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2113 - accuracy: 0.9299 - val_loss: 0.2022 - val_accuracy: 0.9339\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.9304 - val_loss: 0.2000 - val_accuracy: 0.9324\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.9309 - val_loss: 0.2004 - val_accuracy: 0.9308\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2108 - accuracy: 0.9304 - val_loss: 0.1994 - val_accuracy: 0.9328\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9308 - val_loss: 0.1997 - val_accuracy: 0.9330\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9306 - val_loss: 0.1992 - val_accuracy: 0.9337\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2104 - accuracy: 0.9312 - val_loss: 0.1996 - val_accuracy: 0.9343\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2103 - accuracy: 0.9310 - val_loss: 0.2003 - val_accuracy: 0.9342\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9300 - val_loss: 0.1995 - val_accuracy: 0.9321\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2099 - accuracy: 0.9305 - val_loss: 0.1999 - val_accuracy: 0.9327\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9309 - val_loss: 0.2021 - val_accuracy: 0.9321\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9315 - val_loss: 0.2025 - val_accuracy: 0.9336\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9294 - val_loss: 0.2002 - val_accuracy: 0.9320\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2104 - accuracy: 0.9303 - val_loss: 0.1996 - val_accuracy: 0.9343\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9305 - val_loss: 0.2017 - val_accuracy: 0.9328\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9308 - val_loss: 0.1986 - val_accuracy: 0.9320\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9313 - val_loss: 0.1994 - val_accuracy: 0.9324\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9308 - val_loss: 0.1990 - val_accuracy: 0.9331\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9313 - val_loss: 0.2014 - val_accuracy: 0.9334\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9318 - val_loss: 0.1994 - val_accuracy: 0.9324\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9306 - val_loss: 0.2001 - val_accuracy: 0.9333\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2099 - accuracy: 0.9303 - val_loss: 0.1982 - val_accuracy: 0.9324\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9311 - val_loss: 0.2005 - val_accuracy: 0.9342\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9312 - val_loss: 0.1993 - val_accuracy: 0.9325\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9315 - val_loss: 0.1995 - val_accuracy: 0.9331\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9308 - val_loss: 0.1996 - val_accuracy: 0.9321\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9306 - val_loss: 0.1989 - val_accuracy: 0.9321\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9309 - val_loss: 0.1990 - val_accuracy: 0.9339\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9310 - val_loss: 0.2002 - val_accuracy: 0.9321\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9312 - val_loss: 0.1984 - val_accuracy: 0.9343\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9313 - val_loss: 0.2013 - val_accuracy: 0.9325\n",
      "Epoch 38/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9313 - val_loss: 0.1998 - val_accuracy: 0.9317\n",
      "Epoch 39/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9311 - val_loss: 0.1992 - val_accuracy: 0.9340\n",
      "Epoch 40/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9306 - val_loss: 0.2013 - val_accuracy: 0.9321\n",
      "Epoch 41/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9311 - val_loss: 0.1986 - val_accuracy: 0.9343\n",
      "Epoch 42/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9311 - val_loss: 0.1981 - val_accuracy: 0.9330\n",
      "Epoch 43/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9315 - val_loss: 0.1990 - val_accuracy: 0.9342\n",
      "Epoch 44/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9310 - val_loss: 0.1981 - val_accuracy: 0.9345\n",
      "Epoch 45/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9309 - val_loss: 0.1989 - val_accuracy: 0.9325\n",
      "Epoch 46/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9300 - val_loss: 0.1992 - val_accuracy: 0.9321\n",
      "Epoch 47/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9308 - val_loss: 0.1994 - val_accuracy: 0.9336\n",
      "Epoch 48/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9312 - val_loss: 0.2014 - val_accuracy: 0.9324\n",
      "Epoch 49/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9314 - val_loss: 0.1993 - val_accuracy: 0.9330\n",
      "Epoch 50/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9311 - val_loss: 0.1999 - val_accuracy: 0.9330\n",
      "Epoch 51/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9307 - val_loss: 0.1989 - val_accuracy: 0.9337\n",
      "Epoch 52/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9311 - val_loss: 0.2004 - val_accuracy: 0.9343\n",
      "Epoch 53/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9311 - val_loss: 0.1983 - val_accuracy: 0.9343\n",
      "Epoch 54/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9310 - val_loss: 0.1989 - val_accuracy: 0.9336\n",
      "Epoch 55/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9308 - val_loss: 0.2009 - val_accuracy: 0.9339\n",
      "Epoch 56/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9311 - val_loss: 0.2034 - val_accuracy: 0.9339\n",
      "Epoch 57/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9310 - val_loss: 0.1994 - val_accuracy: 0.9336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9304 - val_loss: 0.2013 - val_accuracy: 0.9323\n",
      "Epoch 59/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9309 - val_loss: 0.1996 - val_accuracy: 0.9328\n",
      "Epoch 60/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9307 - val_loss: 0.2006 - val_accuracy: 0.9333\n",
      "Epoch 61/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9313 - val_loss: 0.1993 - val_accuracy: 0.9343\n",
      "Epoch 62/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9315 - val_loss: 0.1999 - val_accuracy: 0.9327\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2355 - accuracy: 0.9275 - val_loss: 0.2116 - val_accuracy: 0.9268\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2100 - accuracy: 0.9295 - val_loss: 0.2075 - val_accuracy: 0.9317\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9305 - val_loss: 0.2064 - val_accuracy: 0.9303\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9302 - val_loss: 0.2081 - val_accuracy: 0.9321\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9306 - val_loss: 0.2098 - val_accuracy: 0.9323\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9307 - val_loss: 0.2053 - val_accuracy: 0.9334\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9305 - val_loss: 0.2058 - val_accuracy: 0.9320\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9305 - val_loss: 0.2094 - val_accuracy: 0.9311\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9311 - val_loss: 0.2061 - val_accuracy: 0.9323\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9307 - val_loss: 0.2057 - val_accuracy: 0.9323\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2081 - accuracy: 0.9304 - val_loss: 0.2063 - val_accuracy: 0.9318\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9306 - val_loss: 0.2056 - val_accuracy: 0.9321\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9310 - val_loss: 0.2056 - val_accuracy: 0.9323\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9311 - val_loss: 0.2071 - val_accuracy: 0.9327\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9311 - val_loss: 0.2062 - val_accuracy: 0.9324\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9308 - val_loss: 0.2078 - val_accuracy: 0.9321\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9311 - val_loss: 0.2050 - val_accuracy: 0.9320\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9307 - val_loss: 0.2067 - val_accuracy: 0.9299\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9310 - val_loss: 0.2065 - val_accuracy: 0.9321\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2081 - accuracy: 0.9308 - val_loss: 0.2062 - val_accuracy: 0.9317\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9309 - val_loss: 0.2085 - val_accuracy: 0.9320\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9307 - val_loss: 0.2068 - val_accuracy: 0.9325\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9314 - val_loss: 0.2053 - val_accuracy: 0.9321\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9310 - val_loss: 0.2088 - val_accuracy: 0.9317\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9310 - val_loss: 0.2055 - val_accuracy: 0.9321\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9311 - val_loss: 0.2065 - val_accuracy: 0.9321\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9306 - val_loss: 0.2074 - val_accuracy: 0.9318\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9313 - val_loss: 0.2076 - val_accuracy: 0.9321\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9314 - val_loss: 0.2057 - val_accuracy: 0.9325\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9311 - val_loss: 0.2073 - val_accuracy: 0.9323\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9313 - val_loss: 0.2064 - val_accuracy: 0.9327\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9314 - val_loss: 0.2072 - val_accuracy: 0.9320\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9309 - val_loss: 0.2057 - val_accuracy: 0.9317\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9312 - val_loss: 0.2061 - val_accuracy: 0.9318\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9309 - val_loss: 0.2055 - val_accuracy: 0.9324\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9306 - val_loss: 0.2087 - val_accuracy: 0.9317\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9311 - val_loss: 0.2067 - val_accuracy: 0.9330\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2324 - accuracy: 0.9274 - val_loss: 0.2145 - val_accuracy: 0.9312\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2091 - accuracy: 0.9301 - val_loss: 0.2118 - val_accuracy: 0.9312\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9306 - val_loss: 0.2174 - val_accuracy: 0.9283\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9305 - val_loss: 0.2158 - val_accuracy: 0.9318\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9311 - val_loss: 0.2113 - val_accuracy: 0.9314\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9307 - val_loss: 0.2152 - val_accuracy: 0.9318\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9311 - val_loss: 0.2125 - val_accuracy: 0.9306\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9314 - val_loss: 0.2117 - val_accuracy: 0.9317\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9312 - val_loss: 0.2164 - val_accuracy: 0.9293\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9317 - val_loss: 0.2106 - val_accuracy: 0.9317\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9314 - val_loss: 0.2121 - val_accuracy: 0.9314\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9317 - val_loss: 0.2117 - val_accuracy: 0.9311\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9317 - val_loss: 0.2117 - val_accuracy: 0.9311\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9315 - val_loss: 0.2101 - val_accuracy: 0.9314\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9309 - val_loss: 0.2102 - val_accuracy: 0.9314\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9310 - val_loss: 0.2101 - val_accuracy: 0.9318\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9316 - val_loss: 0.2095 - val_accuracy: 0.9323\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9313 - val_loss: 0.2121 - val_accuracy: 0.9303\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9315 - val_loss: 0.2137 - val_accuracy: 0.9317\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9314 - val_loss: 0.2099 - val_accuracy: 0.9315\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9316 - val_loss: 0.2120 - val_accuracy: 0.9318\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9321 - val_loss: 0.2105 - val_accuracy: 0.9314\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9316 - val_loss: 0.2107 - val_accuracy: 0.9311\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9319 - val_loss: 0.2108 - val_accuracy: 0.9312\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9318 - val_loss: 0.2101 - val_accuracy: 0.9314\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9320 - val_loss: 0.2148 - val_accuracy: 0.9311\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9315 - val_loss: 0.2119 - val_accuracy: 0.9323\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9318 - val_loss: 0.2159 - val_accuracy: 0.9308\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9315 - val_loss: 0.2096 - val_accuracy: 0.9315\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9314 - val_loss: 0.2152 - val_accuracy: 0.9320\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9317 - val_loss: 0.2104 - val_accuracy: 0.9323\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9319 - val_loss: 0.2140 - val_accuracy: 0.9320\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9317 - val_loss: 0.2132 - val_accuracy: 0.9312\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9319 - val_loss: 0.2113 - val_accuracy: 0.9314\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9312 - val_loss: 0.2128 - val_accuracy: 0.9315\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9318 - val_loss: 0.2119 - val_accuracy: 0.9315\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9319 - val_loss: 0.2180 - val_accuracy: 0.9320\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2345 - accuracy: 0.9254 - val_loss: 0.2189 - val_accuracy: 0.9280\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9314 - val_loss: 0.2181 - val_accuracy: 0.9278\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9325 - val_loss: 0.2232 - val_accuracy: 0.9271\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9318 - val_loss: 0.2197 - val_accuracy: 0.9281\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9322 - val_loss: 0.2211 - val_accuracy: 0.9284\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9330 - val_loss: 0.2219 - val_accuracy: 0.9272\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9320 - val_loss: 0.2179 - val_accuracy: 0.9269\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9331 - val_loss: 0.2216 - val_accuracy: 0.9253\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9327 - val_loss: 0.2202 - val_accuracy: 0.9275\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2041 - accuracy: 0.9331 - val_loss: 0.2173 - val_accuracy: 0.9272\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9329 - val_loss: 0.2203 - val_accuracy: 0.9281\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9326 - val_loss: 0.2202 - val_accuracy: 0.9277\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9328 - val_loss: 0.2175 - val_accuracy: 0.9272\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9334 - val_loss: 0.2196 - val_accuracy: 0.9261\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9330 - val_loss: 0.2181 - val_accuracy: 0.9275\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9331 - val_loss: 0.2205 - val_accuracy: 0.9277\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9328 - val_loss: 0.2252 - val_accuracy: 0.9284\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2041 - accuracy: 0.9330 - val_loss: 0.2216 - val_accuracy: 0.9258\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9328 - val_loss: 0.2219 - val_accuracy: 0.9274\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9325 - val_loss: 0.2234 - val_accuracy: 0.9272\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9334 - val_loss: 0.2210 - val_accuracy: 0.9275\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9331 - val_loss: 0.2211 - val_accuracy: 0.9278\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9329 - val_loss: 0.2205 - val_accuracy: 0.9259\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2033 - accuracy: 0.9327 - val_loss: 0.2255 - val_accuracy: 0.9284\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2031 - accuracy: 0.9324 - val_loss: 0.2197 - val_accuracy: 0.9275\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9324 - val_loss: 0.2219 - val_accuracy: 0.9272\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9336 - val_loss: 0.2202 - val_accuracy: 0.9269\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9335 - val_loss: 0.2263 - val_accuracy: 0.9281\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9335 - val_loss: 0.2297 - val_accuracy: 0.9274\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9335 - val_loss: 0.2181 - val_accuracy: 0.9278\n",
      "logloss: 0.2075\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model1NNproba()\n",
    "pred_train_2_5, pred_test_2_5 = predict_cv(model_2, train_x_2_5, train_y, test_x_2_5)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2_5, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_2_6 = pd.DataFrame({'pred_1a': pred_train_1a, 'pred_1b': pred_train_1b, 'pred_1c':pred_train_1c,'pred_1d':pred_train_1d,'pred_1h':pred_train_1h})\n",
    "test_x_2_6 = pd.DataFrame({'pred_1a': preds_test_1a, 'pred_1b': preds_test_1b, 'pred_1c': pred_test_1c,'pred_1d':pred_test_1d, 'pred_1h':preds_test_1h})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2384 - accuracy: 0.9244 - val_loss: 0.1999 - val_accuracy: 0.9320\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.9297 - val_loss: 0.2022 - val_accuracy: 0.9340\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2121 - accuracy: 0.9298 - val_loss: 0.2003 - val_accuracy: 0.9327\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2119 - accuracy: 0.9296 - val_loss: 0.2002 - val_accuracy: 0.9327\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9308 - val_loss: 0.2026 - val_accuracy: 0.9321\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.9314 - val_loss: 0.2006 - val_accuracy: 0.9311\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2109 - accuracy: 0.9306 - val_loss: 0.2013 - val_accuracy: 0.9315\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9302 - val_loss: 0.2013 - val_accuracy: 0.9320\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9307 - val_loss: 0.2004 - val_accuracy: 0.9309\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2109 - accuracy: 0.9308 - val_loss: 0.1997 - val_accuracy: 0.9323\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2108 - accuracy: 0.9305 - val_loss: 0.1994 - val_accuracy: 0.9320\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2091 - accuracy: 0.9307 - val_loss: 0.2053 - val_accuracy: 0.9323\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2099 - accuracy: 0.9310 - val_loss: 0.2012 - val_accuracy: 0.9336\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9308 - val_loss: 0.2022 - val_accuracy: 0.9321\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2101 - accuracy: 0.9306 - val_loss: 0.2019 - val_accuracy: 0.9318\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9310 - val_loss: 0.1990 - val_accuracy: 0.9315\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9311 - val_loss: 0.2010 - val_accuracy: 0.9342\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9310 - val_loss: 0.1990 - val_accuracy: 0.9334\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9306 - val_loss: 0.2012 - val_accuracy: 0.9333\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9307 - val_loss: 0.2053 - val_accuracy: 0.9333\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2101 - accuracy: 0.9307 - val_loss: 0.1990 - val_accuracy: 0.9333\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2103 - accuracy: 0.9310 - val_loss: 0.2001 - val_accuracy: 0.9339\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9312 - val_loss: 0.2006 - val_accuracy: 0.9321\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9314 - val_loss: 0.2016 - val_accuracy: 0.9337\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9301 - val_loss: 0.1990 - val_accuracy: 0.9334\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9308 - val_loss: 0.2009 - val_accuracy: 0.9333\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9308 - val_loss: 0.1993 - val_accuracy: 0.9330\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9305 - val_loss: 0.1988 - val_accuracy: 0.9328\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9313 - val_loss: 0.2050 - val_accuracy: 0.9317\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9313 - val_loss: 0.2006 - val_accuracy: 0.9320\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9307 - val_loss: 0.2004 - val_accuracy: 0.9342\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9303 - val_loss: 0.2044 - val_accuracy: 0.9333\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9310 - val_loss: 0.1999 - val_accuracy: 0.9339\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9308 - val_loss: 0.2015 - val_accuracy: 0.9323\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9311 - val_loss: 0.1994 - val_accuracy: 0.9331\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9307 - val_loss: 0.2023 - val_accuracy: 0.9327\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9312 - val_loss: 0.1992 - val_accuracy: 0.9336\n",
      "Epoch 38/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9308 - val_loss: 0.2017 - val_accuracy: 0.9320\n",
      "Epoch 39/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9312 - val_loss: 0.2017 - val_accuracy: 0.9318\n",
      "Epoch 40/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9318 - val_loss: 0.2027 - val_accuracy: 0.9342\n",
      "Epoch 41/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9312 - val_loss: 0.2015 - val_accuracy: 0.9328\n",
      "Epoch 42/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9314 - val_loss: 0.2006 - val_accuracy: 0.9333\n",
      "Epoch 43/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9312 - val_loss: 0.1996 - val_accuracy: 0.9325\n",
      "Epoch 44/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9305 - val_loss: 0.2004 - val_accuracy: 0.9318\n",
      "Epoch 45/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9309 - val_loss: 0.2017 - val_accuracy: 0.9345\n",
      "Epoch 46/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9309 - val_loss: 0.1993 - val_accuracy: 0.9339\n",
      "Epoch 47/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2081 - accuracy: 0.9310 - val_loss: 0.2030 - val_accuracy: 0.9345\n",
      "Epoch 48/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9311 - val_loss: 0.2014 - val_accuracy: 0.9340\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2368 - accuracy: 0.9270 - val_loss: 0.2101 - val_accuracy: 0.9299\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9292 - val_loss: 0.2079 - val_accuracy: 0.9306\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9304 - val_loss: 0.2076 - val_accuracy: 0.9305\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2100 - accuracy: 0.9295 - val_loss: 0.2075 - val_accuracy: 0.9323\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9307 - val_loss: 0.2087 - val_accuracy: 0.9278\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9310 - val_loss: 0.2058 - val_accuracy: 0.9315\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9312 - val_loss: 0.2141 - val_accuracy: 0.9312\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9310 - val_loss: 0.2080 - val_accuracy: 0.9306\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9303 - val_loss: 0.2087 - val_accuracy: 0.9314\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2081 - accuracy: 0.9308 - val_loss: 0.2077 - val_accuracy: 0.9314\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9314 - val_loss: 0.2057 - val_accuracy: 0.9318\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9305 - val_loss: 0.2095 - val_accuracy: 0.9312\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9306 - val_loss: 0.2086 - val_accuracy: 0.9311\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9306 - val_loss: 0.2150 - val_accuracy: 0.9300\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9312 - val_loss: 0.2085 - val_accuracy: 0.9305\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9307 - val_loss: 0.2067 - val_accuracy: 0.9317\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9309 - val_loss: 0.2112 - val_accuracy: 0.9299\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9310 - val_loss: 0.2055 - val_accuracy: 0.9309\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9310 - val_loss: 0.2073 - val_accuracy: 0.9302\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9308 - val_loss: 0.2103 - val_accuracy: 0.9320\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9308 - val_loss: 0.2078 - val_accuracy: 0.9320\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9302 - val_loss: 0.2072 - val_accuracy: 0.9303\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9316 - val_loss: 0.2073 - val_accuracy: 0.9308\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9304 - val_loss: 0.2064 - val_accuracy: 0.9315\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9310 - val_loss: 0.2104 - val_accuracy: 0.9314\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9299 - val_loss: 0.2063 - val_accuracy: 0.9306\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9310 - val_loss: 0.2072 - val_accuracy: 0.9287\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9310 - val_loss: 0.2070 - val_accuracy: 0.9314\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9316 - val_loss: 0.2079 - val_accuracy: 0.9315\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9309 - val_loss: 0.2106 - val_accuracy: 0.9314\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9315 - val_loss: 0.2077 - val_accuracy: 0.9311\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9314 - val_loss: 0.2069 - val_accuracy: 0.9324\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9312 - val_loss: 0.2088 - val_accuracy: 0.9303\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9314 - val_loss: 0.2089 - val_accuracy: 0.9325\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9312 - val_loss: 0.2101 - val_accuracy: 0.9314\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9317 - val_loss: 0.2085 - val_accuracy: 0.9320\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9316 - val_loss: 0.2062 - val_accuracy: 0.9309\n",
      "Epoch 38/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9302 - val_loss: 0.2090 - val_accuracy: 0.9321\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2346 - accuracy: 0.9269 - val_loss: 0.2121 - val_accuracy: 0.9311\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9305 - val_loss: 0.2127 - val_accuracy: 0.9314\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9304 - val_loss: 0.2099 - val_accuracy: 0.9323\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9309 - val_loss: 0.2190 - val_accuracy: 0.9286\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9302 - val_loss: 0.2143 - val_accuracy: 0.9315\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9305 - val_loss: 0.2135 - val_accuracy: 0.9314\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9308 - val_loss: 0.2189 - val_accuracy: 0.9314\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9308 - val_loss: 0.2104 - val_accuracy: 0.9317\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9307 - val_loss: 0.2125 - val_accuracy: 0.9317\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9305 - val_loss: 0.2113 - val_accuracy: 0.9299\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9306 - val_loss: 0.2137 - val_accuracy: 0.9315\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9314 - val_loss: 0.2154 - val_accuracy: 0.9306\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9310 - val_loss: 0.2130 - val_accuracy: 0.9315\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9309 - val_loss: 0.2137 - val_accuracy: 0.9314\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9319 - val_loss: 0.2104 - val_accuracy: 0.9321\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9315 - val_loss: 0.2118 - val_accuracy: 0.9318\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9316 - val_loss: 0.2150 - val_accuracy: 0.9317\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9314 - val_loss: 0.2128 - val_accuracy: 0.9312\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9314 - val_loss: 0.2123 - val_accuracy: 0.9317\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9314 - val_loss: 0.2113 - val_accuracy: 0.9315\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9323 - val_loss: 0.2126 - val_accuracy: 0.9312\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9314 - val_loss: 0.2108 - val_accuracy: 0.9317\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9316 - val_loss: 0.2111 - val_accuracy: 0.9308\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2417 - accuracy: 0.9241 - val_loss: 0.2188 - val_accuracy: 0.9262\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9314 - val_loss: 0.2207 - val_accuracy: 0.9268\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2064 - accuracy: 0.9316 - val_loss: 0.2187 - val_accuracy: 0.9268\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9322 - val_loss: 0.2180 - val_accuracy: 0.9283\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9319 - val_loss: 0.2243 - val_accuracy: 0.9277\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9323 - val_loss: 0.2171 - val_accuracy: 0.9286\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9324 - val_loss: 0.2218 - val_accuracy: 0.9266\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2051 - accuracy: 0.9325 - val_loss: 0.2180 - val_accuracy: 0.9252\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9323 - val_loss: 0.2242 - val_accuracy: 0.9269\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9332 - val_loss: 0.2237 - val_accuracy: 0.9249\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9326 - val_loss: 0.2182 - val_accuracy: 0.9275\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9320 - val_loss: 0.2309 - val_accuracy: 0.9278\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9326 - val_loss: 0.2164 - val_accuracy: 0.9265\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9332 - val_loss: 0.2240 - val_accuracy: 0.9253\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9333 - val_loss: 0.2187 - val_accuracy: 0.9265\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9326 - val_loss: 0.2166 - val_accuracy: 0.9262\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9329 - val_loss: 0.2175 - val_accuracy: 0.9271\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9328 - val_loss: 0.2271 - val_accuracy: 0.9274\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9328 - val_loss: 0.2202 - val_accuracy: 0.9263\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2036 - accuracy: 0.9328 - val_loss: 0.2316 - val_accuracy: 0.9271\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2033 - accuracy: 0.9329 - val_loss: 0.2243 - val_accuracy: 0.9261\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2036 - accuracy: 0.9324 - val_loss: 0.2258 - val_accuracy: 0.9256\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2031 - accuracy: 0.9331 - val_loss: 0.2264 - val_accuracy: 0.9262\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9327 - val_loss: 0.2271 - val_accuracy: 0.9255\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2036 - accuracy: 0.9332 - val_loss: 0.2178 - val_accuracy: 0.9266\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9329 - val_loss: 0.2259 - val_accuracy: 0.9263\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9328 - val_loss: 0.2169 - val_accuracy: 0.9280\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9330 - val_loss: 0.2250 - val_accuracy: 0.9262\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2028 - accuracy: 0.9332 - val_loss: 0.2202 - val_accuracy: 0.9272\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2030 - accuracy: 0.9329 - val_loss: 0.2318 - val_accuracy: 0.9265\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2026 - accuracy: 0.9332 - val_loss: 0.2250 - val_accuracy: 0.9269\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2028 - accuracy: 0.9332 - val_loss: 0.2274 - val_accuracy: 0.9284\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2026 - accuracy: 0.9333 - val_loss: 0.2175 - val_accuracy: 0.9266\n",
      "logloss: 0.2076\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model1NNproba()\n",
    "pred_train_2_6, pred_test_2_6 = predict_cv(model_2, train_x_2_6, train_y, test_x_2_6)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2_6, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1NN5proba:\n",
    "  def __init__(self):\n",
    "    self.model = None\n",
    "    self.scaler =None\n",
    "  \n",
    "  def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "    self.scaler = StandardScaler()\n",
    "    self.scaler.fit(tr_x)\n",
    "    batch_size = 128\n",
    "    epochs = 300\n",
    "    tr_x = self.scaler.transform(tr_x)\n",
    "    va_x = self.scaler.transform(va_x)\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.15000000000000002, input_shape=(tr_x.shape[1],)))\n",
    "    model.add(Dense(96,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(96,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = SGD(lr=0.0004400288024095838, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "    history = model.fit(tr_x,tr_y,\n",
    "    batch_size=batch_size, epochs=epochs,verbose=1,validation_data = (va_x,va_y),\n",
    "    callbacks=[early_stopping])\n",
    "    self.model = model\n",
    "\n",
    "\n",
    "  def predict(self,x):\n",
    "    x = self.scaler.transform(x)\n",
    "    y_pred = self.model.predict_proba(x).reshape(-1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.5713 - accuracy: 0.8571 - val_loss: 0.4592 - val_accuracy: 0.9256\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.9220 - val_loss: 0.3252 - val_accuracy: 0.9289\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.3065 - accuracy: 0.9247 - val_loss: 0.2628 - val_accuracy: 0.9339\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2658 - accuracy: 0.9254 - val_loss: 0.2330 - val_accuracy: 0.9348\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.9265 - val_loss: 0.2180 - val_accuracy: 0.9342\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2336 - accuracy: 0.9277 - val_loss: 0.2103 - val_accuracy: 0.9336\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2273 - accuracy: 0.9287 - val_loss: 0.2062 - val_accuracy: 0.9334\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2244 - accuracy: 0.9283 - val_loss: 0.2036 - val_accuracy: 0.9334\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2222 - accuracy: 0.9287 - val_loss: 0.2021 - val_accuracy: 0.9333\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9281 - val_loss: 0.2013 - val_accuracy: 0.9331\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2184 - accuracy: 0.9291 - val_loss: 0.2008 - val_accuracy: 0.9331\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2209 - accuracy: 0.9275 - val_loss: 0.2002 - val_accuracy: 0.9333\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2188 - accuracy: 0.9276 - val_loss: 0.2001 - val_accuracy: 0.9321\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2175 - accuracy: 0.9285 - val_loss: 0.1999 - val_accuracy: 0.9320\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2187 - accuracy: 0.9290 - val_loss: 0.1997 - val_accuracy: 0.9321\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2172 - accuracy: 0.9282 - val_loss: 0.1997 - val_accuracy: 0.9318\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2171 - accuracy: 0.9290 - val_loss: 0.1994 - val_accuracy: 0.9320\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2174 - accuracy: 0.9293 - val_loss: 0.1994 - val_accuracy: 0.9321\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2177 - accuracy: 0.9287 - val_loss: 0.1992 - val_accuracy: 0.9323\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2174 - accuracy: 0.9287 - val_loss: 0.1991 - val_accuracy: 0.9323\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2175 - accuracy: 0.9294 - val_loss: 0.1990 - val_accuracy: 0.9324\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2175 - accuracy: 0.9287 - val_loss: 0.1989 - val_accuracy: 0.9324\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2154 - accuracy: 0.9299 - val_loss: 0.1987 - val_accuracy: 0.9324\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2171 - accuracy: 0.9292 - val_loss: 0.1987 - val_accuracy: 0.9324\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9288 - val_loss: 0.1985 - val_accuracy: 0.9323\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.9287 - val_loss: 0.1985 - val_accuracy: 0.9323\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2167 - accuracy: 0.9289 - val_loss: 0.1983 - val_accuracy: 0.9321\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2174 - accuracy: 0.9286 - val_loss: 0.1984 - val_accuracy: 0.9323\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2163 - accuracy: 0.9283 - val_loss: 0.1982 - val_accuracy: 0.9323\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2158 - accuracy: 0.9285 - val_loss: 0.1982 - val_accuracy: 0.9323\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2162 - accuracy: 0.9289 - val_loss: 0.1982 - val_accuracy: 0.9324\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2154 - accuracy: 0.9298 - val_loss: 0.1981 - val_accuracy: 0.9325\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2156 - accuracy: 0.9283 - val_loss: 0.1980 - val_accuracy: 0.9325\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2161 - accuracy: 0.9294 - val_loss: 0.1980 - val_accuracy: 0.9325\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2172 - accuracy: 0.9296 - val_loss: 0.1978 - val_accuracy: 0.9323\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2155 - accuracy: 0.9292 - val_loss: 0.1978 - val_accuracy: 0.9323\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2140 - accuracy: 0.9288 - val_loss: 0.1978 - val_accuracy: 0.9323\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2152 - accuracy: 0.9297 - val_loss: 0.1978 - val_accuracy: 0.9323\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2160 - accuracy: 0.9284 - val_loss: 0.1979 - val_accuracy: 0.9321\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2156 - accuracy: 0.9292 - val_loss: 0.1979 - val_accuracy: 0.9324\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2168 - accuracy: 0.9288 - val_loss: 0.1977 - val_accuracy: 0.9321\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2145 - accuracy: 0.9292 - val_loss: 0.1975 - val_accuracy: 0.9323\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2146 - accuracy: 0.9292 - val_loss: 0.1975 - val_accuracy: 0.9321\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2149 - accuracy: 0.9297 - val_loss: 0.1975 - val_accuracy: 0.9321\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2150 - accuracy: 0.9300 - val_loss: 0.1975 - val_accuracy: 0.9323\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2152 - accuracy: 0.9293 - val_loss: 0.1974 - val_accuracy: 0.9323\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2154 - accuracy: 0.9288 - val_loss: 0.1975 - val_accuracy: 0.9324\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2150 - accuracy: 0.9297 - val_loss: 0.1976 - val_accuracy: 0.9321\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2163 - accuracy: 0.9293 - val_loss: 0.1976 - val_accuracy: 0.9321\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2145 - accuracy: 0.9296 - val_loss: 0.1976 - val_accuracy: 0.9321\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2152 - accuracy: 0.9293 - val_loss: 0.1974 - val_accuracy: 0.9324\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2137 - accuracy: 0.9292 - val_loss: 0.1974 - val_accuracy: 0.9323\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2144 - accuracy: 0.9294 - val_loss: 0.1974 - val_accuracy: 0.9323\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9293 - val_loss: 0.1974 - val_accuracy: 0.9323\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2170 - accuracy: 0.9293 - val_loss: 0.1974 - val_accuracy: 0.9324\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2150 - accuracy: 0.9289 - val_loss: 0.1973 - val_accuracy: 0.9323\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2140 - accuracy: 0.9298 - val_loss: 0.1974 - val_accuracy: 0.9324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9289 - val_loss: 0.1973 - val_accuracy: 0.9325\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2147 - accuracy: 0.9287 - val_loss: 0.1973 - val_accuracy: 0.9324\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2154 - accuracy: 0.9292 - val_loss: 0.1973 - val_accuracy: 0.9324\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9293 - val_loss: 0.1973 - val_accuracy: 0.9327\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9286 - val_loss: 0.1974 - val_accuracy: 0.9324\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2150 - accuracy: 0.9300 - val_loss: 0.1973 - val_accuracy: 0.9324\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9294 - val_loss: 0.1973 - val_accuracy: 0.9328\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2134 - accuracy: 0.9289 - val_loss: 0.1973 - val_accuracy: 0.9328\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2140 - accuracy: 0.9294 - val_loss: 0.1972 - val_accuracy: 0.9330\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9303 - val_loss: 0.1972 - val_accuracy: 0.9331\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2141 - accuracy: 0.9302 - val_loss: 0.1972 - val_accuracy: 0.9330\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9298 - val_loss: 0.1973 - val_accuracy: 0.9324\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2144 - accuracy: 0.9296 - val_loss: 0.1972 - val_accuracy: 0.9331\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2140 - accuracy: 0.9295 - val_loss: 0.1972 - val_accuracy: 0.9331\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2147 - accuracy: 0.9286 - val_loss: 0.1971 - val_accuracy: 0.9333\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2133 - accuracy: 0.9296 - val_loss: 0.1972 - val_accuracy: 0.9333\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9294 - val_loss: 0.1972 - val_accuracy: 0.9333\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2135 - accuracy: 0.9294 - val_loss: 0.1971 - val_accuracy: 0.9331\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9288 - val_loss: 0.1971 - val_accuracy: 0.9333\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9292 - val_loss: 0.1971 - val_accuracy: 0.9333\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2144 - accuracy: 0.9297 - val_loss: 0.1972 - val_accuracy: 0.9333\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2140 - accuracy: 0.9303 - val_loss: 0.1972 - val_accuracy: 0.9333\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2140 - accuracy: 0.9286 - val_loss: 0.1971 - val_accuracy: 0.9333\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.9297 - val_loss: 0.1972 - val_accuracy: 0.9333\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2140 - accuracy: 0.9293 - val_loss: 0.1972 - val_accuracy: 0.9333\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2137 - accuracy: 0.9300 - val_loss: 0.1972 - val_accuracy: 0.9331\n",
      "Epoch 84/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9288 - val_loss: 0.1972 - val_accuracy: 0.9331\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9288 - val_loss: 0.1971 - val_accuracy: 0.9333\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9291 - val_loss: 0.1971 - val_accuracy: 0.9333\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2133 - accuracy: 0.9296 - val_loss: 0.1971 - val_accuracy: 0.9333\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2146 - accuracy: 0.9292 - val_loss: 0.1971 - val_accuracy: 0.9334\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2137 - accuracy: 0.9297 - val_loss: 0.1971 - val_accuracy: 0.9334\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9300 - val_loss: 0.1971 - val_accuracy: 0.9333\n",
      "Epoch 91/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2143 - accuracy: 0.9288 - val_loss: 0.1971 - val_accuracy: 0.9334\n",
      "Epoch 92/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9305 - val_loss: 0.1971 - val_accuracy: 0.9334\n",
      "Epoch 93/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2137 - accuracy: 0.9287 - val_loss: 0.1971 - val_accuracy: 0.9336\n",
      "Epoch 94/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9298 - val_loss: 0.1970 - val_accuracy: 0.9336\n",
      "Epoch 95/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9303 - val_loss: 0.1971 - val_accuracy: 0.9334\n",
      "Epoch 96/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2144 - accuracy: 0.9293 - val_loss: 0.1971 - val_accuracy: 0.9334\n",
      "Epoch 97/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9305 - val_loss: 0.1971 - val_accuracy: 0.9334\n",
      "Epoch 98/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9292 - val_loss: 0.1971 - val_accuracy: 0.9334\n",
      "Epoch 99/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2137 - accuracy: 0.9290 - val_loss: 0.1971 - val_accuracy: 0.9333\n",
      "Epoch 100/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2128 - accuracy: 0.9303 - val_loss: 0.1971 - val_accuracy: 0.9334\n",
      "Epoch 101/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9297 - val_loss: 0.1972 - val_accuracy: 0.9331\n",
      "Epoch 102/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2133 - accuracy: 0.9297 - val_loss: 0.1972 - val_accuracy: 0.9333\n",
      "Epoch 103/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2134 - accuracy: 0.9296 - val_loss: 0.1971 - val_accuracy: 0.9333\n",
      "Epoch 104/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2136 - accuracy: 0.9292 - val_loss: 0.1971 - val_accuracy: 0.9337\n",
      "Epoch 105/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9299 - val_loss: 0.1971 - val_accuracy: 0.9337\n",
      "Epoch 106/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9295 - val_loss: 0.1971 - val_accuracy: 0.9339\n",
      "Epoch 107/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9297 - val_loss: 0.1971 - val_accuracy: 0.9337\n",
      "Epoch 108/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2134 - accuracy: 0.9290 - val_loss: 0.1971 - val_accuracy: 0.9331\n",
      "Epoch 109/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2136 - accuracy: 0.9289 - val_loss: 0.1971 - val_accuracy: 0.9333\n",
      "Epoch 110/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9299 - val_loss: 0.1972 - val_accuracy: 0.9331\n",
      "Epoch 111/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9300 - val_loss: 0.1971 - val_accuracy: 0.9336\n",
      "Epoch 112/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2128 - accuracy: 0.9298 - val_loss: 0.1971 - val_accuracy: 0.9336\n",
      "Epoch 113/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.9306 - val_loss: 0.1971 - val_accuracy: 0.9337\n",
      "Epoch 114/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2126 - accuracy: 0.9293 - val_loss: 0.1971 - val_accuracy: 0.9336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.5892 - accuracy: 0.7428 - val_loss: 0.4343 - val_accuracy: 0.9258\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.9262 - val_loss: 0.3157 - val_accuracy: 0.9221\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2882 - accuracy: 0.9249 - val_loss: 0.2664 - val_accuracy: 0.9252\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2529 - accuracy: 0.9265 - val_loss: 0.2422 - val_accuracy: 0.9271\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2370 - accuracy: 0.9271 - val_loss: 0.2296 - val_accuracy: 0.9278\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2270 - accuracy: 0.9272 - val_loss: 0.2224 - val_accuracy: 0.9290\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2219 - accuracy: 0.9283 - val_loss: 0.2183 - val_accuracy: 0.9302\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2191 - accuracy: 0.9277 - val_loss: 0.2157 - val_accuracy: 0.9311\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2167 - accuracy: 0.9283 - val_loss: 0.2141 - val_accuracy: 0.9314\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9289 - val_loss: 0.2129 - val_accuracy: 0.9318\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.9296 - val_loss: 0.2123 - val_accuracy: 0.9324\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2144 - accuracy: 0.9295 - val_loss: 0.2117 - val_accuracy: 0.9324\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2123 - accuracy: 0.9300 - val_loss: 0.2113 - val_accuracy: 0.9323\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2131 - accuracy: 0.9293 - val_loss: 0.2110 - val_accuracy: 0.9321\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2130 - accuracy: 0.9289 - val_loss: 0.2109 - val_accuracy: 0.9321\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.9291 - val_loss: 0.2107 - val_accuracy: 0.9324\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2116 - accuracy: 0.9300 - val_loss: 0.2106 - val_accuracy: 0.9323\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9291 - val_loss: 0.2105 - val_accuracy: 0.9324\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2126 - accuracy: 0.9293 - val_loss: 0.2104 - val_accuracy: 0.9327\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9292 - val_loss: 0.2103 - val_accuracy: 0.9327\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2126 - accuracy: 0.9294 - val_loss: 0.2102 - val_accuracy: 0.9327\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9297 - val_loss: 0.2101 - val_accuracy: 0.9327\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2128 - accuracy: 0.9291 - val_loss: 0.2101 - val_accuracy: 0.9328\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2115 - accuracy: 0.9298 - val_loss: 0.2100 - val_accuracy: 0.9327\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9291 - val_loss: 0.2099 - val_accuracy: 0.9327\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9301 - val_loss: 0.2098 - val_accuracy: 0.9325\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2116 - accuracy: 0.9288 - val_loss: 0.2098 - val_accuracy: 0.9323\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2120 - accuracy: 0.9297 - val_loss: 0.2098 - val_accuracy: 0.9324\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2115 - accuracy: 0.9298 - val_loss: 0.2097 - val_accuracy: 0.9325\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2121 - accuracy: 0.9297 - val_loss: 0.2096 - val_accuracy: 0.9325\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.9300 - val_loss: 0.2096 - val_accuracy: 0.9325\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2107 - accuracy: 0.9300 - val_loss: 0.2095 - val_accuracy: 0.9324\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2121 - accuracy: 0.9301 - val_loss: 0.2095 - val_accuracy: 0.9323\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9307 - val_loss: 0.2094 - val_accuracy: 0.9324\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2112 - accuracy: 0.9301 - val_loss: 0.2094 - val_accuracy: 0.9323\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2114 - accuracy: 0.9298 - val_loss: 0.2093 - val_accuracy: 0.9324\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9305 - val_loss: 0.2093 - val_accuracy: 0.9323\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2108 - accuracy: 0.9300 - val_loss: 0.2093 - val_accuracy: 0.9323\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9296 - val_loss: 0.2093 - val_accuracy: 0.9324\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.9300 - val_loss: 0.2093 - val_accuracy: 0.9323\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.9299 - val_loss: 0.2092 - val_accuracy: 0.9324\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2112 - accuracy: 0.9303 - val_loss: 0.2091 - val_accuracy: 0.9324\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.9292 - val_loss: 0.2091 - val_accuracy: 0.9321\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 0.9301 - val_loss: 0.2091 - val_accuracy: 0.9324\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2114 - accuracy: 0.9297 - val_loss: 0.2091 - val_accuracy: 0.9324\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2112 - accuracy: 0.9302 - val_loss: 0.2090 - val_accuracy: 0.9321\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2102 - accuracy: 0.9296 - val_loss: 0.2090 - val_accuracy: 0.9323\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2114 - accuracy: 0.9299 - val_loss: 0.2090 - val_accuracy: 0.9321\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9305 - val_loss: 0.2089 - val_accuracy: 0.9323\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9298 - val_loss: 0.2089 - val_accuracy: 0.9323\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9297 - val_loss: 0.2088 - val_accuracy: 0.9323\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9306 - val_loss: 0.2088 - val_accuracy: 0.9323\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9304 - val_loss: 0.2088 - val_accuracy: 0.9324\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9301 - val_loss: 0.2088 - val_accuracy: 0.9324\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 0.9301 - val_loss: 0.2087 - val_accuracy: 0.9321\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9304 - val_loss: 0.2087 - val_accuracy: 0.9321\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9303 - val_loss: 0.2086 - val_accuracy: 0.9321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9305 - val_loss: 0.2086 - val_accuracy: 0.9321\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9300 - val_loss: 0.2086 - val_accuracy: 0.9323\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2111 - accuracy: 0.9302 - val_loss: 0.2085 - val_accuracy: 0.9321\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9314 - val_loss: 0.2085 - val_accuracy: 0.9321\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9309 - val_loss: 0.2085 - val_accuracy: 0.9321\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9300 - val_loss: 0.2085 - val_accuracy: 0.9321\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9297 - val_loss: 0.2085 - val_accuracy: 0.9318\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9300 - val_loss: 0.2085 - val_accuracy: 0.9321\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9306 - val_loss: 0.2084 - val_accuracy: 0.9321\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2107 - accuracy: 0.9301 - val_loss: 0.2084 - val_accuracy: 0.9320\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9299 - val_loss: 0.2084 - val_accuracy: 0.9320\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9296 - val_loss: 0.2083 - val_accuracy: 0.9320\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2111 - accuracy: 0.9294 - val_loss: 0.2083 - val_accuracy: 0.9318\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9306 - val_loss: 0.2083 - val_accuracy: 0.9318\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 0.9302 - val_loss: 0.2083 - val_accuracy: 0.9318\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9301 - val_loss: 0.2083 - val_accuracy: 0.9317\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9303 - val_loss: 0.2082 - val_accuracy: 0.9318\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9310 - val_loss: 0.2082 - val_accuracy: 0.9317\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9308 - val_loss: 0.2082 - val_accuracy: 0.9320\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9301 - val_loss: 0.2082 - val_accuracy: 0.9318\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 0.9298 - val_loss: 0.2082 - val_accuracy: 0.9320\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9296 - val_loss: 0.2081 - val_accuracy: 0.9317\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9295 - val_loss: 0.2081 - val_accuracy: 0.9317\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9299 - val_loss: 0.2081 - val_accuracy: 0.9320\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9301 - val_loss: 0.2081 - val_accuracy: 0.9320\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9300 - val_loss: 0.2081 - val_accuracy: 0.9318\n",
      "Epoch 84/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9306 - val_loss: 0.2081 - val_accuracy: 0.9320\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9309 - val_loss: 0.2081 - val_accuracy: 0.9318\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9304 - val_loss: 0.2080 - val_accuracy: 0.9318\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9294 - val_loss: 0.2080 - val_accuracy: 0.9317\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9303 - val_loss: 0.2080 - val_accuracy: 0.9315\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9297 - val_loss: 0.2080 - val_accuracy: 0.9311\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.9298 - val_loss: 0.2080 - val_accuracy: 0.9315\n",
      "Epoch 91/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9307 - val_loss: 0.2080 - val_accuracy: 0.9317\n",
      "Epoch 92/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9303 - val_loss: 0.2080 - val_accuracy: 0.9317\n",
      "Epoch 93/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9306 - val_loss: 0.2080 - val_accuracy: 0.9314\n",
      "Epoch 94/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9301 - val_loss: 0.2080 - val_accuracy: 0.9314\n",
      "Epoch 95/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9304 - val_loss: 0.2079 - val_accuracy: 0.9315\n",
      "Epoch 96/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9303 - val_loss: 0.2079 - val_accuracy: 0.9312\n",
      "Epoch 97/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9307 - val_loss: 0.2079 - val_accuracy: 0.9312\n",
      "Epoch 98/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9297 - val_loss: 0.2079 - val_accuracy: 0.9312\n",
      "Epoch 99/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9299 - val_loss: 0.2079 - val_accuracy: 0.9311\n",
      "Epoch 100/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9308 - val_loss: 0.2079 - val_accuracy: 0.9312\n",
      "Epoch 101/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9308 - val_loss: 0.2079 - val_accuracy: 0.9311\n",
      "Epoch 102/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9304 - val_loss: 0.2079 - val_accuracy: 0.9312\n",
      "Epoch 103/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9296 - val_loss: 0.2079 - val_accuracy: 0.9312\n",
      "Epoch 104/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2102 - accuracy: 0.9292 - val_loss: 0.2079 - val_accuracy: 0.9311\n",
      "Epoch 105/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9311 - val_loss: 0.2078 - val_accuracy: 0.9311\n",
      "Epoch 106/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9301 - val_loss: 0.2078 - val_accuracy: 0.9311\n",
      "Epoch 107/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9308 - val_loss: 0.2078 - val_accuracy: 0.9312\n",
      "Epoch 108/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9304 - val_loss: 0.2078 - val_accuracy: 0.9311\n",
      "Epoch 109/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9312 - val_loss: 0.2078 - val_accuracy: 0.9311\n",
      "Epoch 110/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2110 - accuracy: 0.9297 - val_loss: 0.2078 - val_accuracy: 0.9311\n",
      "Epoch 111/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9293 - val_loss: 0.2078 - val_accuracy: 0.9311\n",
      "Epoch 112/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9301 - val_loss: 0.2078 - val_accuracy: 0.9312\n",
      "Epoch 113/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9298 - val_loss: 0.2078 - val_accuracy: 0.9312\n",
      "Epoch 114/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9312 - val_loss: 0.2077 - val_accuracy: 0.9314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9306 - val_loss: 0.2078 - val_accuracy: 0.9312\n",
      "Epoch 116/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9302 - val_loss: 0.2077 - val_accuracy: 0.9312\n",
      "Epoch 117/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9311 - val_loss: 0.2077 - val_accuracy: 0.9311\n",
      "Epoch 118/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9302 - val_loss: 0.2077 - val_accuracy: 0.9312\n",
      "Epoch 119/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9305 - val_loss: 0.2077 - val_accuracy: 0.9309\n",
      "Epoch 120/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9306 - val_loss: 0.2077 - val_accuracy: 0.9311\n",
      "Epoch 121/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9294 - val_loss: 0.2077 - val_accuracy: 0.9311\n",
      "Epoch 122/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9300 - val_loss: 0.2077 - val_accuracy: 0.9311\n",
      "Epoch 123/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9306 - val_loss: 0.2077 - val_accuracy: 0.9311\n",
      "Epoch 124/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9309 - val_loss: 0.2077 - val_accuracy: 0.9311\n",
      "Epoch 125/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9295 - val_loss: 0.2076 - val_accuracy: 0.9309\n",
      "Epoch 126/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9301 - val_loss: 0.2077 - val_accuracy: 0.9309\n",
      "Epoch 127/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9307 - val_loss: 0.2076 - val_accuracy: 0.9309\n",
      "Epoch 128/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9309 - val_loss: 0.2076 - val_accuracy: 0.9309\n",
      "Epoch 129/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9303 - val_loss: 0.2076 - val_accuracy: 0.9311\n",
      "Epoch 130/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9300 - val_loss: 0.2076 - val_accuracy: 0.9309\n",
      "Epoch 131/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9303 - val_loss: 0.2076 - val_accuracy: 0.9311\n",
      "Epoch 132/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9306 - val_loss: 0.2076 - val_accuracy: 0.9311\n",
      "Epoch 133/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9307 - val_loss: 0.2076 - val_accuracy: 0.9311\n",
      "Epoch 134/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9306 - val_loss: 0.2076 - val_accuracy: 0.9311\n",
      "Epoch 135/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9309 - val_loss: 0.2076 - val_accuracy: 0.9311\n",
      "Epoch 136/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9301 - val_loss: 0.2076 - val_accuracy: 0.9314\n",
      "Epoch 137/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9305 - val_loss: 0.2076 - val_accuracy: 0.9311\n",
      "Epoch 138/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9302 - val_loss: 0.2076 - val_accuracy: 0.9312\n",
      "Epoch 139/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9307 - val_loss: 0.2075 - val_accuracy: 0.9312\n",
      "Epoch 140/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9304 - val_loss: 0.2076 - val_accuracy: 0.9312\n",
      "Epoch 141/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9293 - val_loss: 0.2075 - val_accuracy: 0.9311\n",
      "Epoch 142/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9302 - val_loss: 0.2075 - val_accuracy: 0.9314\n",
      "Epoch 143/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9294 - val_loss: 0.2075 - val_accuracy: 0.9311\n",
      "Epoch 144/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9309 - val_loss: 0.2075 - val_accuracy: 0.9311\n",
      "Epoch 145/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9302 - val_loss: 0.2075 - val_accuracy: 0.9311\n",
      "Epoch 146/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9304 - val_loss: 0.2075 - val_accuracy: 0.9311\n",
      "Epoch 147/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9297 - val_loss: 0.2075 - val_accuracy: 0.9311\n",
      "Epoch 148/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9308 - val_loss: 0.2075 - val_accuracy: 0.9311\n",
      "Epoch 149/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9305 - val_loss: 0.2074 - val_accuracy: 0.9311\n",
      "Epoch 150/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9303 - val_loss: 0.2074 - val_accuracy: 0.9309\n",
      "Epoch 151/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9298 - val_loss: 0.2074 - val_accuracy: 0.9309\n",
      "Epoch 152/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9303 - val_loss: 0.2074 - val_accuracy: 0.9311\n",
      "Epoch 153/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9301 - val_loss: 0.2074 - val_accuracy: 0.9311\n",
      "Epoch 154/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9306 - val_loss: 0.2074 - val_accuracy: 0.9309\n",
      "Epoch 155/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9303 - val_loss: 0.2074 - val_accuracy: 0.9309\n",
      "Epoch 156/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9302 - val_loss: 0.2074 - val_accuracy: 0.9309\n",
      "Epoch 157/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9310 - val_loss: 0.2074 - val_accuracy: 0.9311\n",
      "Epoch 158/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9300 - val_loss: 0.2074 - val_accuracy: 0.9309\n",
      "Epoch 159/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9304 - val_loss: 0.2073 - val_accuracy: 0.9309\n",
      "Epoch 160/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9300 - val_loss: 0.2073 - val_accuracy: 0.9309\n",
      "Epoch 161/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9303 - val_loss: 0.2074 - val_accuracy: 0.9309\n",
      "Epoch 162/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9312 - val_loss: 0.2073 - val_accuracy: 0.9309\n",
      "Epoch 163/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9311 - val_loss: 0.2073 - val_accuracy: 0.9308\n",
      "Epoch 164/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9294 - val_loss: 0.2073 - val_accuracy: 0.9308\n",
      "Epoch 165/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9300 - val_loss: 0.2073 - val_accuracy: 0.9309\n",
      "Epoch 166/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9304 - val_loss: 0.2073 - val_accuracy: 0.9309\n",
      "Epoch 167/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9297 - val_loss: 0.2073 - val_accuracy: 0.9309\n",
      "Epoch 168/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9309 - val_loss: 0.2073 - val_accuracy: 0.9309\n",
      "Epoch 169/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9303 - val_loss: 0.2073 - val_accuracy: 0.9309\n",
      "Epoch 170/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9303 - val_loss: 0.2073 - val_accuracy: 0.9309\n",
      "Epoch 171/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9297 - val_loss: 0.2073 - val_accuracy: 0.9308\n",
      "Epoch 172/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9304 - val_loss: 0.2073 - val_accuracy: 0.9309\n",
      "Epoch 173/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9306 - val_loss: 0.2073 - val_accuracy: 0.9311\n",
      "Epoch 174/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9303 - val_loss: 0.2073 - val_accuracy: 0.9309\n",
      "Epoch 175/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9302 - val_loss: 0.2073 - val_accuracy: 0.9308\n",
      "Epoch 176/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9301 - val_loss: 0.2073 - val_accuracy: 0.9309\n",
      "Epoch 177/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9306 - val_loss: 0.2073 - val_accuracy: 0.9308\n",
      "Epoch 178/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9302 - val_loss: 0.2072 - val_accuracy: 0.9311\n",
      "Epoch 179/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9302 - val_loss: 0.2073 - val_accuracy: 0.9311\n",
      "Epoch 180/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9311 - val_loss: 0.2073 - val_accuracy: 0.9311\n",
      "Epoch 181/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9303 - val_loss: 0.2073 - val_accuracy: 0.9309\n",
      "Epoch 182/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9305 - val_loss: 0.2072 - val_accuracy: 0.9311\n",
      "Epoch 183/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9299 - val_loss: 0.2072 - val_accuracy: 0.9311\n",
      "Epoch 184/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9306 - val_loss: 0.2072 - val_accuracy: 0.9311\n",
      "Epoch 185/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9305 - val_loss: 0.2072 - val_accuracy: 0.9312\n",
      "Epoch 186/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9303 - val_loss: 0.2072 - val_accuracy: 0.9311\n",
      "Epoch 187/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9300 - val_loss: 0.2073 - val_accuracy: 0.9309\n",
      "Epoch 188/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9308 - val_loss: 0.2072 - val_accuracy: 0.9312\n",
      "Epoch 189/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9307 - val_loss: 0.2072 - val_accuracy: 0.9312\n",
      "Epoch 190/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9304 - val_loss: 0.2072 - val_accuracy: 0.9312\n",
      "Epoch 191/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9304 - val_loss: 0.2072 - val_accuracy: 0.9309\n",
      "Epoch 192/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9302 - val_loss: 0.2072 - val_accuracy: 0.9312\n",
      "Epoch 193/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9305 - val_loss: 0.2072 - val_accuracy: 0.9312\n",
      "Epoch 194/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9294 - val_loss: 0.2072 - val_accuracy: 0.9311\n",
      "Epoch 195/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9306 - val_loss: 0.2072 - val_accuracy: 0.9312\n",
      "Epoch 196/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9307 - val_loss: 0.2071 - val_accuracy: 0.9312\n",
      "Epoch 197/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9308 - val_loss: 0.2072 - val_accuracy: 0.9312\n",
      "Epoch 198/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9308 - val_loss: 0.2071 - val_accuracy: 0.9312\n",
      "Epoch 199/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9305 - val_loss: 0.2071 - val_accuracy: 0.9311\n",
      "Epoch 200/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9304 - val_loss: 0.2072 - val_accuracy: 0.9309\n",
      "Epoch 201/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9307 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 202/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9302 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 203/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9295 - val_loss: 0.2072 - val_accuracy: 0.9309\n",
      "Epoch 204/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9303 - val_loss: 0.2071 - val_accuracy: 0.9312\n",
      "Epoch 205/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9302 - val_loss: 0.2071 - val_accuracy: 0.9312\n",
      "Epoch 206/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9306 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 207/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9307 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 208/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9305 - val_loss: 0.2072 - val_accuracy: 0.9309\n",
      "Epoch 209/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9306 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 210/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9304 - val_loss: 0.2072 - val_accuracy: 0.9308\n",
      "Epoch 211/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9303 - val_loss: 0.2072 - val_accuracy: 0.9309\n",
      "Epoch 212/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9304 - val_loss: 0.2072 - val_accuracy: 0.9309\n",
      "Epoch 213/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9304 - val_loss: 0.2072 - val_accuracy: 0.9309\n",
      "Epoch 214/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9304 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 215/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9313 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 216/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9307 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 217/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9298 - val_loss: 0.2072 - val_accuracy: 0.9308\n",
      "Epoch 218/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9306 - val_loss: 0.2072 - val_accuracy: 0.9308\n",
      "Epoch 219/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9300 - val_loss: 0.2072 - val_accuracy: 0.9308\n",
      "Epoch 220/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9311 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 221/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9304 - val_loss: 0.2072 - val_accuracy: 0.9309\n",
      "Epoch 222/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9305 - val_loss: 0.2072 - val_accuracy: 0.9308\n",
      "Epoch 223/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9300 - val_loss: 0.2072 - val_accuracy: 0.9308\n",
      "Epoch 224/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9313 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 225/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9308 - val_loss: 0.2071 - val_accuracy: 0.9312\n",
      "Epoch 226/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9307 - val_loss: 0.2071 - val_accuracy: 0.9311\n",
      "Epoch 227/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9313 - val_loss: 0.2071 - val_accuracy: 0.9311\n",
      "Epoch 228/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9306 - val_loss: 0.2071 - val_accuracy: 0.9311\n",
      "Epoch 229/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9304 - val_loss: 0.2070 - val_accuracy: 0.9311\n",
      "Epoch 230/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9310 - val_loss: 0.2071 - val_accuracy: 0.9311\n",
      "Epoch 231/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9301 - val_loss: 0.2071 - val_accuracy: 0.9311\n",
      "Epoch 232/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9307 - val_loss: 0.2071 - val_accuracy: 0.9311\n",
      "Epoch 233/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9304 - val_loss: 0.2071 - val_accuracy: 0.9311\n",
      "Epoch 234/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9301 - val_loss: 0.2071 - val_accuracy: 0.9311\n",
      "Epoch 235/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9310 - val_loss: 0.2071 - val_accuracy: 0.9312\n",
      "Epoch 236/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9301 - val_loss: 0.2070 - val_accuracy: 0.9311\n",
      "Epoch 237/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9302 - val_loss: 0.2070 - val_accuracy: 0.9311\n",
      "Epoch 238/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9302 - val_loss: 0.2070 - val_accuracy: 0.9312\n",
      "Epoch 239/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2067 - accuracy: 0.9308 - val_loss: 0.2070 - val_accuracy: 0.9309\n",
      "Epoch 240/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9296 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 241/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9310 - val_loss: 0.2070 - val_accuracy: 0.9309\n",
      "Epoch 242/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9294 - val_loss: 0.2070 - val_accuracy: 0.9308\n",
      "Epoch 243/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9296 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 244/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9303 - val_loss: 0.2070 - val_accuracy: 0.9309\n",
      "Epoch 245/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9304 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 246/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9310 - val_loss: 0.2071 - val_accuracy: 0.9311\n",
      "Epoch 247/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9311 - val_loss: 0.2071 - val_accuracy: 0.9311\n",
      "Epoch 248/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9306 - val_loss: 0.2070 - val_accuracy: 0.9309\n",
      "Epoch 249/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9308 - val_loss: 0.2070 - val_accuracy: 0.9311\n",
      "Epoch 250/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9307 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 251/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9303 - val_loss: 0.2071 - val_accuracy: 0.9308\n",
      "Epoch 252/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9305 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 253/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9296 - val_loss: 0.2071 - val_accuracy: 0.9311\n",
      "Epoch 254/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9305 - val_loss: 0.2070 - val_accuracy: 0.9312\n",
      "Epoch 255/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9304 - val_loss: 0.2071 - val_accuracy: 0.9311\n",
      "Epoch 256/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9311 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 257/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9305 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 258/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2079 - accuracy: 0.9301 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
      "Epoch 259/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9310 - val_loss: 0.2070 - val_accuracy: 0.9309\n",
      "Epoch 260/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9311 - val_loss: 0.2070 - val_accuracy: 0.9309\n",
      "Epoch 261/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9310 - val_loss: 0.2070 - val_accuracy: 0.9311\n",
      "Epoch 262/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9312 - val_loss: 0.2070 - val_accuracy: 0.9309\n",
      "Epoch 263/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9307 - val_loss: 0.2070 - val_accuracy: 0.9309\n",
      "Epoch 264/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9304 - val_loss: 0.2070 - val_accuracy: 0.9309\n",
      "Epoch 265/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9302 - val_loss: 0.2070 - val_accuracy: 0.9311\n",
      "Epoch 266/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9305 - val_loss: 0.2070 - val_accuracy: 0.9311\n",
      "Epoch 267/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9307 - val_loss: 0.2070 - val_accuracy: 0.9311\n",
      "Epoch 268/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9303 - val_loss: 0.2070 - val_accuracy: 0.9312\n",
      "Epoch 269/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9306 - val_loss: 0.2070 - val_accuracy: 0.9311\n",
      "Epoch 270/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9308 - val_loss: 0.2070 - val_accuracy: 0.9312\n",
      "Epoch 271/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9304 - val_loss: 0.2070 - val_accuracy: 0.9312\n",
      "Epoch 272/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9305 - val_loss: 0.2070 - val_accuracy: 0.9309\n",
      "Epoch 273/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9303 - val_loss: 0.2070 - val_accuracy: 0.9308\n",
      "Epoch 274/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9304 - val_loss: 0.2070 - val_accuracy: 0.9309\n",
      "Epoch 275/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9312 - val_loss: 0.2070 - val_accuracy: 0.9306\n",
      "Epoch 276/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9306 - val_loss: 0.2069 - val_accuracy: 0.9308\n",
      "Epoch 277/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9298 - val_loss: 0.2069 - val_accuracy: 0.9311\n",
      "Epoch 278/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9306 - val_loss: 0.2070 - val_accuracy: 0.9308\n",
      "Epoch 279/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9303 - val_loss: 0.2070 - val_accuracy: 0.9309\n",
      "Epoch 280/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9299 - val_loss: 0.2070 - val_accuracy: 0.9309\n",
      "Epoch 281/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9307 - val_loss: 0.2070 - val_accuracy: 0.9308\n",
      "Epoch 282/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9302 - val_loss: 0.2070 - val_accuracy: 0.9308\n",
      "Epoch 283/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9310 - val_loss: 0.2069 - val_accuracy: 0.9311\n",
      "Epoch 284/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2066 - accuracy: 0.9311 - val_loss: 0.2069 - val_accuracy: 0.9308\n",
      "Epoch 285/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2074 - accuracy: 0.9301 - val_loss: 0.2069 - val_accuracy: 0.9309\n",
      "Epoch 286/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9306 - val_loss: 0.2069 - val_accuracy: 0.9309\n",
      "Epoch 287/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9302 - val_loss: 0.2070 - val_accuracy: 0.9308\n",
      "Epoch 288/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2069 - accuracy: 0.9308 - val_loss: 0.2069 - val_accuracy: 0.9308\n",
      "Epoch 289/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9309 - val_loss: 0.2070 - val_accuracy: 0.9308\n",
      "Epoch 290/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9304 - val_loss: 0.2070 - val_accuracy: 0.9308\n",
      "Epoch 291/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9298 - val_loss: 0.2070 - val_accuracy: 0.9308\n",
      "Epoch 292/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2065 - accuracy: 0.9316 - val_loss: 0.2070 - val_accuracy: 0.9308\n",
      "Epoch 293/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9308 - val_loss: 0.2069 - val_accuracy: 0.9309\n",
      "Epoch 294/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9308 - val_loss: 0.2070 - val_accuracy: 0.9309\n",
      "Epoch 295/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9306 - val_loss: 0.2070 - val_accuracy: 0.9308\n",
      "Epoch 296/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9310 - val_loss: 0.2070 - val_accuracy: 0.9309\n",
      "Epoch 297/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9305 - val_loss: 0.2070 - val_accuracy: 0.9308\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.7359 - val_loss: 0.4715 - val_accuracy: 0.9281\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.9246 - val_loss: 0.3471 - val_accuracy: 0.9266\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.9251 - val_loss: 0.2828 - val_accuracy: 0.9289\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2723 - accuracy: 0.9267 - val_loss: 0.2498 - val_accuracy: 0.9305\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2481 - accuracy: 0.9273 - val_loss: 0.2327 - val_accuracy: 0.9317\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2336 - accuracy: 0.9288 - val_loss: 0.2234 - val_accuracy: 0.9314\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9278 - val_loss: 0.2186 - val_accuracy: 0.9312\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 0.9289 - val_loss: 0.2154 - val_accuracy: 0.9314\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2166 - accuracy: 0.9299 - val_loss: 0.2141 - val_accuracy: 0.9318\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2159 - accuracy: 0.9293 - val_loss: 0.2130 - val_accuracy: 0.9318\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2167 - accuracy: 0.9277 - val_loss: 0.2126 - val_accuracy: 0.9318\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2144 - accuracy: 0.9286 - val_loss: 0.2124 - val_accuracy: 0.9321\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2158 - accuracy: 0.9287 - val_loss: 0.2119 - val_accuracy: 0.9320\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.9288 - val_loss: 0.2120 - val_accuracy: 0.9315\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9294 - val_loss: 0.2118 - val_accuracy: 0.9318\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2135 - accuracy: 0.9298 - val_loss: 0.2120 - val_accuracy: 0.9321\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2135 - accuracy: 0.9292 - val_loss: 0.2116 - val_accuracy: 0.9321\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9291 - val_loss: 0.2117 - val_accuracy: 0.9321\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.9291 - val_loss: 0.2116 - val_accuracy: 0.9323\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2128 - accuracy: 0.9287 - val_loss: 0.2118 - val_accuracy: 0.9317\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2135 - accuracy: 0.9285 - val_loss: 0.2117 - val_accuracy: 0.9318\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2112 - accuracy: 0.9300 - val_loss: 0.2119 - val_accuracy: 0.9320\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.9301 - val_loss: 0.2119 - val_accuracy: 0.9318\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9292 - val_loss: 0.2119 - val_accuracy: 0.9320\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9308 - val_loss: 0.2117 - val_accuracy: 0.9323\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2128 - accuracy: 0.9293 - val_loss: 0.2117 - val_accuracy: 0.9321\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2130 - accuracy: 0.9288 - val_loss: 0.2116 - val_accuracy: 0.9318\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2113 - accuracy: 0.9292 - val_loss: 0.2116 - val_accuracy: 0.9321\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2113 - accuracy: 0.9289 - val_loss: 0.2115 - val_accuracy: 0.9321\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9287 - val_loss: 0.2115 - val_accuracy: 0.9324\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9300 - val_loss: 0.2114 - val_accuracy: 0.9325\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2102 - accuracy: 0.9303 - val_loss: 0.2112 - val_accuracy: 0.9321\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9287 - val_loss: 0.2114 - val_accuracy: 0.9325\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2110 - accuracy: 0.9287 - val_loss: 0.2111 - val_accuracy: 0.9320\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.9294 - val_loss: 0.2112 - val_accuracy: 0.9321\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2111 - accuracy: 0.9296 - val_loss: 0.2110 - val_accuracy: 0.9320\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2112 - accuracy: 0.9295 - val_loss: 0.2109 - val_accuracy: 0.9318\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9300 - val_loss: 0.2109 - val_accuracy: 0.9320\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 0.9302 - val_loss: 0.2110 - val_accuracy: 0.9321\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2102 - accuracy: 0.9299 - val_loss: 0.2109 - val_accuracy: 0.9320\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9298 - val_loss: 0.2110 - val_accuracy: 0.9323\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9301 - val_loss: 0.2110 - val_accuracy: 0.9320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 0.9308 - val_loss: 0.2109 - val_accuracy: 0.9320\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9295 - val_loss: 0.2107 - val_accuracy: 0.9317\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9292 - val_loss: 0.2108 - val_accuracy: 0.9317\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2107 - accuracy: 0.9296 - val_loss: 0.2107 - val_accuracy: 0.9317\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2110 - accuracy: 0.9294 - val_loss: 0.2107 - val_accuracy: 0.9317\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2110 - accuracy: 0.9283 - val_loss: 0.2106 - val_accuracy: 0.9315\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.9304 - val_loss: 0.2106 - val_accuracy: 0.9315\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9297 - val_loss: 0.2107 - val_accuracy: 0.9315\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9296 - val_loss: 0.2107 - val_accuracy: 0.9315\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9282 - val_loss: 0.2106 - val_accuracy: 0.9315\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9303 - val_loss: 0.2107 - val_accuracy: 0.9315\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2110 - accuracy: 0.9292 - val_loss: 0.2107 - val_accuracy: 0.9315\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9295 - val_loss: 0.2106 - val_accuracy: 0.9315\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9298 - val_loss: 0.2106 - val_accuracy: 0.9315\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9301 - val_loss: 0.2106 - val_accuracy: 0.9315\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9299 - val_loss: 0.2105 - val_accuracy: 0.9314\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9298 - val_loss: 0.2106 - val_accuracy: 0.9317\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.9299 - val_loss: 0.2105 - val_accuracy: 0.9314\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2108 - accuracy: 0.9292 - val_loss: 0.2105 - val_accuracy: 0.9314\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9312 - val_loss: 0.2105 - val_accuracy: 0.9314\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9293 - val_loss: 0.2104 - val_accuracy: 0.9317\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9295 - val_loss: 0.2104 - val_accuracy: 0.9315\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9300 - val_loss: 0.2105 - val_accuracy: 0.9315\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9304 - val_loss: 0.2105 - val_accuracy: 0.9315\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9303 - val_loss: 0.2105 - val_accuracy: 0.9315\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9307 - val_loss: 0.2105 - val_accuracy: 0.9314\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9300 - val_loss: 0.2105 - val_accuracy: 0.9315\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9312 - val_loss: 0.2105 - val_accuracy: 0.9317\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.9295 - val_loss: 0.2105 - val_accuracy: 0.9314\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9307 - val_loss: 0.2103 - val_accuracy: 0.9315\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9298 - val_loss: 0.2103 - val_accuracy: 0.9315\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9291 - val_loss: 0.2103 - val_accuracy: 0.9315\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9298 - val_loss: 0.2103 - val_accuracy: 0.9317\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2102 - accuracy: 0.9297 - val_loss: 0.2102 - val_accuracy: 0.9314\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9297 - val_loss: 0.2102 - val_accuracy: 0.9314\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9300 - val_loss: 0.2102 - val_accuracy: 0.9314\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9293 - val_loss: 0.2102 - val_accuracy: 0.9315\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9306 - val_loss: 0.2102 - val_accuracy: 0.9314\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9297 - val_loss: 0.2102 - val_accuracy: 0.9315\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9302 - val_loss: 0.2102 - val_accuracy: 0.9314\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9292 - val_loss: 0.2102 - val_accuracy: 0.9314\n",
      "Epoch 84/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9301 - val_loss: 0.2102 - val_accuracy: 0.9314\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9294 - val_loss: 0.2102 - val_accuracy: 0.9315\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.9306 - val_loss: 0.2101 - val_accuracy: 0.9315\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9306 - val_loss: 0.2102 - val_accuracy: 0.9315\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9303 - val_loss: 0.2101 - val_accuracy: 0.9317\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9301 - val_loss: 0.2101 - val_accuracy: 0.9317\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9295 - val_loss: 0.2102 - val_accuracy: 0.9317\n",
      "Epoch 91/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9294 - val_loss: 0.2102 - val_accuracy: 0.9315\n",
      "Epoch 92/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9300 - val_loss: 0.2102 - val_accuracy: 0.9315\n",
      "Epoch 93/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9306 - val_loss: 0.2102 - val_accuracy: 0.9315\n",
      "Epoch 94/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9296 - val_loss: 0.2103 - val_accuracy: 0.9315\n",
      "Epoch 95/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9304 - val_loss: 0.2102 - val_accuracy: 0.9315\n",
      "Epoch 96/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9298 - val_loss: 0.2103 - val_accuracy: 0.9315\n",
      "Epoch 97/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9305 - val_loss: 0.2102 - val_accuracy: 0.9315\n",
      "Epoch 98/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9304 - val_loss: 0.2102 - val_accuracy: 0.9315\n",
      "Epoch 99/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9300 - val_loss: 0.2102 - val_accuracy: 0.9317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9298 - val_loss: 0.2101 - val_accuracy: 0.9317\n",
      "Epoch 101/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9294 - val_loss: 0.2101 - val_accuracy: 0.9318\n",
      "Epoch 102/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9297 - val_loss: 0.2101 - val_accuracy: 0.9317\n",
      "Epoch 103/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9302 - val_loss: 0.2102 - val_accuracy: 0.9317\n",
      "Epoch 104/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9306 - val_loss: 0.2101 - val_accuracy: 0.9317\n",
      "Epoch 105/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9311 - val_loss: 0.2102 - val_accuracy: 0.9317\n",
      "Epoch 106/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9294 - val_loss: 0.2102 - val_accuracy: 0.9315\n",
      "Epoch 107/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9299 - val_loss: 0.2102 - val_accuracy: 0.9315\n",
      "Epoch 108/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9305 - val_loss: 0.2102 - val_accuracy: 0.9314\n",
      "Epoch 109/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9300 - val_loss: 0.2101 - val_accuracy: 0.9315\n",
      "Epoch 110/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9304 - val_loss: 0.2101 - val_accuracy: 0.9315\n",
      "Epoch 111/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9296 - val_loss: 0.2101 - val_accuracy: 0.9315\n",
      "Epoch 112/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9302 - val_loss: 0.2100 - val_accuracy: 0.9320\n",
      "Epoch 113/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9312 - val_loss: 0.2101 - val_accuracy: 0.9315\n",
      "Epoch 114/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9299 - val_loss: 0.2101 - val_accuracy: 0.9315\n",
      "Epoch 115/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9308 - val_loss: 0.2101 - val_accuracy: 0.9320\n",
      "Epoch 116/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9298 - val_loss: 0.2101 - val_accuracy: 0.9320\n",
      "Epoch 117/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9305 - val_loss: 0.2101 - val_accuracy: 0.9318\n",
      "Epoch 118/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9302 - val_loss: 0.2101 - val_accuracy: 0.9318\n",
      "Epoch 119/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9300 - val_loss: 0.2101 - val_accuracy: 0.9320\n",
      "Epoch 120/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9293 - val_loss: 0.2101 - val_accuracy: 0.9317\n",
      "Epoch 121/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9299 - val_loss: 0.2100 - val_accuracy: 0.9323\n",
      "Epoch 122/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9303 - val_loss: 0.2101 - val_accuracy: 0.9318\n",
      "Epoch 123/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9308 - val_loss: 0.2101 - val_accuracy: 0.9318\n",
      "Epoch 124/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9304 - val_loss: 0.2100 - val_accuracy: 0.9318\n",
      "Epoch 125/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9297 - val_loss: 0.2100 - val_accuracy: 0.9320\n",
      "Epoch 126/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9306 - val_loss: 0.2100 - val_accuracy: 0.9321\n",
      "Epoch 127/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9309 - val_loss: 0.2100 - val_accuracy: 0.9320\n",
      "Epoch 128/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9308 - val_loss: 0.2100 - val_accuracy: 0.9323\n",
      "Epoch 129/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9302 - val_loss: 0.2100 - val_accuracy: 0.9321\n",
      "Epoch 130/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9302 - val_loss: 0.2100 - val_accuracy: 0.9321\n",
      "Epoch 131/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9304 - val_loss: 0.2100 - val_accuracy: 0.9323\n",
      "Epoch 132/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2074 - accuracy: 0.9307 - val_loss: 0.2099 - val_accuracy: 0.9323\n",
      "Epoch 133/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9301 - val_loss: 0.2100 - val_accuracy: 0.9321\n",
      "Epoch 134/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2074 - accuracy: 0.9301 - val_loss: 0.2100 - val_accuracy: 0.9323\n",
      "Epoch 135/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9301 - val_loss: 0.2100 - val_accuracy: 0.9321\n",
      "Epoch 136/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2068 - accuracy: 0.9309 - val_loss: 0.2100 - val_accuracy: 0.9321\n",
      "Epoch 137/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9305 - val_loss: 0.2100 - val_accuracy: 0.9321\n",
      "Epoch 138/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9297 - val_loss: 0.2100 - val_accuracy: 0.9321\n",
      "Epoch 139/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9307 - val_loss: 0.2101 - val_accuracy: 0.9320\n",
      "Epoch 140/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9304 - val_loss: 0.2100 - val_accuracy: 0.9320\n",
      "Epoch 141/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9302 - val_loss: 0.2100 - val_accuracy: 0.9320\n",
      "Epoch 142/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9292 - val_loss: 0.2100 - val_accuracy: 0.9320\n",
      "Epoch 143/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9309 - val_loss: 0.2100 - val_accuracy: 0.9320\n",
      "Epoch 144/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9304 - val_loss: 0.2100 - val_accuracy: 0.9320\n",
      "Epoch 145/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9297 - val_loss: 0.2100 - val_accuracy: 0.9321\n",
      "Epoch 146/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9300 - val_loss: 0.2100 - val_accuracy: 0.9320\n",
      "Epoch 147/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9309 - val_loss: 0.2100 - val_accuracy: 0.9320\n",
      "Epoch 148/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9302 - val_loss: 0.2100 - val_accuracy: 0.9318\n",
      "Epoch 149/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9301 - val_loss: 0.2100 - val_accuracy: 0.9318\n",
      "Epoch 150/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9311 - val_loss: 0.2100 - val_accuracy: 0.9318\n",
      "Epoch 151/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9295 - val_loss: 0.2100 - val_accuracy: 0.9318\n",
      "Epoch 152/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9298 - val_loss: 0.2100 - val_accuracy: 0.9317\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.8112 - val_loss: 0.4824 - val_accuracy: 0.9185\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.9239 - val_loss: 0.3656 - val_accuracy: 0.9185\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.9253 - val_loss: 0.3028 - val_accuracy: 0.9240\n",
      "Epoch 4/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.9274 - val_loss: 0.2687 - val_accuracy: 0.9243\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2409 - accuracy: 0.9283 - val_loss: 0.2497 - val_accuracy: 0.9247\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.9283 - val_loss: 0.2387 - val_accuracy: 0.9263\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2210 - accuracy: 0.9294 - val_loss: 0.2315 - val_accuracy: 0.9268\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2182 - accuracy: 0.9302 - val_loss: 0.2270 - val_accuracy: 0.9272\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2160 - accuracy: 0.9300 - val_loss: 0.2241 - val_accuracy: 0.9271\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2148 - accuracy: 0.9304 - val_loss: 0.2220 - val_accuracy: 0.9272\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.9297 - val_loss: 0.2206 - val_accuracy: 0.9274\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9298 - val_loss: 0.2196 - val_accuracy: 0.9277\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2130 - accuracy: 0.9289 - val_loss: 0.2188 - val_accuracy: 0.9275\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2120 - accuracy: 0.9312 - val_loss: 0.2181 - val_accuracy: 0.9281\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2113 - accuracy: 0.9313 - val_loss: 0.2176 - val_accuracy: 0.9277\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.9299 - val_loss: 0.2172 - val_accuracy: 0.9278\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9308 - val_loss: 0.2169 - val_accuracy: 0.9275\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2121 - accuracy: 0.9298 - val_loss: 0.2167 - val_accuracy: 0.9277\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2110 - accuracy: 0.9308 - val_loss: 0.2165 - val_accuracy: 0.9277\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2114 - accuracy: 0.9295 - val_loss: 0.2163 - val_accuracy: 0.9277\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2107 - accuracy: 0.9306 - val_loss: 0.2161 - val_accuracy: 0.9271\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9300 - val_loss: 0.2160 - val_accuracy: 0.9272\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9307 - val_loss: 0.2159 - val_accuracy: 0.9269\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2110 - accuracy: 0.9302 - val_loss: 0.2158 - val_accuracy: 0.9269\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9306 - val_loss: 0.2157 - val_accuracy: 0.9266\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2110 - accuracy: 0.9297 - val_loss: 0.2156 - val_accuracy: 0.9266\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2108 - accuracy: 0.9299 - val_loss: 0.2156 - val_accuracy: 0.9268\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9315 - val_loss: 0.2155 - val_accuracy: 0.9266\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9313 - val_loss: 0.2155 - val_accuracy: 0.9269\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9309 - val_loss: 0.2154 - val_accuracy: 0.9266\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9305 - val_loss: 0.2154 - val_accuracy: 0.9266\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9309 - val_loss: 0.2153 - val_accuracy: 0.9266\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9307 - val_loss: 0.2151 - val_accuracy: 0.9266\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9296 - val_loss: 0.2151 - val_accuracy: 0.9265\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2102 - accuracy: 0.9307 - val_loss: 0.2150 - val_accuracy: 0.9265\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9312 - val_loss: 0.2151 - val_accuracy: 0.9265\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9306 - val_loss: 0.2150 - val_accuracy: 0.9269\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9303 - val_loss: 0.2150 - val_accuracy: 0.9265\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9316 - val_loss: 0.2149 - val_accuracy: 0.9269\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.9314 - val_loss: 0.2149 - val_accuracy: 0.9269\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9307 - val_loss: 0.2149 - val_accuracy: 0.9269\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9309 - val_loss: 0.2149 - val_accuracy: 0.9269\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9314 - val_loss: 0.2149 - val_accuracy: 0.9269\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9311 - val_loss: 0.2149 - val_accuracy: 0.9269\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2102 - accuracy: 0.9306 - val_loss: 0.2149 - val_accuracy: 0.9269\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9307 - val_loss: 0.2149 - val_accuracy: 0.9271\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9293 - val_loss: 0.2149 - val_accuracy: 0.9269\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9308 - val_loss: 0.2149 - val_accuracy: 0.9268\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9304 - val_loss: 0.2149 - val_accuracy: 0.9268\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9315 - val_loss: 0.2149 - val_accuracy: 0.9269\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9313 - val_loss: 0.2148 - val_accuracy: 0.9269\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9308 - val_loss: 0.2148 - val_accuracy: 0.9269\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9308 - val_loss: 0.2148 - val_accuracy: 0.9269\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9306 - val_loss: 0.2148 - val_accuracy: 0.9268\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9316 - val_loss: 0.2148 - val_accuracy: 0.9266\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9317 - val_loss: 0.2147 - val_accuracy: 0.9266\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9300 - val_loss: 0.2147 - val_accuracy: 0.9268\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9316 - val_loss: 0.2146 - val_accuracy: 0.9266\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9312 - val_loss: 0.2146 - val_accuracy: 0.9266\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9313 - val_loss: 0.2146 - val_accuracy: 0.9266\n",
      "Epoch 61/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9316 - val_loss: 0.2146 - val_accuracy: 0.9268\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9310 - val_loss: 0.2146 - val_accuracy: 0.9266\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9307 - val_loss: 0.2146 - val_accuracy: 0.9268\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9313 - val_loss: 0.2146 - val_accuracy: 0.9265\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9306 - val_loss: 0.2146 - val_accuracy: 0.9265\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9316 - val_loss: 0.2146 - val_accuracy: 0.9265\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9313 - val_loss: 0.2146 - val_accuracy: 0.9262\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9307 - val_loss: 0.2147 - val_accuracy: 0.9263\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9317 - val_loss: 0.2147 - val_accuracy: 0.9262\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9312 - val_loss: 0.2147 - val_accuracy: 0.9262\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9307 - val_loss: 0.2147 - val_accuracy: 0.9261\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9323 - val_loss: 0.2146 - val_accuracy: 0.9265\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9318 - val_loss: 0.2146 - val_accuracy: 0.9259\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2069 - accuracy: 0.9317 - val_loss: 0.2146 - val_accuracy: 0.9262\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9321 - val_loss: 0.2146 - val_accuracy: 0.9262\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2074 - accuracy: 0.9317 - val_loss: 0.2146 - val_accuracy: 0.9262\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9310 - val_loss: 0.2146 - val_accuracy: 0.9263\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9301 - val_loss: 0.2146 - val_accuracy: 0.9263\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9316 - val_loss: 0.2146 - val_accuracy: 0.9259\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2068 - accuracy: 0.9320 - val_loss: 0.2146 - val_accuracy: 0.9262\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9307 - val_loss: 0.2147 - val_accuracy: 0.9263\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2067 - accuracy: 0.9317 - val_loss: 0.2146 - val_accuracy: 0.9263\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9311 - val_loss: 0.2146 - val_accuracy: 0.9262\n",
      "Epoch 84/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9326 - val_loss: 0.2146 - val_accuracy: 0.9262\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9315 - val_loss: 0.2146 - val_accuracy: 0.9262\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9317 - val_loss: 0.2145 - val_accuracy: 0.9262\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2075 - accuracy: 0.9322 - val_loss: 0.2146 - val_accuracy: 0.9262\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9314 - val_loss: 0.2146 - val_accuracy: 0.9262\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9312 - val_loss: 0.2146 - val_accuracy: 0.9262\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9316 - val_loss: 0.2147 - val_accuracy: 0.9259\n",
      "Epoch 91/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9317 - val_loss: 0.2147 - val_accuracy: 0.9259\n",
      "Epoch 92/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9311 - val_loss: 0.2147 - val_accuracy: 0.9259\n",
      "Epoch 93/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9318 - val_loss: 0.2147 - val_accuracy: 0.9262\n",
      "Epoch 94/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9306 - val_loss: 0.2147 - val_accuracy: 0.9262\n",
      "Epoch 95/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9315 - val_loss: 0.2148 - val_accuracy: 0.9259\n",
      "Epoch 96/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9316 - val_loss: 0.2147 - val_accuracy: 0.9262\n",
      "Epoch 97/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2074 - accuracy: 0.9316 - val_loss: 0.2147 - val_accuracy: 0.9261\n",
      "Epoch 98/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9320 - val_loss: 0.2147 - val_accuracy: 0.9259\n",
      "Epoch 99/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9314 - val_loss: 0.2147 - val_accuracy: 0.9262\n",
      "Epoch 100/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9312 - val_loss: 0.2147 - val_accuracy: 0.9259\n",
      "Epoch 101/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9311 - val_loss: 0.2146 - val_accuracy: 0.9259\n",
      "Epoch 102/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2074 - accuracy: 0.9323 - val_loss: 0.2147 - val_accuracy: 0.9262\n",
      "Epoch 103/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9313 - val_loss: 0.2147 - val_accuracy: 0.9256\n",
      "Epoch 104/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9323 - val_loss: 0.2147 - val_accuracy: 0.9259\n",
      "Epoch 105/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9305 - val_loss: 0.2147 - val_accuracy: 0.9258\n",
      "Epoch 106/300\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2069 - accuracy: 0.9321 - val_loss: 0.2147 - val_accuracy: 0.9256\n",
      "logloss: 0.2071\n"
     ]
    }
   ],
   "source": [
    "model_2_a = Model1NN5proba()\n",
    "pred_train_2_a, pred_test_2_a = predict_cv(model_2_a, train_x_2, train_y, test_x_2)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2_a, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(train_y,pred_train_2_a)\n",
    "auc_score = roc_auc_score(train_y,pred_train_2_a)\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC curve/AUC Score : {auc_score}')\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.731207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.052832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.046649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.010430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.076071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18045</th>\n",
       "      <td>18045</td>\n",
       "      <td>0.016874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18046</th>\n",
       "      <td>18046</td>\n",
       "      <td>0.011486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18047</th>\n",
       "      <td>18047</td>\n",
       "      <td>0.058700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18048</th>\n",
       "      <td>18048</td>\n",
       "      <td>0.012311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18049</th>\n",
       "      <td>18049</td>\n",
       "      <td>0.095717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18050 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         y\n",
       "0          0  0.731207\n",
       "1          1  0.052832\n",
       "2          2  0.046649\n",
       "3          3  0.010430\n",
       "4          4  0.076071\n",
       "...      ...       ...\n",
       "18045  18045  0.016874\n",
       "18046  18046  0.011486\n",
       "18047  18047  0.058700\n",
       "18048  18048  0.012311\n",
       "18049  18049  0.095717\n",
       "\n",
       "[18050 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\test.csv')\n",
    "id = test['id']\n",
    "pred = pd.DataFrame(pred_test_2_a)\n",
    "submit = pd.concat([id,pred], axis=1)\n",
    "submit.columns = ['id', 'y']\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('normal_data_stacking.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                           | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: X has 8 features, but this StandardScaler is expecting 7 features as input.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/10 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 8 features, but this StandardScaler is expecting 7 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-943da851d587>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[0mtrials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m \u001b[0mfmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;31m# \u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m         )\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m         )\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    284\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    892\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             )\n\u001b[1;32m--> 894\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-85-943da851d587>\u001b[0m in \u001b[0;36mscore\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;31m# \u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mva_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mva_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[0mva_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mva_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mva_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mva_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-85-943da851d587>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, tr_x, tr_y, va_x, va_y)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mtr_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mva_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mva_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    792\u001b[0m                                 \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m                                 force_all_finite='allow-nan')\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    378\u001b[0m                     \u001b[1;34m'X has {} features, but this {} is expecting {} features '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                     'as input.'.format(n_features, self.__class__.__name__,\n\u001b[1;32m--> 380\u001b[1;33m                                        self.n_features_in_)\n\u001b[0m\u001b[0;32m    381\u001b[0m                 )\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 8 features, but this StandardScaler is expecting 7 features as input."
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "tr_idx, va_idx = list(kf.split(train_x_2_2))[0]\n",
    "tr_x, va_x = train_x_2_2.iloc[tr_idx], train_x_2_2.iloc[va_idx]\n",
    "tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "# tensorflow\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# -----------------------------------\n",
    "# \n",
    "# -----------------------------------\n",
    "from hyperopt import hp\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.advanced_activations import ReLU, PReLU\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# \n",
    "base_param = {\n",
    "    'input_dropout': 0.0,\n",
    "    'hidden_layers': 3,\n",
    "    'hidden_units': 96,\n",
    "    'hidden_activation': 'relu',\n",
    "    'hidden_dropout': 0.2,\n",
    "    'batch_norm': 'before_act',\n",
    "    'optimizer': {'type': 'adam', 'lr': 0.001},\n",
    "    'batch_size': 64,\n",
    "}\n",
    "\n",
    "# \n",
    "param_space = {\n",
    "    'input_dropout': hp.quniform('input_dropout', 0, 0.2, 0.05),\n",
    "    'hidden_layers': hp.quniform('hidden_layers', 2, 4, 1),\n",
    "    'hidden_units': hp.quniform('hidden_units', 32, 256, 32),\n",
    "    'hidden_activation': hp.choice('hidden_activation', ['prelu', 'relu']),\n",
    "    'hidden_dropout': hp.quniform('hidden_dropout', 0, 0.3, 0.05),\n",
    "    'batch_norm': hp.choice('batch_norm', ['before_act', 'no']),\n",
    "    'optimizer': hp.choice('optimizer',\n",
    "                           [{'type': 'adam',\n",
    "                             'lr': hp.loguniform('adam_lr', np.log(0.00001), np.log(0.01))},\n",
    "                            {'type': 'sgd',\n",
    "                             'lr': hp.loguniform('sgd_lr', np.log(0.00001), np.log(0.01))}]),\n",
    "    'batch_size': hp.quniform('batch_size', 32, 128, 32),\n",
    "}\n",
    "\n",
    "\n",
    "class MLP:\n",
    "\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.scaler = None\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "\n",
    "        # \n",
    "        input_dropout = self.params['input_dropout']\n",
    "        hidden_layers = int(self.params['hidden_layers'])\n",
    "        hidden_units = int(self.params['hidden_units'])\n",
    "        hidden_activation = self.params['hidden_activation']\n",
    "        hidden_dropout = self.params['hidden_dropout']\n",
    "        batch_norm = self.params['batch_norm']\n",
    "        optimizer_type = self.params['optimizer']['type']\n",
    "        optimizer_lr = self.params['optimizer']['lr']\n",
    "        batch_size = int(self.params['batch_size'])\n",
    "\n",
    "        # \n",
    "        self.scaler = StandardScaler()\n",
    "        tr_x = self.scaler.fit_transform(tr_x)\n",
    "        va_x = self.scaler.transform(va_x)\n",
    "\n",
    "        self.model = Sequential()\n",
    "\n",
    "        # \n",
    "        self.model.add(Dropout(input_dropout, input_shape=(tr_x.shape[1],)))\n",
    "\n",
    "        # \n",
    "        for i in range(hidden_layers):\n",
    "            self.model.add(Dense(hidden_units))\n",
    "            if batch_norm == 'before_act':\n",
    "                self.model.add(BatchNormalization())\n",
    "            if hidden_activation == 'prelu':\n",
    "                self.model.add(PReLU())\n",
    "            elif hidden_activation == 'relu':\n",
    "                self.model.add(ReLU())\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            self.model.add(Dropout(hidden_dropout))\n",
    "\n",
    "        # \n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # \n",
    "        if optimizer_type == 'sgd':\n",
    "            optimizer = SGD(lr=optimizer_lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        elif optimizer_type == 'adam':\n",
    "            optimizer = Adam(lr=optimizer_lr, beta_1=0.9, beta_2=0.999, decay=0.)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # \n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # \n",
    "        # epoch\n",
    "        nb_epoch = 200\n",
    "        patience = 20\n",
    "        early_stopping = EarlyStopping(patience=patience, restore_best_weights=True)\n",
    "\n",
    "        # \n",
    "        history = self.model.fit(tr_x, tr_y,\n",
    "                                 epochs=nb_epoch,\n",
    "                                 batch_size=batch_size, verbose=1,\n",
    "                                 validation_data=(va_x, va_y),\n",
    "                                 callbacks=[early_stopping])\n",
    "\n",
    "    def predict(self, x):\n",
    "        # \n",
    "        x = self.scaler.transform(x)\n",
    "        y_pred = self.model.predict(x)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "# \n",
    "\n",
    "from hyperopt import fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "def score(params):\n",
    "    # \n",
    "    # \n",
    "    model = MLP(params)\n",
    "    model.fit(tr_x, tr_y, va_x, va_y)\n",
    "    va_pred = model.predict(va_x)\n",
    "    score = log_loss(va_y, va_pred)\n",
    "    print(f'params: {params}, logloss: {score:.4f}')\n",
    "\n",
    "    # \n",
    "    history.append((params, score))\n",
    "\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# hyperopt\n",
    "max_evals = 10\n",
    "trials = Trials()\n",
    "history = []\n",
    "fmin(score, param_space, algo=tpe.suggest, trials=trials, max_evals=max_evals)\n",
    "\n",
    "# \n",
    "# trials\n",
    "history = sorted(history, key=lambda tpl: tpl[1])\n",
    "best = history[0]\n",
    "print(f'best params:{best[0]}, score:{best[1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1NN5proba:\n",
    "  def __init__(self):\n",
    "    self.model = None\n",
    "    self.scaler =None\n",
    "  \n",
    "  def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "    self.scaler = StandardScaler()\n",
    "    self.scaler.fit(tr_x)\n",
    "    batch_size = 128\n",
    "    epochs = 300\n",
    "    tr_x = self.scaler.transform(tr_x)\n",
    "    va_x = self.scaler.transform(va_x)\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.15000000000000002, input_shape=(tr_x.shape[1],)))\n",
    "    model.add(Dense(96,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(96,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = SGD(lr=0.0004400288024095838, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "    history = model.fit(tr_x,tr_y,\n",
    "    batch_size=batch_size, epochs=epochs,verbose=1,validation_data = (va_x,va_y),\n",
    "    callbacks=[early_stopping])\n",
    "    self.model = model\n",
    "\n",
    "\n",
    "  def predict(self,x):\n",
    "    x = self.scaler.transform(x)\n",
    "    y_pred = self.model.predict_proba(x).reshape(-1)\n",
    "    return y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python37164bit745322e800af484d9e7663a15d4e0767"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
