{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso,Ridge\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers.advanced_activations import ReLU, PReLU\n",
    "from keras.optimizers import SGD, Adam\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\dataset\\\\train_x_xgboost.csv')\n",
    "train_y = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\dataset\\\\train_y_xgboost.csv')\n",
    "test_x = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\dataset\\\\test_x_xgboost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_nn = pd.read_csv('.//dataset//train_x_NN.csv')\n",
    "train_y_nn = pd.read_csv('.//dataset//train_y_NN.csv')\n",
    "test_x_nn = pd.read_csv('.//dataset//test_x_NN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Model1xgb,Model1xgb2, Model1NNproba,Model1NN2proba,Model1ramdom,Model2KMeans,Model2KNN,Model3logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv_classfier(model,train_x, train_y, test_x):\n",
    "    \n",
    "\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state= 71)\n",
    "    for i , (tr_idx, va_idx) in enumerate (kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "\n",
    "    tmp = np.stack(preds_test, axis =1)\n",
    "    mode_test, mode_counts = mode(tmp, axis=1)\n",
    "\n",
    "    preds_test = mode_test\n",
    "    preds_size = preds_test.shape[0]\n",
    "    preds_test = preds_test.reshape(preds_size,)\n",
    "    \n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv(model, train_x, train_y, test_x):\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "    \n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "    for i , (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "        \n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "    \n",
    "    preds_test = np.mean(preds_test, axis=0)\n",
    "    \n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNNを省いた"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:25:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06799\teval-error:0.07055\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06824\teval-error:0.07041\n",
      "[2]\ttrain-error:0.06760\teval-error:0.07070\n",
      "[3]\ttrain-error:0.06819\teval-error:0.07026\n",
      "[4]\ttrain-error:0.06716\teval-error:0.07011\n",
      "[5]\ttrain-error:0.06770\teval-error:0.06922\n",
      "[6]\ttrain-error:0.06731\teval-error:0.06937\n",
      "[7]\ttrain-error:0.06750\teval-error:0.06937\n",
      "[8]\ttrain-error:0.06741\teval-error:0.06967\n",
      "[9]\ttrain-error:0.06735\teval-error:0.06922\n",
      "[10]\ttrain-error:0.06701\teval-error:0.06864\n",
      "[11]\ttrain-error:0.06691\teval-error:0.06834\n",
      "[12]\ttrain-error:0.06677\teval-error:0.06804\n",
      "[13]\ttrain-error:0.06701\teval-error:0.06760\n",
      "[14]\ttrain-error:0.06696\teval-error:0.06731\n",
      "[15]\ttrain-error:0.06701\teval-error:0.06686\n",
      "[16]\ttrain-error:0.06657\teval-error:0.06672\n",
      "[17]\ttrain-error:0.06686\teval-error:0.06701\n",
      "[18]\ttrain-error:0.06677\teval-error:0.06657\n",
      "[19]\ttrain-error:0.06662\teval-error:0.06716\n",
      "[20]\ttrain-error:0.06657\teval-error:0.06657\n",
      "[21]\ttrain-error:0.06657\teval-error:0.06657\n",
      "[22]\ttrain-error:0.06637\teval-error:0.06642\n",
      "[23]\ttrain-error:0.06657\teval-error:0.06642\n",
      "[24]\ttrain-error:0.06632\teval-error:0.06657\n",
      "[25]\ttrain-error:0.06608\teval-error:0.06672\n",
      "[26]\ttrain-error:0.06613\teval-error:0.06686\n",
      "[27]\ttrain-error:0.06603\teval-error:0.06731\n",
      "[28]\ttrain-error:0.06583\teval-error:0.06701\n",
      "[29]\ttrain-error:0.06568\teval-error:0.06716\n",
      "[30]\ttrain-error:0.06573\teval-error:0.06672\n",
      "[31]\ttrain-error:0.06544\teval-error:0.06627\n",
      "[32]\ttrain-error:0.06534\teval-error:0.06598\n",
      "[33]\ttrain-error:0.06524\teval-error:0.06627\n",
      "[34]\ttrain-error:0.06504\teval-error:0.06627\n",
      "[35]\ttrain-error:0.06509\teval-error:0.06583\n",
      "[36]\ttrain-error:0.06475\teval-error:0.06598\n",
      "[37]\ttrain-error:0.06460\teval-error:0.06598\n",
      "[38]\ttrain-error:0.06455\teval-error:0.06539\n",
      "[39]\ttrain-error:0.06445\teval-error:0.06524\n",
      "[40]\ttrain-error:0.06426\teval-error:0.06524\n",
      "[41]\ttrain-error:0.06401\teval-error:0.06539\n",
      "[42]\ttrain-error:0.06386\teval-error:0.06509\n",
      "[43]\ttrain-error:0.06357\teval-error:0.06539\n",
      "[44]\ttrain-error:0.06312\teval-error:0.06524\n",
      "[45]\ttrain-error:0.06298\teval-error:0.06553\n",
      "[46]\ttrain-error:0.06308\teval-error:0.06568\n",
      "[47]\ttrain-error:0.06288\teval-error:0.06568\n",
      "[48]\ttrain-error:0.06273\teval-error:0.06568\n",
      "[49]\ttrain-error:0.06278\teval-error:0.06568\n",
      "[50]\ttrain-error:0.06258\teval-error:0.06568\n",
      "[51]\ttrain-error:0.06234\teval-error:0.06583\n",
      "[52]\ttrain-error:0.06180\teval-error:0.06568\n",
      "[53]\ttrain-error:0.06170\teval-error:0.06553\n",
      "[54]\ttrain-error:0.06150\teval-error:0.06568\n",
      "[55]\ttrain-error:0.06130\teval-error:0.06583\n",
      "[56]\ttrain-error:0.06125\teval-error:0.06539\n",
      "[57]\ttrain-error:0.06125\teval-error:0.06524\n",
      "[58]\ttrain-error:0.06135\teval-error:0.06524\n",
      "[59]\ttrain-error:0.06145\teval-error:0.06539\n",
      "[60]\ttrain-error:0.06091\teval-error:0.06495\n",
      "[61]\ttrain-error:0.06066\teval-error:0.06524\n",
      "[62]\ttrain-error:0.06052\teval-error:0.06524\n",
      "[63]\ttrain-error:0.06047\teval-error:0.06553\n",
      "[64]\ttrain-error:0.06052\teval-error:0.06568\n",
      "[65]\ttrain-error:0.06042\teval-error:0.06583\n",
      "[66]\ttrain-error:0.06022\teval-error:0.06539\n",
      "[67]\ttrain-error:0.06003\teval-error:0.06495\n",
      "[68]\ttrain-error:0.05988\teval-error:0.06509\n",
      "[69]\ttrain-error:0.06012\teval-error:0.06480\n",
      "[70]\ttrain-error:0.05998\teval-error:0.06509\n",
      "[71]\ttrain-error:0.05988\teval-error:0.06539\n",
      "[72]\ttrain-error:0.05963\teval-error:0.06539\n",
      "[73]\ttrain-error:0.05953\teval-error:0.06509\n",
      "[74]\ttrain-error:0.05924\teval-error:0.06524\n",
      "[75]\ttrain-error:0.05914\teval-error:0.06524\n",
      "[76]\ttrain-error:0.05914\teval-error:0.06539\n",
      "[77]\ttrain-error:0.05889\teval-error:0.06539\n",
      "[78]\ttrain-error:0.05880\teval-error:0.06539\n",
      "[79]\ttrain-error:0.05874\teval-error:0.06539\n",
      "[80]\ttrain-error:0.05840\teval-error:0.06583\n",
      "[81]\ttrain-error:0.05811\teval-error:0.06553\n",
      "[82]\ttrain-error:0.05806\teval-error:0.06553\n",
      "[83]\ttrain-error:0.05796\teval-error:0.06553\n",
      "[84]\ttrain-error:0.05781\teval-error:0.06568\n",
      "[85]\ttrain-error:0.05776\teval-error:0.06568\n",
      "[86]\ttrain-error:0.05761\teval-error:0.06568\n",
      "[87]\ttrain-error:0.05766\teval-error:0.06539\n",
      "[88]\ttrain-error:0.05737\teval-error:0.06553\n",
      "[89]\ttrain-error:0.05727\teval-error:0.06553\n",
      "Stopping. Best iteration:\n",
      "[69]\ttrain-error:0.06012\teval-error:0.06480\n",
      "\n",
      "[14:25:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06780\teval-error:0.07188\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06790\teval-error:0.07173\n",
      "[2]\ttrain-error:0.06785\teval-error:0.07114\n",
      "[3]\ttrain-error:0.06780\teval-error:0.07129\n",
      "[4]\ttrain-error:0.06775\teval-error:0.07114\n",
      "[5]\ttrain-error:0.06770\teval-error:0.07129\n",
      "[6]\ttrain-error:0.06750\teval-error:0.07070\n",
      "[7]\ttrain-error:0.06741\teval-error:0.07129\n",
      "[8]\ttrain-error:0.06735\teval-error:0.07114\n",
      "[9]\ttrain-error:0.06716\teval-error:0.07085\n",
      "[10]\ttrain-error:0.06691\teval-error:0.07114\n",
      "[11]\ttrain-error:0.06677\teval-error:0.07041\n",
      "[12]\ttrain-error:0.06647\teval-error:0.06982\n",
      "[13]\ttrain-error:0.06642\teval-error:0.06996\n",
      "[14]\ttrain-error:0.06617\teval-error:0.06996\n",
      "[15]\ttrain-error:0.06608\teval-error:0.06908\n",
      "[16]\ttrain-error:0.06627\teval-error:0.06922\n",
      "[17]\ttrain-error:0.06622\teval-error:0.06922\n",
      "[18]\ttrain-error:0.06603\teval-error:0.06922\n",
      "[19]\ttrain-error:0.06578\teval-error:0.06922\n",
      "[20]\ttrain-error:0.06598\teval-error:0.06952\n",
      "[21]\ttrain-error:0.06603\teval-error:0.06982\n",
      "[22]\ttrain-error:0.06593\teval-error:0.06967\n",
      "[23]\ttrain-error:0.06593\teval-error:0.06937\n",
      "[24]\ttrain-error:0.06583\teval-error:0.06952\n",
      "[25]\ttrain-error:0.06553\teval-error:0.06952\n",
      "[26]\ttrain-error:0.06568\teval-error:0.06952\n",
      "[27]\ttrain-error:0.06563\teval-error:0.06952\n",
      "[28]\ttrain-error:0.06544\teval-error:0.06967\n",
      "[29]\ttrain-error:0.06544\teval-error:0.06952\n",
      "[30]\ttrain-error:0.06544\teval-error:0.06952\n",
      "[31]\ttrain-error:0.06499\teval-error:0.06967\n",
      "[32]\ttrain-error:0.06480\teval-error:0.06982\n",
      "[33]\ttrain-error:0.06455\teval-error:0.06937\n",
      "[34]\ttrain-error:0.06470\teval-error:0.06937\n",
      "[35]\ttrain-error:0.06460\teval-error:0.06937\n",
      "Stopping. Best iteration:\n",
      "[15]\ttrain-error:0.06608\teval-error:0.06908\n",
      "\n",
      "[14:25:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06775\teval-error:0.07262\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06741\teval-error:0.07306\n",
      "[2]\ttrain-error:0.06745\teval-error:0.07306\n",
      "[3]\ttrain-error:0.06745\teval-error:0.07262\n",
      "[4]\ttrain-error:0.06735\teval-error:0.07203\n",
      "[5]\ttrain-error:0.06735\teval-error:0.07173\n",
      "[6]\ttrain-error:0.06711\teval-error:0.07188\n",
      "[7]\ttrain-error:0.06711\teval-error:0.07173\n",
      "[8]\ttrain-error:0.06711\teval-error:0.07129\n",
      "[9]\ttrain-error:0.06696\teval-error:0.07085\n",
      "[10]\ttrain-error:0.06667\teval-error:0.07085\n",
      "[11]\ttrain-error:0.06652\teval-error:0.07055\n",
      "[12]\ttrain-error:0.06657\teval-error:0.07085\n",
      "[13]\ttrain-error:0.06632\teval-error:0.07085\n",
      "[14]\ttrain-error:0.06627\teval-error:0.07085\n",
      "[15]\ttrain-error:0.06642\teval-error:0.07129\n",
      "[16]\ttrain-error:0.06647\teval-error:0.07114\n",
      "[17]\ttrain-error:0.06622\teval-error:0.07085\n",
      "[18]\ttrain-error:0.06622\teval-error:0.07114\n",
      "[19]\ttrain-error:0.06642\teval-error:0.07114\n",
      "[20]\ttrain-error:0.06642\teval-error:0.07100\n",
      "[21]\ttrain-error:0.06632\teval-error:0.07100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\ttrain-error:0.06622\teval-error:0.07100\n",
      "[23]\ttrain-error:0.06622\teval-error:0.07100\n",
      "[24]\ttrain-error:0.06632\teval-error:0.07055\n",
      "[25]\ttrain-error:0.06637\teval-error:0.07041\n",
      "[26]\ttrain-error:0.06627\teval-error:0.07070\n",
      "[27]\ttrain-error:0.06617\teval-error:0.07026\n",
      "[28]\ttrain-error:0.06632\teval-error:0.07055\n",
      "[29]\ttrain-error:0.06608\teval-error:0.07070\n",
      "[30]\ttrain-error:0.06593\teval-error:0.07055\n",
      "[31]\ttrain-error:0.06568\teval-error:0.07041\n",
      "[32]\ttrain-error:0.06553\teval-error:0.07085\n",
      "[33]\ttrain-error:0.06534\teval-error:0.07070\n",
      "[34]\ttrain-error:0.06519\teval-error:0.07026\n",
      "[35]\ttrain-error:0.06495\teval-error:0.07070\n",
      "[36]\ttrain-error:0.06499\teval-error:0.07100\n",
      "[37]\ttrain-error:0.06485\teval-error:0.07070\n",
      "[38]\ttrain-error:0.06460\teval-error:0.07085\n",
      "[39]\ttrain-error:0.06431\teval-error:0.07070\n",
      "[40]\ttrain-error:0.06406\teval-error:0.07100\n",
      "[41]\ttrain-error:0.06391\teval-error:0.07100\n",
      "[42]\ttrain-error:0.06376\teval-error:0.07085\n",
      "[43]\ttrain-error:0.06376\teval-error:0.07085\n",
      "[44]\ttrain-error:0.06342\teval-error:0.07041\n",
      "[45]\ttrain-error:0.06332\teval-error:0.07055\n",
      "[46]\ttrain-error:0.06327\teval-error:0.07055\n",
      "[47]\ttrain-error:0.06298\teval-error:0.07041\n",
      "Stopping. Best iteration:\n",
      "[27]\ttrain-error:0.06617\teval-error:0.07026\n",
      "\n",
      "[14:25:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06686\teval-error:0.07572\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06677\teval-error:0.07542\n",
      "[2]\ttrain-error:0.06642\teval-error:0.07439\n",
      "[3]\ttrain-error:0.06627\teval-error:0.07410\n",
      "[4]\ttrain-error:0.06667\teval-error:0.07439\n",
      "[5]\ttrain-error:0.06627\teval-error:0.07454\n",
      "[6]\ttrain-error:0.06642\teval-error:0.07498\n",
      "[7]\ttrain-error:0.06598\teval-error:0.07454\n",
      "[8]\ttrain-error:0.06608\teval-error:0.07454\n",
      "[9]\ttrain-error:0.06578\teval-error:0.07410\n",
      "[10]\ttrain-error:0.06539\teval-error:0.07424\n",
      "[11]\ttrain-error:0.06549\teval-error:0.07469\n",
      "[12]\ttrain-error:0.06544\teval-error:0.07454\n",
      "[13]\ttrain-error:0.06553\teval-error:0.07424\n",
      "[14]\ttrain-error:0.06558\teval-error:0.07410\n",
      "[15]\ttrain-error:0.06534\teval-error:0.07439\n",
      "[16]\ttrain-error:0.06509\teval-error:0.07424\n",
      "[17]\ttrain-error:0.06475\teval-error:0.07424\n",
      "[18]\ttrain-error:0.06480\teval-error:0.07439\n",
      "[19]\ttrain-error:0.06480\teval-error:0.07439\n",
      "[20]\ttrain-error:0.06480\teval-error:0.07439\n",
      "[21]\ttrain-error:0.06470\teval-error:0.07410\n",
      "[22]\ttrain-error:0.06450\teval-error:0.07380\n",
      "[23]\ttrain-error:0.06440\teval-error:0.07395\n",
      "[24]\ttrain-error:0.06435\teval-error:0.07410\n",
      "[25]\ttrain-error:0.06401\teval-error:0.07380\n",
      "[26]\ttrain-error:0.06416\teval-error:0.07424\n",
      "[27]\ttrain-error:0.06411\teval-error:0.07454\n",
      "[28]\ttrain-error:0.06396\teval-error:0.07424\n",
      "[29]\ttrain-error:0.06362\teval-error:0.07424\n",
      "[30]\ttrain-error:0.06366\teval-error:0.07454\n",
      "[31]\ttrain-error:0.06337\teval-error:0.07380\n",
      "[32]\ttrain-error:0.06322\teval-error:0.07380\n",
      "[33]\ttrain-error:0.06308\teval-error:0.07365\n",
      "[34]\ttrain-error:0.06312\teval-error:0.07336\n",
      "[35]\ttrain-error:0.06312\teval-error:0.07336\n",
      "[36]\ttrain-error:0.06308\teval-error:0.07321\n",
      "[37]\ttrain-error:0.06303\teval-error:0.07336\n",
      "[38]\ttrain-error:0.06278\teval-error:0.07306\n",
      "[39]\ttrain-error:0.06229\teval-error:0.07336\n",
      "[40]\ttrain-error:0.06229\teval-error:0.07336\n",
      "[41]\ttrain-error:0.06209\teval-error:0.07351\n",
      "[42]\ttrain-error:0.06189\teval-error:0.07321\n",
      "[43]\ttrain-error:0.06150\teval-error:0.07336\n",
      "[44]\ttrain-error:0.06125\teval-error:0.07306\n",
      "[45]\ttrain-error:0.06111\teval-error:0.07306\n",
      "[46]\ttrain-error:0.06125\teval-error:0.07321\n",
      "[47]\ttrain-error:0.06111\teval-error:0.07336\n",
      "[48]\ttrain-error:0.06086\teval-error:0.07380\n",
      "[49]\ttrain-error:0.06076\teval-error:0.07351\n",
      "[50]\ttrain-error:0.06066\teval-error:0.07306\n",
      "[51]\ttrain-error:0.06052\teval-error:0.07291\n",
      "[52]\ttrain-error:0.06042\teval-error:0.07277\n",
      "[53]\ttrain-error:0.06042\teval-error:0.07321\n",
      "[54]\ttrain-error:0.06032\teval-error:0.07306\n",
      "[55]\ttrain-error:0.05988\teval-error:0.07306\n",
      "[56]\ttrain-error:0.05988\teval-error:0.07321\n",
      "[57]\ttrain-error:0.05988\teval-error:0.07321\n",
      "[58]\ttrain-error:0.05968\teval-error:0.07306\n",
      "[59]\ttrain-error:0.05958\teval-error:0.07306\n",
      "[60]\ttrain-error:0.05943\teval-error:0.07306\n",
      "[61]\ttrain-error:0.05904\teval-error:0.07291\n",
      "[62]\ttrain-error:0.05899\teval-error:0.07277\n",
      "[63]\ttrain-error:0.05889\teval-error:0.07262\n",
      "[64]\ttrain-error:0.05870\teval-error:0.07262\n",
      "[65]\ttrain-error:0.05820\teval-error:0.07247\n",
      "[66]\ttrain-error:0.05825\teval-error:0.07247\n",
      "[67]\ttrain-error:0.05815\teval-error:0.07262\n",
      "[68]\ttrain-error:0.05815\teval-error:0.07247\n",
      "[69]\ttrain-error:0.05786\teval-error:0.07233\n",
      "[70]\ttrain-error:0.05756\teval-error:0.07218\n",
      "[71]\ttrain-error:0.05751\teval-error:0.07233\n",
      "[72]\ttrain-error:0.05756\teval-error:0.07218\n",
      "[73]\ttrain-error:0.05737\teval-error:0.07203\n",
      "[74]\ttrain-error:0.05737\teval-error:0.07203\n",
      "[75]\ttrain-error:0.05717\teval-error:0.07188\n",
      "[76]\ttrain-error:0.05717\teval-error:0.07188\n",
      "[77]\ttrain-error:0.05678\teval-error:0.07218\n",
      "[78]\ttrain-error:0.05658\teval-error:0.07218\n",
      "[79]\ttrain-error:0.05653\teval-error:0.07218\n",
      "[80]\ttrain-error:0.05648\teval-error:0.07218\n",
      "[81]\ttrain-error:0.05599\teval-error:0.07233\n",
      "[82]\ttrain-error:0.05584\teval-error:0.07233\n",
      "[83]\ttrain-error:0.05579\teval-error:0.07247\n",
      "[84]\ttrain-error:0.05570\teval-error:0.07262\n",
      "[85]\ttrain-error:0.05560\teval-error:0.07247\n",
      "[86]\ttrain-error:0.05555\teval-error:0.07247\n",
      "[87]\ttrain-error:0.05530\teval-error:0.07203\n",
      "[88]\ttrain-error:0.05535\teval-error:0.07233\n",
      "[89]\ttrain-error:0.05525\teval-error:0.07218\n",
      "[90]\ttrain-error:0.05520\teval-error:0.07203\n",
      "[91]\ttrain-error:0.05530\teval-error:0.07218\n",
      "[92]\ttrain-error:0.05515\teval-error:0.07233\n",
      "[93]\ttrain-error:0.05505\teval-error:0.07188\n",
      "[94]\ttrain-error:0.05501\teval-error:0.07188\n",
      "[95]\ttrain-error:0.05505\teval-error:0.07188\n",
      "Stopping. Best iteration:\n",
      "[75]\ttrain-error:0.05717\teval-error:0.07188\n",
      "\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2496 - accuracy: 0.9205 - val_loss: 0.2098 - val_accuracy: 0.9325\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2145 - accuracy: 0.9301 - val_loss: 0.2072 - val_accuracy: 0.9333\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9306 - val_loss: 0.2084 - val_accuracy: 0.9336\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9314 - val_loss: 0.2058 - val_accuracy: 0.9333\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9322 - val_loss: 0.2099 - val_accuracy: 0.9327\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9320 - val_loss: 0.2090 - val_accuracy: 0.9340\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1998 - accuracy: 0.9319 - val_loss: 0.2102 - val_accuracy: 0.9330\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1975 - accuracy: 0.9328 - val_loss: 0.2078 - val_accuracy: 0.9328\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1963 - accuracy: 0.9329 - val_loss: 0.2081 - val_accuracy: 0.9348\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1929 - accuracy: 0.9337 - val_loss: 0.2097 - val_accuracy: 0.9342\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1925 - accuracy: 0.9342 - val_loss: 0.2120 - val_accuracy: 0.9345\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1889 - accuracy: 0.9354 - val_loss: 0.2117 - val_accuracy: 0.9336\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1881 - accuracy: 0.9360 - val_loss: 0.2116 - val_accuracy: 0.9315\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1841 - accuracy: 0.9372 - val_loss: 0.2136 - val_accuracy: 0.9324\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1831 - accuracy: 0.9360 - val_loss: 0.2182 - val_accuracy: 0.9309\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1790 - accuracy: 0.9385 - val_loss: 0.2166 - val_accuracy: 0.9318\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1759 - accuracy: 0.9396 - val_loss: 0.2165 - val_accuracy: 0.9345\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1752 - accuracy: 0.9393 - val_loss: 0.2172 - val_accuracy: 0.9311\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1708 - accuracy: 0.9405 - val_loss: 0.2212 - val_accuracy: 0.9290\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1690 - accuracy: 0.9404 - val_loss: 0.2207 - val_accuracy: 0.9305\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1665 - accuracy: 0.9405 - val_loss: 0.2237 - val_accuracy: 0.9318\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1632 - accuracy: 0.9420 - val_loss: 0.2258 - val_accuracy: 0.9336\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1610 - accuracy: 0.9436 - val_loss: 0.2291 - val_accuracy: 0.9317\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1571 - accuracy: 0.9449 - val_loss: 0.2273 - val_accuracy: 0.9302\n",
      "WARNING:tensorflow:From C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:122: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2413 - accuracy: 0.9234 - val_loss: 0.2176 - val_accuracy: 0.9294\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2125 - accuracy: 0.9306 - val_loss: 0.2167 - val_accuracy: 0.9299\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9313 - val_loss: 0.2153 - val_accuracy: 0.9309\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9324 - val_loss: 0.2172 - val_accuracy: 0.9302\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2009 - accuracy: 0.9328 - val_loss: 0.2162 - val_accuracy: 0.9292\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2014 - accuracy: 0.9332 - val_loss: 0.2164 - val_accuracy: 0.9296\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1983 - accuracy: 0.9329 - val_loss: 0.2168 - val_accuracy: 0.9297\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1966 - accuracy: 0.9335 - val_loss: 0.2173 - val_accuracy: 0.9302\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1938 - accuracy: 0.9354 - val_loss: 0.2186 - val_accuracy: 0.9300\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1922 - accuracy: 0.9346 - val_loss: 0.2195 - val_accuracy: 0.9290\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1898 - accuracy: 0.9359 - val_loss: 0.2209 - val_accuracy: 0.9292\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1892 - accuracy: 0.9361 - val_loss: 0.2211 - val_accuracy: 0.9278\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - ETA: 0s - loss: 0.1852 - accuracy: 0.93 - 1s 3ms/step - loss: 0.1860 - accuracy: 0.9373 - val_loss: 0.2211 - val_accuracy: 0.9286\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1820 - accuracy: 0.9383 - val_loss: 0.2285 - val_accuracy: 0.9287\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1817 - accuracy: 0.9378 - val_loss: 0.2242 - val_accuracy: 0.9280\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1796 - accuracy: 0.9382 - val_loss: 0.2229 - val_accuracy: 0.9286\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1751 - accuracy: 0.9406 - val_loss: 0.2276 - val_accuracy: 0.9272\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1725 - accuracy: 0.9425 - val_loss: 0.2290 - val_accuracy: 0.9252\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1714 - accuracy: 0.9410 - val_loss: 0.2296 - val_accuracy: 0.9272\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1677 - accuracy: 0.9430 - val_loss: 0.2358 - val_accuracy: 0.9259\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1646 - accuracy: 0.9432 - val_loss: 0.2371 - val_accuracy: 0.9265\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1623 - accuracy: 0.9440 - val_loss: 0.2361 - val_accuracy: 0.9252\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1594 - accuracy: 0.9442 - val_loss: 0.2406 - val_accuracy: 0.9246\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2392 - accuracy: 0.9262 - val_loss: 0.2225 - val_accuracy: 0.9272\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2133 - accuracy: 0.9303 - val_loss: 0.2146 - val_accuracy: 0.9290\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2073 - accuracy: 0.9318 - val_loss: 0.2204 - val_accuracy: 0.9289\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9323 - val_loss: 0.2184 - val_accuracy: 0.9292\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2030 - accuracy: 0.9326 - val_loss: 0.2177 - val_accuracy: 0.9300\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1995 - accuracy: 0.9331 - val_loss: 0.2194 - val_accuracy: 0.9315\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1983 - accuracy: 0.9343 - val_loss: 0.2194 - val_accuracy: 0.9300\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1949 - accuracy: 0.9340 - val_loss: 0.2218 - val_accuracy: 0.9306\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1938 - accuracy: 0.9340 - val_loss: 0.2201 - val_accuracy: 0.9287\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1935 - accuracy: 0.9348 - val_loss: 0.2202 - val_accuracy: 0.9306\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1880 - accuracy: 0.9356 - val_loss: 0.2221 - val_accuracy: 0.9294\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1888 - accuracy: 0.9360 - val_loss: 0.2209 - val_accuracy: 0.9302\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1844 - accuracy: 0.9371 - val_loss: 0.2215 - val_accuracy: 0.9305\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1813 - accuracy: 0.9376 - val_loss: 0.2267 - val_accuracy: 0.9312\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.1794 - accuracy: 0.9382 - val_loss: 0.2286 - val_accuracy: 0.9287\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1775 - accuracy: 0.9378 - val_loss: 0.2287 - val_accuracy: 0.9302\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1737 - accuracy: 0.9386 - val_loss: 0.2312 - val_accuracy: 0.9302\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1725 - accuracy: 0.9401 - val_loss: 0.2312 - val_accuracy: 0.9283\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1691 - accuracy: 0.9414 - val_loss: 0.2387 - val_accuracy: 0.9274\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1671 - accuracy: 0.9410 - val_loss: 0.2362 - val_accuracy: 0.9300\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1640 - accuracy: 0.9424 - val_loss: 0.2398 - val_accuracy: 0.9250\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1617 - accuracy: 0.9442 - val_loss: 0.2397 - val_accuracy: 0.9252\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2400 - accuracy: 0.9266 - val_loss: 0.2187 - val_accuracy: 0.9271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2131 - accuracy: 0.9303 - val_loss: 0.2142 - val_accuracy: 0.9275\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2077 - accuracy: 0.9319 - val_loss: 0.2176 - val_accuracy: 0.9275\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9325 - val_loss: 0.2172 - val_accuracy: 0.9262\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2020 - accuracy: 0.9325 - val_loss: 0.2147 - val_accuracy: 0.9277\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1996 - accuracy: 0.9343 - val_loss: 0.2187 - val_accuracy: 0.9268\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1968 - accuracy: 0.9347 - val_loss: 0.2166 - val_accuracy: 0.9271\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1949 - accuracy: 0.9354 - val_loss: 0.2189 - val_accuracy: 0.9281\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1923 - accuracy: 0.9356 - val_loss: 0.2172 - val_accuracy: 0.9269\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1902 - accuracy: 0.9361 - val_loss: 0.2232 - val_accuracy: 0.9256\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1888 - accuracy: 0.9361 - val_loss: 0.2213 - val_accuracy: 0.9272\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1861 - accuracy: 0.9380 - val_loss: 0.2220 - val_accuracy: 0.9261\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9389 - val_loss: 0.2243 - val_accuracy: 0.9253\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1819 - accuracy: 0.9402 - val_loss: 0.2295 - val_accuracy: 0.9261\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1810 - accuracy: 0.9395 - val_loss: 0.2255 - val_accuracy: 0.9258\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1786 - accuracy: 0.9390 - val_loss: 0.2278 - val_accuracy: 0.9228\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1755 - accuracy: 0.9413 - val_loss: 0.2277 - val_accuracy: 0.9244\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1718 - accuracy: 0.9409 - val_loss: 0.2307 - val_accuracy: 0.9231\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1702 - accuracy: 0.9417 - val_loss: 0.2305 - val_accuracy: 0.9228\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1675 - accuracy: 0.9421 - val_loss: 0.2415 - val_accuracy: 0.9252\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1633 - accuracy: 0.9434 - val_loss: 0.2411 - val_accuracy: 0.9238\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1635 - accuracy: 0.9434 - val_loss: 0.2389 - val_accuracy: 0.9225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:178: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:178: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:178: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:178: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:27:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06922\teval-error:0.07100\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06888\teval-error:0.06967\n",
      "[2]\ttrain-error:0.06962\teval-error:0.06819\n",
      "[3]\ttrain-error:0.06898\teval-error:0.06745\n",
      "[4]\ttrain-error:0.06809\teval-error:0.06686\n",
      "[5]\ttrain-error:0.06927\teval-error:0.06613\n",
      "[6]\ttrain-error:0.06903\teval-error:0.06598\n",
      "[7]\ttrain-error:0.06844\teval-error:0.06613\n",
      "[8]\ttrain-error:0.06819\teval-error:0.06627\n",
      "[9]\ttrain-error:0.06775\teval-error:0.06583\n",
      "[10]\ttrain-error:0.06775\teval-error:0.06583\n",
      "[11]\ttrain-error:0.06741\teval-error:0.06598\n",
      "[12]\ttrain-error:0.06741\teval-error:0.06598\n",
      "[13]\ttrain-error:0.06755\teval-error:0.06553\n",
      "[14]\ttrain-error:0.06750\teval-error:0.06568\n",
      "[15]\ttrain-error:0.06731\teval-error:0.06583\n",
      "[16]\ttrain-error:0.06711\teval-error:0.06553\n",
      "[17]\ttrain-error:0.06706\teval-error:0.06568\n",
      "[18]\ttrain-error:0.06686\teval-error:0.06583\n",
      "[19]\ttrain-error:0.06657\teval-error:0.06583\n",
      "[20]\ttrain-error:0.06672\teval-error:0.06613\n",
      "[21]\ttrain-error:0.06686\teval-error:0.06613\n",
      "[22]\ttrain-error:0.06686\teval-error:0.06598\n",
      "[23]\ttrain-error:0.06701\teval-error:0.06568\n",
      "[24]\ttrain-error:0.06677\teval-error:0.06568\n",
      "[25]\ttrain-error:0.06706\teval-error:0.06583\n",
      "[26]\ttrain-error:0.06667\teval-error:0.06568\n",
      "[27]\ttrain-error:0.06642\teval-error:0.06568\n",
      "[28]\ttrain-error:0.06662\teval-error:0.06553\n",
      "[29]\ttrain-error:0.06657\teval-error:0.06568\n",
      "[30]\ttrain-error:0.06608\teval-error:0.06568\n",
      "[31]\ttrain-error:0.06617\teval-error:0.06539\n",
      "[32]\ttrain-error:0.06608\teval-error:0.06553\n",
      "[33]\ttrain-error:0.06598\teval-error:0.06568\n",
      "[34]\ttrain-error:0.06603\teval-error:0.06553\n",
      "[35]\ttrain-error:0.06583\teval-error:0.06539\n",
      "[36]\ttrain-error:0.06568\teval-error:0.06524\n",
      "[37]\ttrain-error:0.06553\teval-error:0.06524\n",
      "[38]\ttrain-error:0.06539\teval-error:0.06539\n",
      "[39]\ttrain-error:0.06480\teval-error:0.06553\n",
      "[40]\ttrain-error:0.06470\teval-error:0.06539\n",
      "[41]\ttrain-error:0.06455\teval-error:0.06553\n",
      "[42]\ttrain-error:0.06421\teval-error:0.06539\n",
      "[43]\ttrain-error:0.06426\teval-error:0.06553\n",
      "[44]\ttrain-error:0.06416\teval-error:0.06568\n",
      "[45]\ttrain-error:0.06426\teval-error:0.06583\n",
      "[46]\ttrain-error:0.06406\teval-error:0.06568\n",
      "[47]\ttrain-error:0.06352\teval-error:0.06553\n",
      "[48]\ttrain-error:0.06327\teval-error:0.06568\n",
      "[49]\ttrain-error:0.06308\teval-error:0.06553\n",
      "[50]\ttrain-error:0.06288\teval-error:0.06553\n",
      "[51]\ttrain-error:0.06258\teval-error:0.06598\n",
      "[52]\ttrain-error:0.06239\teval-error:0.06568\n",
      "[53]\ttrain-error:0.06243\teval-error:0.06568\n",
      "[54]\ttrain-error:0.06234\teval-error:0.06539\n",
      "[55]\ttrain-error:0.06219\teval-error:0.06539\n",
      "[56]\ttrain-error:0.06234\teval-error:0.06539\n",
      "Stopping. Best iteration:\n",
      "[36]\ttrain-error:0.06568\teval-error:0.06524\n",
      "\n",
      "[14:27:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06937\teval-error:0.07100\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06888\teval-error:0.07011\n",
      "[2]\ttrain-error:0.06952\teval-error:0.07085\n",
      "[3]\ttrain-error:0.06893\teval-error:0.07100\n",
      "[4]\ttrain-error:0.06878\teval-error:0.07114\n",
      "[5]\ttrain-error:0.06908\teval-error:0.07114\n",
      "[6]\ttrain-error:0.06858\teval-error:0.07041\n",
      "[7]\ttrain-error:0.06829\teval-error:0.07070\n",
      "[8]\ttrain-error:0.06814\teval-error:0.07026\n",
      "[9]\ttrain-error:0.06760\teval-error:0.07011\n",
      "[10]\ttrain-error:0.06790\teval-error:0.07026\n",
      "[11]\ttrain-error:0.06780\teval-error:0.06982\n",
      "[12]\ttrain-error:0.06750\teval-error:0.06967\n",
      "[13]\ttrain-error:0.06745\teval-error:0.06996\n",
      "[14]\ttrain-error:0.06741\teval-error:0.06952\n",
      "[15]\ttrain-error:0.06706\teval-error:0.06952\n",
      "[16]\ttrain-error:0.06716\teval-error:0.06952\n",
      "[17]\ttrain-error:0.06677\teval-error:0.06922\n",
      "[18]\ttrain-error:0.06652\teval-error:0.06908\n",
      "[19]\ttrain-error:0.06667\teval-error:0.06893\n",
      "[20]\ttrain-error:0.06677\teval-error:0.06908\n",
      "[21]\ttrain-error:0.06681\teval-error:0.06908\n",
      "[22]\ttrain-error:0.06677\teval-error:0.06922\n",
      "[23]\ttrain-error:0.06657\teval-error:0.06893\n",
      "[24]\ttrain-error:0.06647\teval-error:0.06893\n",
      "[25]\ttrain-error:0.06622\teval-error:0.06908\n",
      "[26]\ttrain-error:0.06608\teval-error:0.06908\n",
      "[27]\ttrain-error:0.06617\teval-error:0.06893\n",
      "[28]\ttrain-error:0.06598\teval-error:0.06849\n",
      "[29]\ttrain-error:0.06603\teval-error:0.06864\n",
      "[30]\ttrain-error:0.06583\teval-error:0.06893\n",
      "[31]\ttrain-error:0.06534\teval-error:0.06878\n",
      "[32]\ttrain-error:0.06529\teval-error:0.06864\n",
      "[33]\ttrain-error:0.06529\teval-error:0.06878\n",
      "[34]\ttrain-error:0.06519\teval-error:0.06819\n",
      "[35]\ttrain-error:0.06489\teval-error:0.06893\n",
      "[36]\ttrain-error:0.06495\teval-error:0.06893\n",
      "[37]\ttrain-error:0.06460\teval-error:0.06834\n",
      "[38]\ttrain-error:0.06440\teval-error:0.06849\n",
      "[39]\ttrain-error:0.06440\teval-error:0.06790\n",
      "[40]\ttrain-error:0.06440\teval-error:0.06804\n",
      "[41]\ttrain-error:0.06431\teval-error:0.06819\n",
      "[42]\ttrain-error:0.06416\teval-error:0.06804\n",
      "[43]\ttrain-error:0.06381\teval-error:0.06790\n",
      "[44]\ttrain-error:0.06362\teval-error:0.06804\n",
      "[45]\ttrain-error:0.06317\teval-error:0.06834\n",
      "[46]\ttrain-error:0.06303\teval-error:0.06819\n",
      "[47]\ttrain-error:0.06288\teval-error:0.06849\n",
      "[48]\ttrain-error:0.06268\teval-error:0.06849\n",
      "[49]\ttrain-error:0.06253\teval-error:0.06804\n",
      "[50]\ttrain-error:0.06199\teval-error:0.06849\n",
      "[51]\ttrain-error:0.06189\teval-error:0.06790\n",
      "[52]\ttrain-error:0.06145\teval-error:0.06849\n",
      "[53]\ttrain-error:0.06121\teval-error:0.06878\n",
      "[54]\ttrain-error:0.06121\teval-error:0.06849\n",
      "[55]\ttrain-error:0.06111\teval-error:0.06922\n",
      "[56]\ttrain-error:0.06106\teval-error:0.06922\n",
      "[57]\ttrain-error:0.06091\teval-error:0.06908\n",
      "[58]\ttrain-error:0.06096\teval-error:0.06864\n",
      "[59]\ttrain-error:0.06081\teval-error:0.06878\n",
      "Stopping. Best iteration:\n",
      "[39]\ttrain-error:0.06440\teval-error:0.06790\n",
      "\n",
      "[14:27:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06873\teval-error:0.06996\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06893\teval-error:0.07114\n",
      "[2]\ttrain-error:0.06893\teval-error:0.07085\n",
      "[3]\ttrain-error:0.06873\teval-error:0.07026\n",
      "[4]\ttrain-error:0.06839\teval-error:0.07085\n",
      "[5]\ttrain-error:0.06873\teval-error:0.07011\n",
      "[6]\ttrain-error:0.06799\teval-error:0.06982\n",
      "[7]\ttrain-error:0.06795\teval-error:0.06982\n",
      "[8]\ttrain-error:0.06775\teval-error:0.07026\n",
      "[9]\ttrain-error:0.06790\teval-error:0.06967\n",
      "[10]\ttrain-error:0.06790\teval-error:0.06952\n",
      "[11]\ttrain-error:0.06770\teval-error:0.06937\n",
      "[12]\ttrain-error:0.06750\teval-error:0.06967\n",
      "[13]\ttrain-error:0.06741\teval-error:0.06937\n",
      "[14]\ttrain-error:0.06755\teval-error:0.06922\n",
      "[15]\ttrain-error:0.06745\teval-error:0.06937\n",
      "[16]\ttrain-error:0.06775\teval-error:0.06893\n",
      "[17]\ttrain-error:0.06735\teval-error:0.06922\n",
      "[18]\ttrain-error:0.06735\teval-error:0.06922\n",
      "[19]\ttrain-error:0.06731\teval-error:0.06922\n",
      "[20]\ttrain-error:0.06706\teval-error:0.06908\n",
      "[21]\ttrain-error:0.06686\teval-error:0.06908\n",
      "[22]\ttrain-error:0.06677\teval-error:0.06908\n",
      "[23]\ttrain-error:0.06662\teval-error:0.06908\n",
      "[24]\ttrain-error:0.06622\teval-error:0.06922\n",
      "[25]\ttrain-error:0.06642\teval-error:0.06922\n",
      "[26]\ttrain-error:0.06613\teval-error:0.06922\n",
      "[27]\ttrain-error:0.06578\teval-error:0.06982\n",
      "[28]\ttrain-error:0.06598\teval-error:0.06967\n",
      "[29]\ttrain-error:0.06583\teval-error:0.06982\n",
      "[30]\ttrain-error:0.06573\teval-error:0.06967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\ttrain-error:0.06549\teval-error:0.06952\n",
      "[32]\ttrain-error:0.06514\teval-error:0.06952\n",
      "[33]\ttrain-error:0.06489\teval-error:0.06922\n",
      "[34]\ttrain-error:0.06504\teval-error:0.06922\n",
      "[35]\ttrain-error:0.06499\teval-error:0.06878\n",
      "[36]\ttrain-error:0.06489\teval-error:0.06878\n",
      "[37]\ttrain-error:0.06470\teval-error:0.06849\n",
      "[38]\ttrain-error:0.06470\teval-error:0.06878\n",
      "[39]\ttrain-error:0.06480\teval-error:0.06864\n",
      "[40]\ttrain-error:0.06460\teval-error:0.06893\n",
      "[41]\ttrain-error:0.06406\teval-error:0.06893\n",
      "[42]\ttrain-error:0.06386\teval-error:0.06893\n",
      "[43]\ttrain-error:0.06357\teval-error:0.06922\n",
      "[44]\ttrain-error:0.06347\teval-error:0.06908\n",
      "[45]\ttrain-error:0.06347\teval-error:0.06893\n",
      "[46]\ttrain-error:0.06327\teval-error:0.06864\n",
      "[47]\ttrain-error:0.06322\teval-error:0.06893\n",
      "[48]\ttrain-error:0.06283\teval-error:0.06878\n",
      "[49]\ttrain-error:0.06268\teval-error:0.06864\n",
      "[50]\ttrain-error:0.06253\teval-error:0.06849\n",
      "[51]\ttrain-error:0.06224\teval-error:0.06864\n",
      "[52]\ttrain-error:0.06219\teval-error:0.06834\n",
      "[53]\ttrain-error:0.06219\teval-error:0.06819\n",
      "[54]\ttrain-error:0.06209\teval-error:0.06849\n",
      "[55]\ttrain-error:0.06189\teval-error:0.06819\n",
      "[56]\ttrain-error:0.06175\teval-error:0.06819\n",
      "[57]\ttrain-error:0.06150\teval-error:0.06834\n",
      "[58]\ttrain-error:0.06145\teval-error:0.06878\n",
      "[59]\ttrain-error:0.06125\teval-error:0.06878\n",
      "[60]\ttrain-error:0.06086\teval-error:0.06878\n",
      "[61]\ttrain-error:0.06096\teval-error:0.06893\n",
      "[62]\ttrain-error:0.06081\teval-error:0.06908\n",
      "[63]\ttrain-error:0.06062\teval-error:0.06922\n",
      "[64]\ttrain-error:0.06037\teval-error:0.06908\n",
      "[65]\ttrain-error:0.06032\teval-error:0.06893\n",
      "[66]\ttrain-error:0.06022\teval-error:0.06864\n",
      "[67]\ttrain-error:0.05993\teval-error:0.06878\n",
      "[68]\ttrain-error:0.05973\teval-error:0.06849\n",
      "[69]\ttrain-error:0.05993\teval-error:0.06819\n",
      "[70]\ttrain-error:0.05988\teval-error:0.06834\n",
      "[71]\ttrain-error:0.05973\teval-error:0.06804\n",
      "[72]\ttrain-error:0.05934\teval-error:0.06804\n",
      "[73]\ttrain-error:0.05934\teval-error:0.06790\n",
      "[74]\ttrain-error:0.05914\teval-error:0.06804\n",
      "[75]\ttrain-error:0.05929\teval-error:0.06790\n",
      "[76]\ttrain-error:0.05909\teval-error:0.06849\n",
      "[77]\ttrain-error:0.05889\teval-error:0.06849\n",
      "[78]\ttrain-error:0.05870\teval-error:0.06849\n",
      "[79]\ttrain-error:0.05860\teval-error:0.06804\n",
      "[80]\ttrain-error:0.05870\teval-error:0.06849\n",
      "[81]\ttrain-error:0.05884\teval-error:0.06849\n",
      "[82]\ttrain-error:0.05880\teval-error:0.06834\n",
      "[83]\ttrain-error:0.05860\teval-error:0.06864\n",
      "[84]\ttrain-error:0.05830\teval-error:0.06878\n",
      "[85]\ttrain-error:0.05825\teval-error:0.06849\n",
      "[86]\ttrain-error:0.05771\teval-error:0.06878\n",
      "[87]\ttrain-error:0.05766\teval-error:0.06878\n",
      "[88]\ttrain-error:0.05751\teval-error:0.06878\n",
      "[89]\ttrain-error:0.05742\teval-error:0.06937\n",
      "[90]\ttrain-error:0.05742\teval-error:0.06922\n",
      "[91]\ttrain-error:0.05707\teval-error:0.06908\n",
      "[92]\ttrain-error:0.05717\teval-error:0.06893\n",
      "[93]\ttrain-error:0.05707\teval-error:0.06893\n",
      "Stopping. Best iteration:\n",
      "[73]\ttrain-error:0.05934\teval-error:0.06790\n",
      "\n",
      "[14:27:42] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06854\teval-error:0.07351\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06780\teval-error:0.07321\n",
      "[2]\ttrain-error:0.06814\teval-error:0.07336\n",
      "[3]\ttrain-error:0.06765\teval-error:0.07410\n",
      "[4]\ttrain-error:0.06780\teval-error:0.07424\n",
      "[5]\ttrain-error:0.06839\teval-error:0.07498\n",
      "[6]\ttrain-error:0.06770\teval-error:0.07454\n",
      "[7]\ttrain-error:0.06731\teval-error:0.07439\n",
      "[8]\ttrain-error:0.06701\teval-error:0.07483\n",
      "[9]\ttrain-error:0.06735\teval-error:0.07454\n",
      "[10]\ttrain-error:0.06735\teval-error:0.07424\n",
      "[11]\ttrain-error:0.06706\teval-error:0.07380\n",
      "[12]\ttrain-error:0.06662\teval-error:0.07380\n",
      "[13]\ttrain-error:0.06652\teval-error:0.07380\n",
      "[14]\ttrain-error:0.06652\teval-error:0.07380\n",
      "[15]\ttrain-error:0.06627\teval-error:0.07454\n",
      "[16]\ttrain-error:0.06632\teval-error:0.07424\n",
      "[17]\ttrain-error:0.06617\teval-error:0.07439\n",
      "[18]\ttrain-error:0.06608\teval-error:0.07454\n",
      "[19]\ttrain-error:0.06588\teval-error:0.07424\n",
      "[20]\ttrain-error:0.06568\teval-error:0.07424\n",
      "[21]\ttrain-error:0.06573\teval-error:0.07439\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.06780\teval-error:0.07321\n",
      "\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3603 - accuracy: 0.8991 - val_loss: 0.2806 - val_accuracy: 0.9256\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2815 - accuracy: 0.9209 - val_loss: 0.2492 - val_accuracy: 0.9258\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2558 - accuracy: 0.9219 - val_loss: 0.2335 - val_accuracy: 0.9305\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2454 - accuracy: 0.9245 - val_loss: 0.2258 - val_accuracy: 0.9315\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2393 - accuracy: 0.9253 - val_loss: 0.2231 - val_accuracy: 0.9315\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2347 - accuracy: 0.9263 - val_loss: 0.2194 - val_accuracy: 0.9317\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2305 - accuracy: 0.9267 - val_loss: 0.2176 - val_accuracy: 0.9312\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2292 - accuracy: 0.9267 - val_loss: 0.2160 - val_accuracy: 0.9314\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2286 - accuracy: 0.9260 - val_loss: 0.2157 - val_accuracy: 0.9309\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2277 - accuracy: 0.9272 - val_loss: 0.2145 - val_accuracy: 0.9315\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2261 - accuracy: 0.9277 - val_loss: 0.2142 - val_accuracy: 0.9312\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2235 - accuracy: 0.9274 - val_loss: 0.2134 - val_accuracy: 0.9312\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2246 - accuracy: 0.9279 - val_loss: 0.2128 - val_accuracy: 0.9315\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2225 - accuracy: 0.9274 - val_loss: 0.2125 - val_accuracy: 0.9315\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2227 - accuracy: 0.9275 - val_loss: 0.2121 - val_accuracy: 0.9317\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2222 - accuracy: 0.9281 - val_loss: 0.2112 - val_accuracy: 0.9320\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2205 - accuracy: 0.9281 - val_loss: 0.2112 - val_accuracy: 0.9321\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2211 - accuracy: 0.9277 - val_loss: 0.2113 - val_accuracy: 0.9317\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2195 - accuracy: 0.9283 - val_loss: 0.2113 - val_accuracy: 0.9317\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2185 - accuracy: 0.9285 - val_loss: 0.2106 - val_accuracy: 0.9318\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2203 - accuracy: 0.9285 - val_loss: 0.2105 - val_accuracy: 0.9320\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2196 - accuracy: 0.9277 - val_loss: 0.2103 - val_accuracy: 0.9317\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2193 - accuracy: 0.9279 - val_loss: 0.2103 - val_accuracy: 0.9318\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2167 - accuracy: 0.9280 - val_loss: 0.2104 - val_accuracy: 0.9317\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2179 - accuracy: 0.9282 - val_loss: 0.2098 - val_accuracy: 0.9318\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2180 - accuracy: 0.9276 - val_loss: 0.2099 - val_accuracy: 0.9315\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2173 - accuracy: 0.9280 - val_loss: 0.2098 - val_accuracy: 0.9317\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2174 - accuracy: 0.9279 - val_loss: 0.2096 - val_accuracy: 0.9315\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2145 - accuracy: 0.9287 - val_loss: 0.2095 - val_accuracy: 0.9317\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2165 - accuracy: 0.9292 - val_loss: 0.2091 - val_accuracy: 0.9315\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2150 - accuracy: 0.9292 - val_loss: 0.2092 - val_accuracy: 0.9323\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2141 - accuracy: 0.9280 - val_loss: 0.2089 - val_accuracy: 0.9315\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2160 - accuracy: 0.9285 - val_loss: 0.2089 - val_accuracy: 0.9315\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2143 - accuracy: 0.9290 - val_loss: 0.2089 - val_accuracy: 0.9323\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2145 - accuracy: 0.9293 - val_loss: 0.2088 - val_accuracy: 0.9318\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2159 - accuracy: 0.9288 - val_loss: 0.2088 - val_accuracy: 0.9320\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2153 - accuracy: 0.9286 - val_loss: 0.2088 - val_accuracy: 0.9321\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2143 - accuracy: 0.9290 - val_loss: 0.2084 - val_accuracy: 0.9323\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2128 - accuracy: 0.9298 - val_loss: 0.2084 - val_accuracy: 0.9323\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2121 - accuracy: 0.9290 - val_loss: 0.2087 - val_accuracy: 0.9321\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2134 - accuracy: 0.9286 - val_loss: 0.2083 - val_accuracy: 0.9321\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2139 - accuracy: 0.9286 - val_loss: 0.2084 - val_accuracy: 0.9324\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2124 - accuracy: 0.9292 - val_loss: 0.2082 - val_accuracy: 0.9324\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2125 - accuracy: 0.9286 - val_loss: 0.2082 - val_accuracy: 0.9324\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2127 - accuracy: 0.9296 - val_loss: 0.2079 - val_accuracy: 0.9320\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2145 - accuracy: 0.9298 - val_loss: 0.2077 - val_accuracy: 0.9320\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2108 - accuracy: 0.9299 - val_loss: 0.2080 - val_accuracy: 0.9323\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.9286 - val_loss: 0.2082 - val_accuracy: 0.9325\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2124 - accuracy: 0.9291 - val_loss: 0.2077 - val_accuracy: 0.9321\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2112 - accuracy: 0.9303 - val_loss: 0.2077 - val_accuracy: 0.9324\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2120 - accuracy: 0.9290 - val_loss: 0.2077 - val_accuracy: 0.9321\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9296 - val_loss: 0.2078 - val_accuracy: 0.9324\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2104 - accuracy: 0.9295 - val_loss: 0.2079 - val_accuracy: 0.9325\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9288 - val_loss: 0.2079 - val_accuracy: 0.9327\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2112 - accuracy: 0.9294 - val_loss: 0.2075 - val_accuracy: 0.9324\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2125 - accuracy: 0.9286 - val_loss: 0.2076 - val_accuracy: 0.9323\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.9291 - val_loss: 0.2075 - val_accuracy: 0.9323\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2118 - accuracy: 0.9305 - val_loss: 0.2075 - val_accuracy: 0.9324\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9297 - val_loss: 0.2074 - val_accuracy: 0.9325\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9301 - val_loss: 0.2075 - val_accuracy: 0.9324\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9296 - val_loss: 0.2075 - val_accuracy: 0.9323\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.9290 - val_loss: 0.2075 - val_accuracy: 0.9323\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2099 - accuracy: 0.9289 - val_loss: 0.2074 - val_accuracy: 0.9324\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9291 - val_loss: 0.2076 - val_accuracy: 0.9324\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9283 - val_loss: 0.2076 - val_accuracy: 0.9324\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9298 - val_loss: 0.2076 - val_accuracy: 0.9324\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9292 - val_loss: 0.2076 - val_accuracy: 0.9324\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2104 - accuracy: 0.9301 - val_loss: 0.2075 - val_accuracy: 0.9327\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9301 - val_loss: 0.2072 - val_accuracy: 0.9327\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9300 - val_loss: 0.2075 - val_accuracy: 0.9327\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9301 - val_loss: 0.2072 - val_accuracy: 0.9327\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9290 - val_loss: 0.2070 - val_accuracy: 0.9328\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9300 - val_loss: 0.2070 - val_accuracy: 0.9325\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2097 - accuracy: 0.9293 - val_loss: 0.2074 - val_accuracy: 0.9325\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2094 - accuracy: 0.9295 - val_loss: 0.2072 - val_accuracy: 0.9323\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9298 - val_loss: 0.2073 - val_accuracy: 0.9325\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2080 - accuracy: 0.9303 - val_loss: 0.2070 - val_accuracy: 0.9330\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9297 - val_loss: 0.2072 - val_accuracy: 0.9330\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9307 - val_loss: 0.2073 - val_accuracy: 0.9328\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9298 - val_loss: 0.2072 - val_accuracy: 0.9328\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2081 - accuracy: 0.9300 - val_loss: 0.2072 - val_accuracy: 0.9325\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9300 - val_loss: 0.2073 - val_accuracy: 0.9324\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9299 - val_loss: 0.2073 - val_accuracy: 0.9327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9310 - val_loss: 0.2075 - val_accuracy: 0.9327\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9299 - val_loss: 0.2073 - val_accuracy: 0.9323\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9307 - val_loss: 0.2072 - val_accuracy: 0.9324\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9312 - val_loss: 0.2070 - val_accuracy: 0.9324\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9305 - val_loss: 0.2075 - val_accuracy: 0.9328\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9301 - val_loss: 0.2071 - val_accuracy: 0.9324\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9303 - val_loss: 0.2072 - val_accuracy: 0.9327\n",
      "Epoch 91/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9304 - val_loss: 0.2069 - val_accuracy: 0.9323\n",
      "Epoch 92/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9305 - val_loss: 0.2069 - val_accuracy: 0.9321\n",
      "Epoch 93/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2081 - accuracy: 0.9292 - val_loss: 0.2069 - val_accuracy: 0.9320\n",
      "Epoch 94/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9302 - val_loss: 0.2070 - val_accuracy: 0.9321\n",
      "Epoch 95/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9308 - val_loss: 0.2073 - val_accuracy: 0.9324\n",
      "Epoch 96/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9305 - val_loss: 0.2074 - val_accuracy: 0.9327\n",
      "Epoch 97/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9309 - val_loss: 0.2074 - val_accuracy: 0.9327\n",
      "Epoch 98/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9310 - val_loss: 0.2076 - val_accuracy: 0.9325\n",
      "Epoch 99/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9302 - val_loss: 0.2078 - val_accuracy: 0.9325\n",
      "Epoch 100/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9307 - val_loss: 0.2074 - val_accuracy: 0.9325\n",
      "Epoch 101/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9296 - val_loss: 0.2074 - val_accuracy: 0.9323\n",
      "Epoch 102/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9313 - val_loss: 0.2074 - val_accuracy: 0.9325\n",
      "Epoch 103/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9309 - val_loss: 0.2074 - val_accuracy: 0.9325\n",
      "Epoch 104/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9303 - val_loss: 0.2073 - val_accuracy: 0.9327\n",
      "Epoch 105/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9312 - val_loss: 0.2075 - val_accuracy: 0.9324\n",
      "Epoch 106/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9308 - val_loss: 0.2076 - val_accuracy: 0.9325\n",
      "Epoch 107/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9297 - val_loss: 0.2071 - val_accuracy: 0.9328\n",
      "Epoch 108/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9304 - val_loss: 0.2074 - val_accuracy: 0.9324\n",
      "Epoch 109/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9306 - val_loss: 0.2073 - val_accuracy: 0.9327\n",
      "Epoch 110/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9292 - val_loss: 0.2075 - val_accuracy: 0.9325\n",
      "Epoch 111/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9305 - val_loss: 0.2074 - val_accuracy: 0.9324\n",
      "Epoch 112/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9310 - val_loss: 0.2074 - val_accuracy: 0.9323\n",
      "Epoch 113/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9305 - val_loss: 0.2075 - val_accuracy: 0.9325\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3547 - accuracy: 0.8813 - val_loss: 0.2698 - val_accuracy: 0.9225\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2603 - accuracy: 0.9247 - val_loss: 0.2417 - val_accuracy: 0.9278\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2419 - accuracy: 0.9268 - val_loss: 0.2310 - val_accuracy: 0.9290\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2360 - accuracy: 0.9276 - val_loss: 0.2259 - val_accuracy: 0.9293\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2307 - accuracy: 0.9285 - val_loss: 0.2230 - val_accuracy: 0.9296\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2299 - accuracy: 0.9275 - val_loss: 0.2211 - val_accuracy: 0.9293\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2272 - accuracy: 0.9286 - val_loss: 0.2198 - val_accuracy: 0.9293\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2265 - accuracy: 0.9286 - val_loss: 0.2188 - val_accuracy: 0.9293\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2259 - accuracy: 0.9278 - val_loss: 0.2181 - val_accuracy: 0.9296\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2233 - accuracy: 0.9290 - val_loss: 0.2175 - val_accuracy: 0.9292\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2223 - accuracy: 0.9288 - val_loss: 0.2172 - val_accuracy: 0.9296\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2223 - accuracy: 0.9291 - val_loss: 0.2168 - val_accuracy: 0.9299\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2211 - accuracy: 0.9286 - val_loss: 0.2161 - val_accuracy: 0.9297\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2204 - accuracy: 0.9295 - val_loss: 0.2158 - val_accuracy: 0.9296\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2210 - accuracy: 0.9287 - val_loss: 0.2156 - val_accuracy: 0.9297\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2212 - accuracy: 0.9284 - val_loss: 0.2153 - val_accuracy: 0.9296\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2207 - accuracy: 0.9283 - val_loss: 0.2152 - val_accuracy: 0.9297\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2195 - accuracy: 0.9290 - val_loss: 0.2151 - val_accuracy: 0.9296\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2194 - accuracy: 0.9290 - val_loss: 0.2149 - val_accuracy: 0.9296\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2170 - accuracy: 0.9287 - val_loss: 0.2149 - val_accuracy: 0.9297\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2163 - accuracy: 0.9292 - val_loss: 0.2146 - val_accuracy: 0.9297\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2160 - accuracy: 0.9289 - val_loss: 0.2146 - val_accuracy: 0.9302\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2172 - accuracy: 0.9291 - val_loss: 0.2145 - val_accuracy: 0.9299\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2156 - accuracy: 0.9292 - val_loss: 0.2144 - val_accuracy: 0.9300\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2177 - accuracy: 0.9293 - val_loss: 0.2143 - val_accuracy: 0.9296\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2162 - accuracy: 0.9288 - val_loss: 0.2141 - val_accuracy: 0.9300\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2165 - accuracy: 0.9290 - val_loss: 0.2140 - val_accuracy: 0.9299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2168 - accuracy: 0.9292 - val_loss: 0.2139 - val_accuracy: 0.9296\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2141 - accuracy: 0.9297 - val_loss: 0.2138 - val_accuracy: 0.9297\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2172 - accuracy: 0.9286 - val_loss: 0.2138 - val_accuracy: 0.9296\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2143 - accuracy: 0.9293 - val_loss: 0.2137 - val_accuracy: 0.9296\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2155 - accuracy: 0.9290 - val_loss: 0.2138 - val_accuracy: 0.9296\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2147 - accuracy: 0.9298 - val_loss: 0.2136 - val_accuracy: 0.9296\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2137 - accuracy: 0.9297 - val_loss: 0.2135 - val_accuracy: 0.9297\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2121 - accuracy: 0.9301 - val_loss: 0.2134 - val_accuracy: 0.9299\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2134 - accuracy: 0.9292 - val_loss: 0.2133 - val_accuracy: 0.9299\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2137 - accuracy: 0.9291 - val_loss: 0.2132 - val_accuracy: 0.9300\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2118 - accuracy: 0.9295 - val_loss: 0.2132 - val_accuracy: 0.9300\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2120 - accuracy: 0.9296 - val_loss: 0.2132 - val_accuracy: 0.9303\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2114 - accuracy: 0.9302 - val_loss: 0.2131 - val_accuracy: 0.9300\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2134 - accuracy: 0.9292 - val_loss: 0.2131 - val_accuracy: 0.9297\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2127 - accuracy: 0.9294 - val_loss: 0.2130 - val_accuracy: 0.9302\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.9299 - val_loss: 0.2130 - val_accuracy: 0.9302\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.9297 - val_loss: 0.2131 - val_accuracy: 0.9302\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2117 - accuracy: 0.9297 - val_loss: 0.2132 - val_accuracy: 0.9302\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2116 - accuracy: 0.9297 - val_loss: 0.2132 - val_accuracy: 0.9299\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9300 - val_loss: 0.2131 - val_accuracy: 0.9306\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.9305 - val_loss: 0.2131 - val_accuracy: 0.9303\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9302 - val_loss: 0.2130 - val_accuracy: 0.9302\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2107 - accuracy: 0.9309 - val_loss: 0.2130 - val_accuracy: 0.9296\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9304 - val_loss: 0.2131 - val_accuracy: 0.9294\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2091 - accuracy: 0.9309 - val_loss: 0.2130 - val_accuracy: 0.9306\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9303 - val_loss: 0.2130 - val_accuracy: 0.9305\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2101 - accuracy: 0.9305 - val_loss: 0.2129 - val_accuracy: 0.9306\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2104 - accuracy: 0.9309 - val_loss: 0.2129 - val_accuracy: 0.9308\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9302 - val_loss: 0.2129 - val_accuracy: 0.9306\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2091 - accuracy: 0.9312 - val_loss: 0.2128 - val_accuracy: 0.9306\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2096 - accuracy: 0.9302 - val_loss: 0.2128 - val_accuracy: 0.9309\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9307 - val_loss: 0.2128 - val_accuracy: 0.9308\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2092 - accuracy: 0.9298 - val_loss: 0.2127 - val_accuracy: 0.9306\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2091 - accuracy: 0.9300 - val_loss: 0.2127 - val_accuracy: 0.9309\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2082 - accuracy: 0.9312 - val_loss: 0.2128 - val_accuracy: 0.9308\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2081 - accuracy: 0.9311 - val_loss: 0.2127 - val_accuracy: 0.9309\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2070 - accuracy: 0.9300 - val_loss: 0.2127 - val_accuracy: 0.9309\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9312 - val_loss: 0.2129 - val_accuracy: 0.9308\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9314 - val_loss: 0.2127 - val_accuracy: 0.9306\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9307 - val_loss: 0.2128 - val_accuracy: 0.9309\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9317 - val_loss: 0.2127 - val_accuracy: 0.9306\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9313 - val_loss: 0.2126 - val_accuracy: 0.9309\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9299 - val_loss: 0.2127 - val_accuracy: 0.9308\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9300 - val_loss: 0.2126 - val_accuracy: 0.9311\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9297 - val_loss: 0.2126 - val_accuracy: 0.9308\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9312 - val_loss: 0.2126 - val_accuracy: 0.9308\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9312 - val_loss: 0.2127 - val_accuracy: 0.9309\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2064 - accuracy: 0.9314 - val_loss: 0.2129 - val_accuracy: 0.9306\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9309 - val_loss: 0.2129 - val_accuracy: 0.9308\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9299 - val_loss: 0.2128 - val_accuracy: 0.9309\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2058 - accuracy: 0.9305 - val_loss: 0.2127 - val_accuracy: 0.9309\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2056 - accuracy: 0.9311 - val_loss: 0.2127 - val_accuracy: 0.9309\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2064 - accuracy: 0.9311 - val_loss: 0.2126 - val_accuracy: 0.9308\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9308 - val_loss: 0.2126 - val_accuracy: 0.9309\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2055 - accuracy: 0.9307 - val_loss: 0.2125 - val_accuracy: 0.9308\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2041 - accuracy: 0.9306 - val_loss: 0.2127 - val_accuracy: 0.9309\n",
      "Epoch 84/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9314 - val_loss: 0.2126 - val_accuracy: 0.9309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9317 - val_loss: 0.2125 - val_accuracy: 0.9309\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9322 - val_loss: 0.2127 - val_accuracy: 0.9308\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9311 - val_loss: 0.2127 - val_accuracy: 0.9306\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9314 - val_loss: 0.2125 - val_accuracy: 0.9309\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2036 - accuracy: 0.9309 - val_loss: 0.2126 - val_accuracy: 0.9308\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9311 - val_loss: 0.2128 - val_accuracy: 0.9309\n",
      "Epoch 91/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9316 - val_loss: 0.2128 - val_accuracy: 0.9306\n",
      "Epoch 92/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9316 - val_loss: 0.2129 - val_accuracy: 0.9306\n",
      "Epoch 93/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9322 - val_loss: 0.2131 - val_accuracy: 0.9306\n",
      "Epoch 94/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9315 - val_loss: 0.2129 - val_accuracy: 0.9306\n",
      "Epoch 95/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2024 - accuracy: 0.9313 - val_loss: 0.2130 - val_accuracy: 0.9305\n",
      "Epoch 96/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9313 - val_loss: 0.2132 - val_accuracy: 0.9305\n",
      "Epoch 97/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9320 - val_loss: 0.2131 - val_accuracy: 0.9306\n",
      "Epoch 98/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9319 - val_loss: 0.2131 - val_accuracy: 0.9303\n",
      "Epoch 99/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2030 - accuracy: 0.9312 - val_loss: 0.2130 - val_accuracy: 0.9306\n",
      "Epoch 100/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2043 - accuracy: 0.9319 - val_loss: 0.2130 - val_accuracy: 0.9306\n",
      "Epoch 101/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9321 - val_loss: 0.2131 - val_accuracy: 0.9305\n",
      "Epoch 102/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2040 - accuracy: 0.9319 - val_loss: 0.2129 - val_accuracy: 0.9305\n",
      "Epoch 103/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2018 - accuracy: 0.9318 - val_loss: 0.2129 - val_accuracy: 0.9306\n",
      "Epoch 104/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2019 - accuracy: 0.9322 - val_loss: 0.2129 - val_accuracy: 0.9303\n",
      "Epoch 105/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2033 - accuracy: 0.9324 - val_loss: 0.2129 - val_accuracy: 0.9305\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3630 - accuracy: 0.9017 - val_loss: 0.2996 - val_accuracy: 0.9221\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2867 - accuracy: 0.9221 - val_loss: 0.2674 - val_accuracy: 0.9221\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2627 - accuracy: 0.9222 - val_loss: 0.2481 - val_accuracy: 0.9228\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2485 - accuracy: 0.9228 - val_loss: 0.2366 - val_accuracy: 0.9243\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2376 - accuracy: 0.9248 - val_loss: 0.2306 - val_accuracy: 0.9275\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2344 - accuracy: 0.9254 - val_loss: 0.2272 - val_accuracy: 0.9286\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2323 - accuracy: 0.9268 - val_loss: 0.2247 - val_accuracy: 0.9281\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2294 - accuracy: 0.9278 - val_loss: 0.2229 - val_accuracy: 0.9287\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2278 - accuracy: 0.9272 - val_loss: 0.2216 - val_accuracy: 0.9287\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2257 - accuracy: 0.9283 - val_loss: 0.2206 - val_accuracy: 0.9289\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2240 - accuracy: 0.9284 - val_loss: 0.2196 - val_accuracy: 0.9289\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2219 - accuracy: 0.9292 - val_loss: 0.2187 - val_accuracy: 0.9293\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2220 - accuracy: 0.9287 - val_loss: 0.2183 - val_accuracy: 0.9299\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2221 - accuracy: 0.9289 - val_loss: 0.2180 - val_accuracy: 0.9299\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2192 - accuracy: 0.9290 - val_loss: 0.2177 - val_accuracy: 0.9296\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2199 - accuracy: 0.9288 - val_loss: 0.2171 - val_accuracy: 0.9302\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2213 - accuracy: 0.9290 - val_loss: 0.2169 - val_accuracy: 0.9306\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2206 - accuracy: 0.9290 - val_loss: 0.2167 - val_accuracy: 0.9302\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2181 - accuracy: 0.9291 - val_loss: 0.2165 - val_accuracy: 0.9303\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2181 - accuracy: 0.9288 - val_loss: 0.2163 - val_accuracy: 0.9303\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2159 - accuracy: 0.9299 - val_loss: 0.2163 - val_accuracy: 0.9302\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2168 - accuracy: 0.9292 - val_loss: 0.2162 - val_accuracy: 0.9302\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2175 - accuracy: 0.9292 - val_loss: 0.2159 - val_accuracy: 0.9300\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2150 - accuracy: 0.9299 - val_loss: 0.2158 - val_accuracy: 0.9300\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2149 - accuracy: 0.9301 - val_loss: 0.2158 - val_accuracy: 0.9299\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2170 - accuracy: 0.9296 - val_loss: 0.2156 - val_accuracy: 0.9299\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2152 - accuracy: 0.9301 - val_loss: 0.2155 - val_accuracy: 0.9300\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2157 - accuracy: 0.9295 - val_loss: 0.2156 - val_accuracy: 0.9300\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2143 - accuracy: 0.9297 - val_loss: 0.2153 - val_accuracy: 0.9300\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2147 - accuracy: 0.9307 - val_loss: 0.2152 - val_accuracy: 0.9300\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2151 - accuracy: 0.9303 - val_loss: 0.2151 - val_accuracy: 0.9300\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2153 - accuracy: 0.9296 - val_loss: 0.2151 - val_accuracy: 0.9302\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2140 - accuracy: 0.9295 - val_loss: 0.2152 - val_accuracy: 0.9299\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2140 - accuracy: 0.9298 - val_loss: 0.2153 - val_accuracy: 0.9297\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2136 - accuracy: 0.9303 - val_loss: 0.2150 - val_accuracy: 0.9302\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2126 - accuracy: 0.9298 - val_loss: 0.2148 - val_accuracy: 0.9303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2115 - accuracy: 0.9307 - val_loss: 0.2148 - val_accuracy: 0.9300\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2112 - accuracy: 0.9303 - val_loss: 0.2146 - val_accuracy: 0.9300\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2102 - accuracy: 0.9303 - val_loss: 0.2147 - val_accuracy: 0.9303\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2125 - accuracy: 0.9307 - val_loss: 0.2146 - val_accuracy: 0.9302\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2118 - accuracy: 0.9308 - val_loss: 0.2145 - val_accuracy: 0.9302\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2123 - accuracy: 0.9311 - val_loss: 0.2145 - val_accuracy: 0.9302\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2116 - accuracy: 0.9297 - val_loss: 0.2144 - val_accuracy: 0.9302\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.9298 - val_loss: 0.2144 - val_accuracy: 0.9297\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2115 - accuracy: 0.9307 - val_loss: 0.2144 - val_accuracy: 0.9297\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9304 - val_loss: 0.2142 - val_accuracy: 0.9299\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2105 - accuracy: 0.9307 - val_loss: 0.2142 - val_accuracy: 0.9296\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.9311 - val_loss: 0.2140 - val_accuracy: 0.9302\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9310 - val_loss: 0.2141 - val_accuracy: 0.9296\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9301 - val_loss: 0.2141 - val_accuracy: 0.9300\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9302 - val_loss: 0.2142 - val_accuracy: 0.9299\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9315 - val_loss: 0.2143 - val_accuracy: 0.9297\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9310 - val_loss: 0.2142 - val_accuracy: 0.9299\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2082 - accuracy: 0.9312 - val_loss: 0.2144 - val_accuracy: 0.9300\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2091 - accuracy: 0.9301 - val_loss: 0.2144 - val_accuracy: 0.9299\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9311 - val_loss: 0.2144 - val_accuracy: 0.9296\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9305 - val_loss: 0.2144 - val_accuracy: 0.9297\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9313 - val_loss: 0.2142 - val_accuracy: 0.9297\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9311 - val_loss: 0.2141 - val_accuracy: 0.9297\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2064 - accuracy: 0.9315 - val_loss: 0.2142 - val_accuracy: 0.9297\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9314 - val_loss: 0.2140 - val_accuracy: 0.9300\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9310 - val_loss: 0.2140 - val_accuracy: 0.9296\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9312 - val_loss: 0.2139 - val_accuracy: 0.9299\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9310 - val_loss: 0.2140 - val_accuracy: 0.9299\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2083 - accuracy: 0.9307 - val_loss: 0.2141 - val_accuracy: 0.9297\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9308 - val_loss: 0.2140 - val_accuracy: 0.9299\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9312 - val_loss: 0.2142 - val_accuracy: 0.9296\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2073 - accuracy: 0.9305 - val_loss: 0.2142 - val_accuracy: 0.9297\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9312 - val_loss: 0.2142 - val_accuracy: 0.9299\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9316 - val_loss: 0.2141 - val_accuracy: 0.9299\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2061 - accuracy: 0.9321 - val_loss: 0.2142 - val_accuracy: 0.9302\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9305 - val_loss: 0.2141 - val_accuracy: 0.9302\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2066 - accuracy: 0.9318 - val_loss: 0.2140 - val_accuracy: 0.9299\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9326 - val_loss: 0.2142 - val_accuracy: 0.9293\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2056 - accuracy: 0.9308 - val_loss: 0.2141 - val_accuracy: 0.9299\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9320 - val_loss: 0.2141 - val_accuracy: 0.9297\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9316 - val_loss: 0.2142 - val_accuracy: 0.9294\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2064 - accuracy: 0.9310 - val_loss: 0.2141 - val_accuracy: 0.9297\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9319 - val_loss: 0.2141 - val_accuracy: 0.9296\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2058 - accuracy: 0.9312 - val_loss: 0.2141 - val_accuracy: 0.9294\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9311 - val_loss: 0.2141 - val_accuracy: 0.9294\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2055 - accuracy: 0.9315 - val_loss: 0.2141 - val_accuracy: 0.9296\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9316 - val_loss: 0.2139 - val_accuracy: 0.9297\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3627 - accuracy: 0.9026 - val_loss: 0.3028 - val_accuracy: 0.9185\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2860 - accuracy: 0.9232 - val_loss: 0.2744 - val_accuracy: 0.9185\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2651 - accuracy: 0.9232 - val_loss: 0.2560 - val_accuracy: 0.9185\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2514 - accuracy: 0.9234 - val_loss: 0.2436 - val_accuracy: 0.9185\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2414 - accuracy: 0.9238 - val_loss: 0.2355 - val_accuracy: 0.9207\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2346 - accuracy: 0.9254 - val_loss: 0.2305 - val_accuracy: 0.9230\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2316 - accuracy: 0.9280 - val_loss: 0.2276 - val_accuracy: 0.9255\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2280 - accuracy: 0.9272 - val_loss: 0.2255 - val_accuracy: 0.9253\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2260 - accuracy: 0.9283 - val_loss: 0.2240 - val_accuracy: 0.9259\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2240 - accuracy: 0.9284 - val_loss: 0.2232 - val_accuracy: 0.9255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2231 - accuracy: 0.9287 - val_loss: 0.2221 - val_accuracy: 0.9256\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2222 - accuracy: 0.9287 - val_loss: 0.2215 - val_accuracy: 0.9255\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2208 - accuracy: 0.9297 - val_loss: 0.2209 - val_accuracy: 0.9258\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2200 - accuracy: 0.9299 - val_loss: 0.2202 - val_accuracy: 0.9255\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2189 - accuracy: 0.9294 - val_loss: 0.2199 - val_accuracy: 0.9255\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2199 - accuracy: 0.9296 - val_loss: 0.2196 - val_accuracy: 0.9258\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2193 - accuracy: 0.9294 - val_loss: 0.2190 - val_accuracy: 0.9258\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2193 - accuracy: 0.9304 - val_loss: 0.2188 - val_accuracy: 0.9258\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2187 - accuracy: 0.9296 - val_loss: 0.2185 - val_accuracy: 0.9261\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2156 - accuracy: 0.9302 - val_loss: 0.2183 - val_accuracy: 0.9261\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2158 - accuracy: 0.9297 - val_loss: 0.2181 - val_accuracy: 0.9259\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2146 - accuracy: 0.9304 - val_loss: 0.2179 - val_accuracy: 0.9262\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2156 - accuracy: 0.9301 - val_loss: 0.2177 - val_accuracy: 0.9262\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2166 - accuracy: 0.9299 - val_loss: 0.2174 - val_accuracy: 0.9266\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2168 - accuracy: 0.9306 - val_loss: 0.2171 - val_accuracy: 0.9263\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2142 - accuracy: 0.9302 - val_loss: 0.2171 - val_accuracy: 0.9265\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2151 - accuracy: 0.9293 - val_loss: 0.2168 - val_accuracy: 0.9263\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2138 - accuracy: 0.9302 - val_loss: 0.2165 - val_accuracy: 0.9262\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2124 - accuracy: 0.9310 - val_loss: 0.2164 - val_accuracy: 0.9262\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2141 - accuracy: 0.9314 - val_loss: 0.2163 - val_accuracy: 0.9262\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2139 - accuracy: 0.9305 - val_loss: 0.2162 - val_accuracy: 0.9262\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2128 - accuracy: 0.9303 - val_loss: 0.2161 - val_accuracy: 0.9261\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2119 - accuracy: 0.9309 - val_loss: 0.2159 - val_accuracy: 0.9262\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2122 - accuracy: 0.9307 - val_loss: 0.2158 - val_accuracy: 0.9262\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2133 - accuracy: 0.9298 - val_loss: 0.2157 - val_accuracy: 0.9262\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9312 - val_loss: 0.2155 - val_accuracy: 0.9262\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2138 - accuracy: 0.9296 - val_loss: 0.2154 - val_accuracy: 0.9262\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2113 - accuracy: 0.9297 - val_loss: 0.2153 - val_accuracy: 0.9265\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2112 - accuracy: 0.9300 - val_loss: 0.2151 - val_accuracy: 0.9265\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2119 - accuracy: 0.9302 - val_loss: 0.2151 - val_accuracy: 0.9261\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2114 - accuracy: 0.9315 - val_loss: 0.2150 - val_accuracy: 0.9262\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9313 - val_loss: 0.2150 - val_accuracy: 0.9266\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2126 - accuracy: 0.9316 - val_loss: 0.2151 - val_accuracy: 0.9265\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9313 - val_loss: 0.2149 - val_accuracy: 0.9268\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9315 - val_loss: 0.2148 - val_accuracy: 0.9266\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2104 - accuracy: 0.9310 - val_loss: 0.2147 - val_accuracy: 0.9266\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9309 - val_loss: 0.2146 - val_accuracy: 0.9265\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9319 - val_loss: 0.2146 - val_accuracy: 0.9272\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9318 - val_loss: 0.2143 - val_accuracy: 0.9266\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9316 - val_loss: 0.2143 - val_accuracy: 0.9271\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9304 - val_loss: 0.2143 - val_accuracy: 0.9272\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9316 - val_loss: 0.2143 - val_accuracy: 0.9266\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9306 - val_loss: 0.2143 - val_accuracy: 0.9269\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9313 - val_loss: 0.2141 - val_accuracy: 0.9269\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2091 - accuracy: 0.9305 - val_loss: 0.2140 - val_accuracy: 0.9272\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9312 - val_loss: 0.2140 - val_accuracy: 0.9272\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9310 - val_loss: 0.2141 - val_accuracy: 0.9268\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9322 - val_loss: 0.2140 - val_accuracy: 0.9271\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9318 - val_loss: 0.2142 - val_accuracy: 0.9275\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9312 - val_loss: 0.2141 - val_accuracy: 0.9269\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2079 - accuracy: 0.9314 - val_loss: 0.2139 - val_accuracy: 0.9272\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9318 - val_loss: 0.2139 - val_accuracy: 0.9271\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9318 - val_loss: 0.2138 - val_accuracy: 0.9269\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9322 - val_loss: 0.2139 - val_accuracy: 0.9277\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9320 - val_loss: 0.2138 - val_accuracy: 0.9274\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9318 - val_loss: 0.2137 - val_accuracy: 0.9275\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9319 - val_loss: 0.2138 - val_accuracy: 0.9278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9304 - val_loss: 0.2138 - val_accuracy: 0.9275\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9314 - val_loss: 0.2137 - val_accuracy: 0.9274\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9321 - val_loss: 0.2138 - val_accuracy: 0.9275\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9321 - val_loss: 0.2136 - val_accuracy: 0.9277\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9322 - val_loss: 0.2136 - val_accuracy: 0.9274\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9322 - val_loss: 0.2138 - val_accuracy: 0.9272\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9321 - val_loss: 0.2137 - val_accuracy: 0.9271\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2064 - accuracy: 0.9315 - val_loss: 0.2137 - val_accuracy: 0.9274\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9322 - val_loss: 0.2137 - val_accuracy: 0.9275\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9319 - val_loss: 0.2136 - val_accuracy: 0.9277\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9316 - val_loss: 0.2136 - val_accuracy: 0.9277\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2041 - accuracy: 0.9322 - val_loss: 0.2136 - val_accuracy: 0.9275\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9319 - val_loss: 0.2136 - val_accuracy: 0.9275\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9312 - val_loss: 0.2135 - val_accuracy: 0.9278\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9323 - val_loss: 0.2134 - val_accuracy: 0.9278\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2049 - accuracy: 0.9315 - val_loss: 0.2135 - val_accuracy: 0.9280\n",
      "Epoch 84/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2034 - accuracy: 0.9321 - val_loss: 0.2136 - val_accuracy: 0.9278\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2036 - accuracy: 0.9324 - val_loss: 0.2134 - val_accuracy: 0.9277\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9323 - val_loss: 0.2133 - val_accuracy: 0.9281\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9326 - val_loss: 0.2133 - val_accuracy: 0.9284\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9318 - val_loss: 0.2135 - val_accuracy: 0.9278\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9327 - val_loss: 0.2134 - val_accuracy: 0.9281\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9334 - val_loss: 0.2135 - val_accuracy: 0.9283\n",
      "Epoch 91/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9325 - val_loss: 0.2135 - val_accuracy: 0.9281\n",
      "Epoch 92/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9319 - val_loss: 0.2134 - val_accuracy: 0.9283\n",
      "Epoch 93/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2026 - accuracy: 0.9331 - val_loss: 0.2134 - val_accuracy: 0.9280\n",
      "Epoch 94/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2021 - accuracy: 0.9324 - val_loss: 0.2134 - val_accuracy: 0.9281\n",
      "Epoch 95/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9323 - val_loss: 0.2135 - val_accuracy: 0.9281\n",
      "Epoch 96/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2019 - accuracy: 0.9332 - val_loss: 0.2135 - val_accuracy: 0.9278\n",
      "Epoch 97/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9317 - val_loss: 0.2135 - val_accuracy: 0.9280\n",
      "Epoch 98/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9329 - val_loss: 0.2135 - val_accuracy: 0.9278\n",
      "Epoch 99/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9323 - val_loss: 0.2135 - val_accuracy: 0.9275\n",
      "Epoch 100/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9327 - val_loss: 0.2135 - val_accuracy: 0.9278\n",
      "Epoch 101/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9328 - val_loss: 0.2136 - val_accuracy: 0.9277\n",
      "Epoch 102/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2020 - accuracy: 0.9330 - val_loss: 0.2134 - val_accuracy: 0.9278\n",
      "Epoch 103/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2026 - accuracy: 0.9328 - val_loss: 0.2135 - val_accuracy: 0.9280\n",
      "Epoch 104/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9326 - val_loss: 0.2136 - val_accuracy: 0.9280\n",
      "Epoch 105/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9320 - val_loss: 0.2136 - val_accuracy: 0.9280\n",
      "Epoch 106/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2028 - accuracy: 0.9330 - val_loss: 0.2135 - val_accuracy: 0.9278\n"
     ]
    }
   ],
   "source": [
    "model1_a = Model2KMeans()\n",
    "pred_train_1a , preds_test_1a = predict_cv_classfier(model1_a, train_x, train_y, test_x)\n",
    "\n",
    "model_1b = Model1xgb()\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_1b, train_x, train_y, test_x)\n",
    "\n",
    "model_1c = Model1NNproba()\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_1c, train_x_nn, train_y, test_x_nn)\n",
    "\n",
    "\n",
    "model_1d = Model1ramdom()\n",
    "pred_train_1d, pred_test_1d = predict_cv(model_1d, train_x, train_y, test_x)\n",
    "\n",
    "\n",
    "model_1e = Model1xgb2()\n",
    "pred_train_1e, pred_test_1e = predict_cv(model_1e, train_x, train_y, test_x)\n",
    "\n",
    "model_1f = Model1NN2proba()\n",
    "pred_train_1f, pred_test_1f = predict_cv(model_1f, train_x_nn, train_y, test_x_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 7.3887\n",
      "logloss: 0.2068\n",
      "logloss: 0.2124\n",
      "logloss: 0.2492\n",
      "logloss: 0.2129\n",
      "logloss: 0.2117\n"
     ]
    }
   ],
   "source": [
    "print(f'logloss: {log_loss(train_y, pred_train_1a, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1b, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1c, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1d, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1e, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1f, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_2 = pd.DataFrame({'pred_1a': pred_train_1a, 'pred_1b': pred_train_1b, 'pred_1c':pred_train_1c,'pred_1d':pred_train_1d, 'pred_1e':pred_train_1e, 'pred_1f': pred_train_1f})\n",
    "test_x_2 = pd.DataFrame({'pred_1a': preds_test_1a, 'pred_1b': pred_test_1b, 'pred_1c': pred_test_1c,'pred_1d':pred_test_1d, 'pred_1e':pred_test_1e, 'pred_1f': pred_test_1f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.2073\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model3logistic()\n",
    "pred_train_2, pred_test_2 = predict_cv(model_2, train_x_2, train_y, test_x_2)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV1fn48c+ThLAkhJ2wyw6CAmIEtS7BrbiVWq1KrWsttUr39qs/u1mttVW7aKu11AW1KlZrK664BlFEEUVkEWQn7GsggYQk9/n9cU5guNyEm5Cbm5t53q/XfXFn5szMcyaXeWbOzJwRVcUYY0x4pSU7AGOMMcllicAYY0LOEoExxoScJQJjjAk5SwTGGBNylgiMMSbkLBEYY0zIWSIwxpiQs0RQCyKyUkT2iEixiGwQkckikh1V5kQReUtEdolIkYi8ICJDosrkiMhfRGS1X9ZSP9yxYWtUeyIySUQmBIbzRURF5P+iyuWLSGGM+QtE5NrA8EAReUZEtvjtNU9Efiwi6dWs/2YRWeG3W6GIPF2f9UsEERkhInNEZLf/d0QNZduLyNN+e2wRkSdEJMdP6ygi74nIVhHZISLvi8iXAvOKiPxWRNb6bVkgIkOjln+piCwSkRIRWSYiJ/vxmSLyrP+Nq4jkR803RkTe9stdGSPut0Vks4jsFJFPRWRcNfV7xC+/f2BccxF52M+7QUR+HJg2UESe98veJiLTRGRQ1DL7isiL/v/cFhG5MzBtooh8JCJlIjI5ar7ePpbiwOeXUdvzD357bxWRO0VE/LReUfMV+2X9JJ46Nzqqap84P8BK4Az/vQvwKXB7YPoJQDHwA6A10B74LbAd6OvLZAKzgdeBIbhk3Bn4JXBOAmPPqKflrAZ6BIYfAbYCC6LK5QOFMeYvAK713/v5bfMnoKsfNwh4EmgbY94rgUVAv8DfYEJj3E6B5WUCq4AfAc2B7/vhzGrK3w+8BuQAbYA3gD/5aS389kkDBPgqsK0qZuBiYB3QF0gH7gA+Diz7TL/u4/0yugPdA3H+EDgJWA/kR8U1CrgcmACsjBH3sEAco4FdVX/TQJmTgHcABfoHxt8BzADaAUcCG4CxgfV+y/9fagbcBnwetX2XAT8Gsvw2GhaY/jW/nf4OTI6Kp7ePJebfHPgOsBjo4bfVQuC6asr2ASqB3vHUubF9kh5AKn0IJAI/fCfwUmB4BnB/jPleAR7z368FNgLZtVjvUFzi2ObnvdmPnwz8NlAun8DO18d7IzAPKAN+ATwbtex7gHv99zbAQ35HsBaXxNIDZYcB8wLDrfx/+EuBvUBedbEExhewPxH8K7j94tgOfwP+UsP09rjEtA6XYP4XmPZtYKnfhlOBboFpCtwAfAGs8OPOA+YCO4CZwZ1LLX8zZ/ltKYFxq/E7ump+K9cHhm8ApsUolwac72Pv7MfdCPw76ndTGhieCXwrjpgLiUoEgWlnECMRRJUZBZQCowLjMoBP/G8oOhGsBc4KDN8GTKnhb6xABz88AZgRR51+S+0TwUwCBxq4hDSrmrK/Bt6OGldtnRvbx5qG6khEegBn43YuiEgr4ETgmRjF/407GgP3H+lVVS2Ocz2tcUeFrwLdgP7Am7UIdTxwLtAWeBw4J9DUkI47inzSl30UqPDrOAa3E7s2sKxzgJcCwxfizoCeAaYBV9QiLnDb4tlalJ8FXCEiPxORvBjNR4/jktNQ3FnWnwFE5DTcUefFQFfcUfGUqHm/ijuSHSIiI4GHcUeEHYB/AFNFpHmsoHyzxE3VxDwUlzyDnXrN8+NjuQ84T0TaiUg73DZ+JWp983A72qnAg6q6yU+aAvT3zSnNcGdQr/p50oE8oJO4pshCEfmbiLSsJo5a89uhFPgAl/A/Ckz+EfCOqs6Lmqcd7nf9aWD0p1S/fU4BNqjqVj98PLBSRF7xzUIFInJ0LUNf5bfHI3Jg8+zQWsR1Be7/T1DMOjdKyc5EqfTBHWEX446CFbdDbuun9fDjBseYbyxQ7r+/Dvy+FuscD3xSzbTJHPqM4Jqoed4FrvDfzwSW+e+5uLOGllHrfjswPAM4OTD8Bv4I3ZfdDDSLFUtgngL2nxGUU82RcQ3b4zK/3hJck9RNfnxXIAK0izHPQ8CdgeFsv+7efliB0wLT/w7cFrWMxcCpdfjN/JKoo1vgCeCWasp38/WL+M/rxGhGwjWBjAeuDIzLxJ3hKS6hrwD6BJaruJ1zV6Aj8B6Bps3Acup8RoBrvjkb+FFgXE/cAVObwPbuH5imQItA+TNjrQP3f2wtMD4w7jX/tzzb1/9nwPLobUbsM4JsXHLM8L//ZwmcfeGaegYHhgf4WCVqOSfj9gvZ8dS5MX7sjKD2vqqqrXE7usG4/1DgmiIiuP9k0boCW/z3rdWUqU5PXBtoXa2JGn4StwMB+Ab7zwaOwP0nXu8vRO7AHQl3BhCRtrj6zvTDPYExuJ0awPO4ndO5frjCLy9aM9x/XKj9tkBVn1DVM3BnONcBt4rIl3HbaZuqbo8xWzfcWUDVMor9ursHygS30xHAT6q2g98WPf1yaqsY194flIM7mIjlGWAJ7hpTDu5v/6/oQqpaqqpPATeJyHA/+tfAcT7WFsBvgLf82eoeX+avqrpeVbfgrs2cU4c6VUtVy1X1FeDLIvIVP/ovwK2qWhRjlqoz4+A2Omj7iEgn3E7/fl/vKnuAd1X1FVXdC9yNO4s7Mo5Yi1X1I1WtUNWNwETgrKozZg7+2+UAxer37AFXAv/RA8/ya6pzo2OJoI5UdTruiPxuP1wCvA98PUbxi9nfnPMG7j9JVpyrWoO7qBpLCa4ppEqXWKFGDT8D5PumrQvYnwjW4M4IOqpqW//JUdWqU+EvA2+qaqUfvhz3+3lBRDbgjsJasL95aDXQUQJ3Vfk7Lo5g/075DVzTR635Hc4zuGaWo3z87X3CirbOr7cqjizczmJtcJGB72twR8ptA59WUTugeC0AhlXdbeIN8+NjGQ78Q1VL/I7lAWreWTfDXRyumvdpVS30O7fJuAuwQ3yCLOTg30OiZLD/d3s6cJe/I2iDH/e+iHzDx7Xex15lOIHt45uPXgOmqurtUeuZR/3VqWo5VX+rBTXF5WNrifs/H90sVG2d6ynW+pXsU5JU+nDwxeJOuJ3xCD98kh/+Pu6Irh3ulHQHMMCXaY67a+hV3BF2Gm6ndDMx7hryy1mPu6OjuR8e7ad9G/gcdwGtC64NPbpp6IwYy3wF1+TwSdT453FNCzk+rn745hDgMXyTkh/+HLjFr7fq8xVcMqm6kDcT1+ad7WP/Px9TCz+9H+7i7V1AFz+uP+4IONZdQ1fhzjha+/jOxh0RnuSnv4RLbO1wO8hT/PjTcc1WI3wc9+COIquWG33xMg+XDEbjdgpZVeutw2+m6q6hH/h1T6Tmu4beBv4KtPSf+4H3/LTj/W8s00+7EXfk3M1P/zWu6S/Xb5/Lcb/HqubLW3G/vc5+G80g0ATm42uBSxhn+e/ip6X54bN9/C2q6oD7HZ/tY2oGfBN388BIP71z1O9EfV1a+um/B6b7mAbjfu9Vdw3lAB8Cf6tmew0CduOarNJx7fLLArFl+FjvwF1DasGBdzdV3YXVAXiaA5tCr8PdpdYddza4gKi7hnBn1as4uLmoxjo3tk/SA0ilDzF2rLj25P8Ehk/CtYMXAztxO6ejouZpgzt1XOPLLcOdpneoZr1H4c4otuNuratqF2/hf7w7cUdGPyK+RHC5/2H+LEZcf/c7giLcHQ+X4naG69l/d8rxuIuVnWIsewEw0X/viTsD2YBrGpuGOzoNlh/ky2z16/wUl/TSYyz7a7h27e2+zp8BVwWmt8cdmW30ZZ4LTLvOb+dtwIsceAvsQe23uOs6s3FJfL2PMWYiwCXWm2v43RwDzMElrY+BYwLTLiNw6y3uNsQX/PbYhjtgqDqIONVvn11+2nR8sgv8Hu7z8e706xobmN4Ml1h2+L/JvRzYNr/Sb4vgp7eflh9jWoGfdiTuAvEuv+zZwAU1bI/oxNscd3F+p//b/Tgw7UpfvgT3f6Xq0yvqd7HUz18ADA1MuyVG3Lf4aeNx11FK/DZ7DH9A4qcL7s7Abf5zJwfv8KcRdT0pnjo3tk9VtjemWiIyCndENirZsRhj6p9dIzDx+nWyAzDGJIadERhjTMjZGYExxoRcRrIDqK2OHTtq79696zRvSUkJWVnx3rXZNFidw8HqHA6HU+c5c+ZsUdVOsaalXCLo3bs3H3300aELxlBQUEB+fn79BtTIWZ3DweocDodTZxFZVd00axoyxpiQs0RgjDEhZ4nAGGNCzhKBMcaEnCUCY4wJuYQlAv8O0k0iMr+a6SIi9/qXZMzzLwMxxhjTwBJ5RjAZ13FXdc7GvehhAO51c39PYCzGGGOqkbDnCFT1HRHpXUORcbj3+CowS0TaikhXVV2fqJiMMaa+rN2xh2WbiikpqyCioCiqvotT33WPBscrRFSp6ov0wPLBcsoXm4pp2/Lg9zpl7qwgPwF1SeYDZd058K1QhX7cQYlARCbgzhrIzc2loKCgTissLi6u87ypyuocDlbnQ1NVyiOwtxK2lkYorYD1JREEtzOOBHfK6l43GNyxR4BVOyOs3RVhXUnD9NEmUcNn9NCE/J2TmQii6wjVvGlIVScBkwDy8vK0rk/W2ZOI4WB1DoeqOqsq20r2Ul6plFdGqIgoa7btZtbyrazdsYey8gjLNhfzxaaSelv3kK459OmUxVeGd6N18ww6ZDdHxO3U3LvoJDAsCJAmQtV76kT2j3flfHn/PT1NaJ+VWW2d61syE0Eh7sUlVXrgXilojAkpVWVzcRnLNpWwcWcpnxbuIDM9jbKKCPPXFtGqeQal5ZXMWbWdVukKBdPYVVpR4zIH5mbTvFkag3JbM7RbDkO7tyESUfrnZpPdPINO2c1pmZmOiNtZu4/bUacFxlVNz8xoejdbJjMRTAUmisgU3Cvjiuz6gDFNV1lFJWUVEbaX7GXR+p1s2lXGRyu3U7SnnCUbd7G+qLTaeVu3yKBZehq791YwvEdbTujbga3btjF6cA+aZ6RRWl7JoC45ZKQLzdKF9LQ0erZryVHd29AsventuOtbwhKBiDyFe71dRxEpxL3YpBmAqj4AvIx7KfdS3DtHr05ULMaYhrGluIyF63ZSWl7Jii0lzFtbxNrte5i7ZkeN83Vq3ZxRvdtzdI82tGnZjNyc5vRqn0W/zll0bt0i5jyumWRoIqoROom8a2j8IaYrcEOi1m+MqR8bikqZu2Y7C9fvorwywt6KCOWVET5ZvYO2rZpRXhmhuKyC+Wt3xpx/cJfWDOmaQ/d2LTm+bweaZ6TRKjOdYT3a0LN9K5pnpDdwjUy0lOuG2hhTf0rLK9mzt5LV23ZTsreCf81aRXbzDD5evYOWzdL5bG3RQfNkZaaTmZGGiLByawlHds2hbctMvtS/A7k5LTi6exuO692e5hlpdGrdnLatDr7oaRoXSwTGNHHFZRX895O1zC8sYmvJXj5evZ1WmekUbt9T7Tx9OmaxtbiMc4/uCgLnHt2VgbnZHNEhy9rcmyBLBMY0IarK4o27eOqD1Sxav4uyygifRrXPH9k1h9YtMjh5QEd2761kRM+2qMKgLq3Jap7B8B5tEIl1d7dpqiwRGJNiSssrWbxhFyu3lvDRyu2UV0b4dNkerpn2EpGoJ3HatmrG6YM7c9qRnRk3ojvZze2/vDmY/SqMSQHri/awcN1OXpm/gWfnFB40vXMroWublvRq34r8QZ3IH9SZQV1aJyFSk4osERjTyJRVVPLXN5eybsce9pRXMuOLLRSX7X9oKqdFBpcc15MT+3WkV4dW9O2YxfTp00P3ZLGpP5YIjGkkXpy3jgdnrDjgnvsBnbPp3bEVWZkZjBvRnRP7deCIDq2sDd/UK0sExjSwTTtLWbKxmFfmr+eztUUUbt/DtpK9+6Z3b9uS0wZ35uZzjqRlpt1jbxLPEoExCRSJKG8s2siML7aQJvD0R2soLY8cUKZrmxac2K8DZxyZy/nDu9GpdfMkRWvCyhKBMfWotLySwu27eWZOIf+Zs5YtxWUHTM/NaU5uTjoTx/RnWI+2dkHXNAqWCIw5DEW7y1mwvoj3l23l8Vmr2LG7/IDpZx/VhSO75vDN44+I2a2wMY2BJQJj4vTx6u3c8MTHFJdVUBlRdu+tPKhM305ZXHRsD4Z2a8PxfdtbPzomJVgiMCaGSER5ef56PlyxjQ9XbGPzrjK2+gu6Pdq1ZOzQLmRmpBFR6N2hFUd2zWGYPZFrUpQlAhN6ZRWVzFq+jdVbS/h8wy52763kv5+sPaBM305ZnDqoE+NGdOfUgZ2SFKkxiWGJwITWztJyZi7dwnX/+vigaX07ZdG3YxZ3fG0YHbMz7UjfNGmWCEyoFJdV8OjMlTzy3gq2FO+/d39I1xx+M24og7u0Jiszg7Q02/Gb8LBEYELj1fnrDzj6P3dYV0b0aMvZR3ehR7tWSYzMmOSyRGCarEhEmbe2iDcXbeThd1dQ4u/yGTeiG7ecP5R2djunMYAlAtMElVUo4yfN4oMVWw/olvnCkT343mn96d0xK3nBGdMIWSIwTcLO0nLue2sp89cV8d7S3cBuAMaP6sW4Ed0Y0bMtLZrZPf3GxGKJwKSsNdt289j7K3l2TiHb/RO9rZtnkNUMrj6pPz85a6Dd7WNMHCwRmJSyZttu/vT6EqYv2XxAj5092rXkl+cN4ctDu1BQUEB+/qAkRmlMarFEYBq9isoIL8/fwNOzV/Pe0q37xn91RDcuP6E3I3u1tSN/Yw6DJQLTaC1YV8QtUxcwe+X2A8Y/ds0oTh7Q0Xb+xtQTSwSm0dlespfr/jWHD1ZsA1y7//jRvbg+vx9tWjazBGBMPbNEYBqNTbtK+eGUucxctr/555Grj2PMoM5JjMqYps8SgUm6sopKnp1TyM//Ox9w7+n90ZkDOeforkmOzJhwsERgkuqLjbs488/v7Bu+42tHM35UryRGZEz4WCIwSaGq/OzZeTw7pxCAET3b8uCVeXTMtvf1GtPQLBGYBrVo/U5++synLFi3c9+4x781ipMHWB//xiSLJQLTIDbuLOWaybP3JYAWzdK4Pr8/E8f0ty6fjUmyhCYCERkL3AOkAw+q6u+jprcB/gX08rHcraqPJDIm0/DeX7aV8f+cBUDzjDSmTjyJQV1aJzkqY0yVhCUCEUkH7gPOBAqB2SIyVVUXBordACxU1fNFpBOwWESeUNW9MRZpUtCDM5bz25cWAXDL+UO46kt9khyRMSZaIs8IRgFLVXU5gIhMAcYBwUSgQGtxTwhlA9uAigTGZBpAZUS59YUFPPr+qn3j7rxwGBcf1zOJURljqiOqeuhSdVmwyEXAWFW91g9fDoxW1YmBMq2BqcBgoDVwiaq+FGNZE4AJALm5ucdOmTKlTjEVFxeTnZ1dp3lTVUPWeeueCP9bWs6Mtftz+VEd07nmqEzat0hrkBjA/s5hYXWunTFjxsxR1bxY0xJ5RhDrCmB01vkyMBc4DegHvC4iM1R15wEzqU4CJgHk5eVpfn5+nQJyvVLWbd5Uleg6RyLKc5+sZfLMFcxfWwK4nkCvOrE3157cN2HrrYn9ncPB6lx/EpkICoFgW0APYF1UmauB36s7LVkqIitwZwcfJjAuUw/KKyP85oUF/GvW6n3jhnTN4fun92fsUfZEsDGpJJGJYDYwQET6AGuBS4FvRJVZDZwOzBCRXGAQsDyBMZnDtLO0nDte/pynPtyfAL4yvBu3X3AUrVs0S2Jkxpi6SlgiUNUKEZkITMPdPvqwqi4Qkev89AeA24DJIvIZrinpRlXdkqiYzOF5dOZKfj11wb7hK044glvHHZXEiIwx9SGhzxGo6svAy1HjHgh8XweclcgYzOFbsaWE219ayBuLNgFw50XDuDjP7gAypqmwJ4tNtSoqI3zr0Y+YvmQz4K4B/Pu6E8hubj8bY5oS+x9tYiopq2D0796kuKyC1s0z+McVx3Jiv47JDssYkwCWCMxBlm4q5ow/TQfg1IGdmHz1cfZWMGOaMEsE5gBTP13Hj56eC8DtFxzFZaOPSHJExphEs0RgANi8q4yv/O1d1heVAvDkt0dbU5AxIWGJIORWbS3hB1PmMnfNDgDatGzGyz84me5tWyY5MmNMQ7FEEFKqyr1vLuXPbywB4MiuOXw3vx9fGd4tyZEZYxqaJYIQKq+MMODnrwCQkSY8eGUe+YM6JzkqY0yyWCIImeAdQV1yWvDmT04ly54LMCbUbA8QIvPXFnHeX98F4Jyju/C38SPtNZHGmPgTgYhkqWpJIoMxiXPrCwt5+L0VADx57WhO7G93BBljnEO+LUREThSRhcAiPzxcRO5PeGSm3tzw5Mf7ksD9l420JGCMOUA8ZwR/xr1AZiqAqn4qIqckNCpTLyoqI/zugz0s2V7CwNxsnr/hJFpmpic7LGNMIxNX05CqronqYqAyMeGY+rJpVykX/f19Vm+PMKJnW5769vGWBIwxMcWTCNaIyImAikgm8H18M5FpnN5evImrH5kNwGk9M3jo+hOtryBjTLXiSQTXAfcA3XGvn3wNuD6RQZm6+fdHa7j9pUUU7SkH4HcXHE23PcstCRhjahRPIhikqpcFR4jIl4D3EhOSqa3tJXv5zuNz+HDlNgDGDu3CHV87mnZZmRQU2Js/jTE1iycR/BUYGcc4kwSPvb+SXz2///WRz9/wJYb3bJu8gIwxKafaRCAiJwAnAp1E5MeBSTm4dxCbJJu1fOu+JHDv+GOsnyBjTJ3UdEaQCWT7Mq0D43cCFyUyKHNob32+kWsmfwTAg1fkccaQ3CRHZIxJVdUmAlWdDkwXkcmquqoBYzKH8I/py7jjlc/d98uPtSRgjDks8Vwj2C0idwFDgRZVI1X1tIRFZWKKRJQJj8/hjUUbAXjmuhM4rnf7JEdljEl1h+xiAngC+BzoA/wGWAnMTmBMphq/fWnRviQw91dnWhIwxtSLeBJBB1V9CChX1emqeg1wfILjMlFWbCnhkZkrGN6jDSvuOIe2rTKTHZIxpomIp2mo3P+7XkTOBdYBPRIXkom2tbiMbz74Aarwx4tH2ANixph6FU8i+K2ItAF+gnt+IAf4YUKjMvtMW7CB7zw+B4DvnNKX/p2zkxyRMaapOWQiUNUX/dciYAzse7LYJNhD767gthcXAnD314dz0bF2ImaMqX81PVCWDlyM62PoVVWdLyLnATcDLYFjGibEcHp+7tp9SeDF753EUd3bJDkiY0xTVdMZwUNAT+BD4F4RWQWcANykqv9riODC6q3PN/KDKXPJSBNm//wM2mXZhWFjTOLUlAjygGGqGhGRFsAWoL+qbmiY0MKpcPtuvvWoe2L4sWtGWRIwxiRcTbeP7lXVCICqlgJLapsERGSsiCwWkaUiclM1ZfJFZK6ILBCR6bVZflNTXhnh5DvfRhXuumiYvVLSGNMgajojGCwi8/x3Afr5YQFUVYfVtGB/jeE+4Ezcewxmi8hUVV0YKNMWuB8Yq6qrRaTzYdQl5d3wxMeowmmDO/P1vJ7JDscYExI1JYIjD3PZo4ClqrocQESmAOOAhYEy3wCeU9XVAKq66TDXmbJufWEhry3cyMhebXnoyrxkh2OMCRFR1cQsWOQi3JH+tX74cmC0qk4MlPkL0AzXj1Fr4B5VfSzGsiYAEwByc3OPnTJlSp1iKi4uJju78d2H/8SiMl5fVUFOJvzupFZkZ9bfA2ONtc6JZHUOB6tz7YwZM2aOqsY8yozr5fV1FGtvFp11MoBjgdNxt6S+LyKzVHXJATOpTgImAeTl5Wl+fn6dAiooKKCu8yaCqvLDp+fy+qp1dMlpwWs/PoWcFs3qdR2Nrc4NweocDlbn+pPIRFCIu/20Sg9c9xTRZbaoaglQIiLvAMOBJTRxZRWVjLmrgHVFpbRr1Yy3f5pPy0x7348xpuHF0+kcItJSRAbVctmzgQEi0kdEMoFLgalRZZ4HThaRDBFpBYwGFtVyPSnpvreWsq6olDGDOjHzptMtCRhjkuaQiUBEzgfmAq/64REiEr1DP4iqVgATgWm4nfu/VXWBiFwnItf5Mov8cufhHlx7UFXn17UyqeKD5Vu5962lHNe7HQ9fdZwlAWNMUsXTNHQL7g6gAgBVnSsiveNZuKq+DLwcNe6BqOG7gLviWV5TsGbbbi6ZNAuA2756lPUkaoxJuniahipUtSjhkYRAJKJc+ciHANw4djCDu+QkOSJjjInvjGC+iHwDSBeRAcD3gZmJDatpunPaYpZvLmF0n/Z8N79fssMxxhggvjOC7+Hu8y8DnsR1R23vI6iluWt28MD0ZRzRoRVPXDs62eEYY8w+8ZwRDFLVnwM/T3QwTVVFZYSv3vceAPdcegwZ6XHdrGWMMQ0inj3Sn0TkcxG5TUSGJjyiJuiXzy8A4IoTjmBEz7ZJjsYYYw50yESgqmOAfGAzMElEPhORXyQ6sKbitQUbeOrD1QzMzebX51seNcY0PnG1UajqBlW9F7gO90zBrxIaVROxbHMxE/z7hv95RR7paXarqDGm8YnngbIjReQWEZkP/A13x5C9PLcGkYjy0rz1nP5H93qF33/taI7okJXkqIwxJrZ4LhY/AjwFnKWq0X0FmSiqSv7dBazethuA6/P7cemoXkmOyhhjqnfIRKCqxzdEIE3FI++tZPW23fTtlMWT1x5PlzYtkh2SMcbUqNpEICL/VtWLReQzDuw+Oq43lIVR0e5y/vz6Etel9A9PsdtEjTEpoaYzgh/4f89riECagpv/+xm7yip47FujLAkYY1JGtXsrVV3vv16vqquCH+D6hgkvdRTtLuelz9bTu0MrjunVLtnhGGNM3OI5bD0zxriz6zuQVPe7l91rFG75ij0rYIxJLTVdI/gu7si/r4jMC0xqDbyX6MBSyfvLtvL0R2vokJXJKQM6JTscY4yplZquETwJvALcAdwUGL9LVbclNKoUsmlXKeP/6d4v8M8r80izh8aMMSmmpkSgqrpSRG6IniAi7S0ZwNufb+LqybMB+MW5RzLSrg0YY1LQoc4IzgPm4G4fDR7qKtA3gXE1env2VvK9pz4B4NZxQ7nihN7JDQC1ynUAABOhSURBVMgYY+qo2kSgquf5f/s0XDip4zcvLKC4rII/fn04Fx5rPW4YY1JXPH0NfUlEsvz3b4rIn0Qk1H0mVFRGmLZgA80z0jh/eLdkh2OMMYclnttH/w7sFpHhwP8Bq4DHExpVI3fntMVs313O7RccTWaGPThmjElt8b68XoFxwD2qeg/uFtJQ+mjlNia9s5yjuudw4cjuyQ7HGGMOWzy9j+4Skf8HXA6cLCLpQLPEhtV4/XPGcgD+fPEIROxWUWNM6ovnjOAS3Ivrr1HVDUB34K6ERtVIfbB8K9MWbOTUgZ0YkBvakyJjTBMTz6sqNwBPAG1E5DygVFUfS3hkjdCzcwoBuOfSEUmOxBhj6k88dw1dDHwIfB24GPhARC5KdGCNzcadpTwzp5Bzh3WlbavMZIdjjDH1Jp5rBD8HjlPVTQAi0gl4A3g2kYE1Nve8+QUA5w/rmuRIjDGmfsVzjSCtKgl4W+Ocr8mIRJQnP1gNwJlDuiQ5GmOMqV/xnBG8KiLTcO8tBnfx+OXEhdT4PPGhSwJXnnAE6dapnDGmiYnnncU/E5GvASfh+huapKr/TXhkjciUD1fTrlUz/t85RyY7FGOMqXc1vY9gAHA30A/4DPipqq5tqMAai2Wbi1mwbic/PWsgLZqlJzscY4ypdzW19T8MvAhciOuB9K+1XbiIjBWRxSKyVERuqqHccSJS2RjvRrr5uc8AOG+Y9SlkjGmaamoaaq2q//TfF4vIx7VZsH8C+T7cqy4LgdkiMlVVF8Yo9wdgWm2W3xD++NpiPlixjWE92tC7Y1aywzHGmISoKRG0EJFj2P8egpbBYVU9VGIYBSxV1eUAIjIF11/Rwqhy3wP+AxxXy9gTas/eSp74YDUi8O/vnJDscIwxJmHE9ScXY4LI2zXMp6p6Wo0Lds08Y1X1Wj98OTBaVScGynTHvQDnNOAh4EVVPej5BBGZAEwAyM3NPXbKlCk1Vqo6xcXFZGdnx1X23bXlPPjZXq4f3pxRXeO5uapxqk2dmwqrczhYnWtnzJgxc1Q1L9a0ml5MM6ZOa9sv1n2W0VnnL8CNqlpZUwduqjoJmASQl5en+fn5dQqooKCAeOZVVX7zx+lkplfwo4tPo1l66j42EW+dmxKrczhYnetPIg91C4GegeEewLqoMnnAFJ8EOgLniEiFqv4vgXEd0pxV21mxpYRvn9wnpZOAMcbEI5GJYDYwQET6AGuBS4FvBAsEX4MpIpNxTUNJTQIAD727AoBLjgv1i9iMMSGRsESgqhUiMhF3N1A68LCqLhCR6/z0BxK17sNRXFbB6ws3cuHIHvTvHK72R2NMOB0yEYhrt7kM6Kuqt/r3FXdR1Q8PNa+qvkxUdxTVJQBVvSquiBNs8YadVESUMYM7JTsUY4xpEPE0gN8PnACM98O7cM8HNEmfrN4BQNc2LZMciTHGNIx4moZGq+pIEfkEQFW3i0iT7ZB/xhdbADimZ9skR2KMMQ0jnjOCcv/0r8K+9xFEEhpVkqgqSzbuYnCX1qRZL6PGmJCIJxHcC/wX6CwitwPvAr9LaFRJ8tnaItYXlXLJcT0PXdgYY5qIeLqhfkJE5gCn4x4S+6qqLkp4ZEnwx9eWAPDlofbyGWNMeMRz11AvYDfwQnCcqq5OZGANbc/eSt5duoUv9e9At7Z2odgYEx7xXCx+CXd9QIAWQB9gMTA0gXE1uDc/30hlRBk/yh4iM8aESzxNQ0cHh0VkJPCdhEWUJK/M3wDA6YNzkxyJMcY0rFp3pOO7n25UXUYfrvLKCNMXb2Z0n/a0zLS3kBljwiWeawQ/DgymASOBzQmLKAk+XbOD4rIKLjy2R7JDMcaYBhfPNYLWge8VuGsG/0lMOMkxr7AIgJG97CEyY0z41JgI/INk2ar6swaKJynuL1hGj3Yt6d+59aELG2NME1PtNQIRyVDVSlxTUJO1bHMxW4rLOLp7m2SHYowxSVHTGcGHuCQwV0SmAs8AJVUTVfW5BMfWIGYscZc7fnTmwCRHYowxyRHPNYL2wFbce4WrnidQoEkkgsUbi8nKTGeAvXvAGBNSNSWCzv6OofnsTwBVYr/xPgV9vmEnA3JbU9M7k40xpimr6TmCdCDbf1oHvld9moRPVu+wN5EZY0KtpjOC9ap6a4NFkgRLNxUD0CGryb5ewRhjDqmmM4Im31Yyc5l7Cc05R3dNciTGGJM8NSWC0xssiiRZsHYnmelpDOtht44aY8Kr2kSgqtsaMpCGpqq8PH89w3u2sQvFxphQq3Wnc03F9t3l7Cqt4IR+HZMdijHGJFVoE8HCdTsBGJhrdwwZY8IttIngrc83AVjXEsaY0AtxItgIQK/2rZIciTHGJFdoE0FZRYQjOrSyC8XGmNALZSLYWlzG+qJSxg7tkuxQjDEm6UKZCGYu2wrAKQM7JTkSY4xJvlAmggX+jqHeHbOSHIkxxiRfKBPBko27AOia0yLJkRhjTPIlNBGIyFgRWSwiS0XkphjTLxORef4zU0SGJzKeKhuKSmmflUlaml0oNsaYhCUC/77j+4CzgSHAeBEZElVsBXCqqg4DbgMmJSqeA1a6pYTeHey2UWOMgcSeEYwClqrqclXdC0wBxgULqOpMVd3uB2cBPRIYT9U62VNeac8PGGOMF8+rKuuqO7AmMFwIjK6h/LeAV2JNEJEJwASA3NxcCgoK6hRQcXExL7zm5q3cubnOy0klxcXFoahnkNU5HKzO9SeRiSBWA3zMV1yKyBhcIjgp1nRVnYRvNsrLy9P8/Pw6BVRQUEB272Hw9vuMO2k4+UNy67ScVFJQUEBdt1eqsjqHg9W5/iQyERQCPQPDPYB10YVEZBjwIHC2qm5NYDyAuz4A0L1dy0SvyhhjUkIirxHMBgaISB8RyQQuBaYGC4hIL+A54HJVXZLAWPapeobArhEYY4yTsDMCVa0QkYnANCAdeFhVF4jIdX76A8CvgA7A/b7PnwpVzUtUTACbdpUC0CozPZGrMcaYlJHIpiFU9WXg5ahxDwS+Xwtcm8gYon2xsZgOWZnW2Zwxxnihe7L4i03F1rWEMcYEhCoR7KlwNy3162SJwBhjqoQqEazeGQHg5AHW66gxxlQJVSLYUVZ1RmDvKTbGmCqhSgRllS4R5LRM6DVyY4xJKaFKBHsr3b/NM+zWUWOMqRKqRFC0150RtGnZLMmRGGNM4xGqRPDF9kqym2eQmRGqahtjTI1CtUeMKEQ0Zr93xhgTWqFLBEd2zUl2GMYY06iEKhGsLY7QrlVmssMwxphGJVSJoFWGsKu0PNlhGGNMoxKqRFAegb7WvYQxxhwgZIlA7RkCY4yJEppEEIkoeyogp4U9VWyMMUGhSQSlFe6x4qzmlgiMMSYoNImguLQCAHuKwBhjDhSaRFBW4bqgzrJXVBpjzAFCkwj2VrpEkGP9DBljzAFCkwjKfSJolh6aKhtjTFxCs1fc5a8RZFoiMMaYA4Rmryj+36prBcYYY5zQJIKIv13I3kVgjDEHClEicJkgLTQ1NsaY+IRmt7gvEYgcoqQxxoRLaBJB1ftoLBEYY8yBQpMIKiNVZwRJDsQYYxqZ0CSC/dcILBMYY0xQaBKBNQ0ZY0xsoUkE+y8WJzkQY4xpZEKUCNy/dkZgjDEHSmgiEJGxIrJYRJaKyE0xpouI3OunzxORkYmKpepiseUBY4w5UMISgYikA/cBZwNDgPEiMiSq2NnAAP+ZAPw9UfGobxpKt7YhY4w5QCLPCEYBS1V1uaruBaYA46LKjAMeU2cW0FZEuiYiGGsaMsaY2BL53sbuwJrAcCEwOo4y3YH1wUIiMgF3xkBubi4FBQW1Dmbd9kqO6ajM/2Q261qE5tIIxcXFddpeqczqHA5W5/qTyEQQ69A7+k2R8ZRBVScBkwDy8vI0Pz+/1sHkAwMKCqjLvKmswOocClbncEhUnRN5aFwI9AwM9wDW1aGMMcaYBEpkIpgNDBCRPiKSCVwKTI0qMxW4wt89dDxQpKrroxdkjDEmcRLWNKSqFSIyEZgGpAMPq+oCEbnOT38AeBk4B1gK7AauTlQ8xhhjYkvkNQJU9WXczj447oHAdwVuSGQMxhhjahae22eMMcbEZInAGGNCzhKBMcaEnCUCY4wJOanqgydViMhmYFUdZ+8IbKnHcFKB1TkcrM7hcDh1PkJVO8WakHKJ4HCIyEeqmpfsOBqS1TkcrM7hkKg6W9OQMcaEnCUCY4wJubAlgknJDiAJrM7hYHUOh4TUOVTXCIwxxhwsbGcExhhjolgiMMaYkGuSiUBExorIYhFZKiI3xZguInKvnz5PREYmI876FEedL/N1nSciM0VkeDLirE+HqnOg3HEiUikiFzVkfIkQT51FJF9E5orIAhGZ3tAx1rc4ftttROQFEfnU1zmlezEWkYdFZJOIzK9mev3vv1S1SX1wXV4vA/oCmcCnwJCoMucAr+DekHY88EGy426AOp8ItPPfzw5DnQPl3sL1gntRsuNugL9zW2Ah0MsPd0523A1Q55uBP/jvnYBtQGayYz+MOp8CjATmVzO93vdfTfGMYBSwVFWXq+peYAowLqrMOOAxdWYBbUWka0MHWo8OWWdVnamq2/3gLNzb4FJZPH9ngO8B/wE2NWRwCRJPnb8BPKeqqwFUNdXrHU+dFWgtIgJk4xJBRcOGWX9U9R1cHapT7/uvppgIugNrAsOFflxty6SS2tbnW7gjilR2yDqLSHfgAuABmoZ4/s4DgXYiUiAic0TkigaLLjHiqfPfgCNxr7n9DPiBqkYaJrykqPf9V0JfTJMkEmNc9D2y8ZRJJXHXR0TG4BLBSQmNKPHiqfNfgBtVtdIdLKa8eOqcARwLnA60BN4XkVmquiTRwSVIPHX+MjAXOA3oB7wuIjNUdWeig0uSet9/NcVEUAj0DAz3wB0p1LZMKomrPiIyDHgQOFtVtzZQbIkST53zgCk+CXQEzhGRClX9X8OEWO/i/W1vUdUSoERE3gGGA6maCOKp89XA79U1oC8VkRXAYODDhgmxwdX7/qspNg3NBgaISB8RyQQuBaZGlZkKXOGvvh8PFKnq+oYOtB4dss4i0gt4Drg8hY8Ogw5ZZ1Xto6q9VbU38CxwfQonAYjvt/08cLKIZIhIK2A0sKiB46xP8dR5Ne4MCBHJBQYByxs0yoZV7/uvJndGoKoVIjIRmIa74+BhVV0gItf56Q/g7iA5B1gK7MYdUaSsOOv8K6ADcL8/Qq7QFO65Mc46Nynx1FlVF4nIq8A8IAI8qKoxb0NMBXH+nW8DJovIZ7hmkxtVNWW7pxaRp4B8oKOIFAK/BppB4vZf1sWEMcaEXFNsGjLGGFMLlgiMMSbkLBEYY0zIWSIwxpiQs0RgjDEhZ4nANEq+t9C5gU/vGsoW18P6JovICr+uj0XkhDos40ERGeK/3xw1bebhxuiXU7Vd5vseN9seovwIETmnPtZtmi67fdQ0SiJSrKrZ9V22hmVMBl5U1WdF5CzgblUddhjLO+yYDrVcEXkUWKKqt9dQ/iogT1Un1ncspumwMwKTEkQkW0Te9Efrn4nIQT2NikhXEXkncMR8sh9/loi87+d9RkQOtYN+B+jv5/2xX9Z8EfmhH5clIi/5/u/ni8glfnyBiOSJyO+Blj6OJ/y0Yv/v08EjdH8mcqGIpIvIXSIyW1wf89+JY7O8j+9sTERGiXvPxCf+30H+SdxbgUt8LJf42B/26/kk1nY0IZTsvrftY59YH6AS15HYXOC/uKfgc/y0jrinKqvOaIv9vz8Bfu6/pwOtfdl3gCw//kbgVzHWNxn/vgLg68AHuM7bPgOycN0bLwCOAS4E/hmYt43/twB39L0vpkCZqhgvAB713zNxvUi2BCYAv/DjmwMfAX1ixFkcqN8zwFg/nANk+O9nAP/x368C/haY/3fAN/33trg+iLKS/fe2T3I/Ta6LCdNk7FHVEVUDItIM+J2InILrOqE7kAtsCMwzG3jYl/2fqs4VkVOBIcB7vmuNTNyRdCx3icgvgM24HlpPB/6rrgM3ROQ54GTgVeBuEfkDrjlpRi3q9Qpwr4g0B8YC76jqHt8cNUz2v0WtDTAAWBE1f0sRmQv0BuYArwfKPyoiA3A9UTarZv1nAV8RkZ/64RZAL1K7PyJzmCwRmFRxGe7tU8eqarmIrMTtxPZR1Xd8ojgXeFxE7gK2A6+r6vg41vEzVX22akBEzohVSFWXiMixuP5e7hCR11T11ngqoaqlIlKA6zr5EuCpqtUB31PVaYdYxB5VHSEibYAXgRuAe3H97bytqhf4C+sF1cwvwIWqujieeE042DUCkyraAJt8EhgDHBFdQESO8GX+CTyEe93fLOBLIlLV5t9KRAbGuc53gK/6ebJwzTozRKQbsFtV/wXc7dcTrdyfmcQyBddR2Mm4ztTw/363ah4RGejXGZOqFgHfB37q52kDrPWTrwoU3YVrIqsyDfie+NMjETmmunWY8LBEYFLFE0CeiHyEOzv4PEaZfGCuiHyCa8e/R1U343aMT4nIPFxiGBzPClX1Y9y1gw9x1wweVNVPgKOBD30Tzc+B38aYfRIwr+picZTXcO+lfUPd6xfBvSdiIfCxuJeW/4NDnLH7WD7Fdc18J+7s5D3c9YMqbwNDqi4W484cmvnY5vthE3J2+6gxxoScnREYY0zIWSIwxpiQs0RgjDEhZ4nAGGNCzhKBMcaEnCUCY4wJOUsExhgTcv8fRSQTOSMV76QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(train_y,pred_train_2)\n",
    "auc_score = roc_auc_score(train_y,pred_train_2)\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC curve/AUC Score : {auc_score}')\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.782129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.068811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.035137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.004835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.062852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18045</th>\n",
       "      <td>18045</td>\n",
       "      <td>0.009490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18046</th>\n",
       "      <td>18046</td>\n",
       "      <td>0.008622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18047</th>\n",
       "      <td>18047</td>\n",
       "      <td>0.089630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18048</th>\n",
       "      <td>18048</td>\n",
       "      <td>0.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18049</th>\n",
       "      <td>18049</td>\n",
       "      <td>0.099129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18050 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         y\n",
       "0          0  0.782129\n",
       "1          1  0.068811\n",
       "2          2  0.035137\n",
       "3          3  0.004835\n",
       "4          4  0.062852\n",
       "...      ...       ...\n",
       "18045  18045  0.009490\n",
       "18046  18046  0.008622\n",
       "18047  18047  0.089630\n",
       "18048  18048  0.012400\n",
       "18049  18049  0.099129\n",
       "\n",
       "[18050 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\test.csv')\n",
    "id = test['id']\n",
    "pred = pd.DataFrame(pred_test_2)\n",
    "submit = pd.concat([id,pred], axis=1)\n",
    "submit.columns = ['id', 'y']\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('stack6.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python37164bit745322e800af484d9e7663a15d4e0767"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
