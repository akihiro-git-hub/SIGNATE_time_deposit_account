{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso,Ridge\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers.advanced_activations import ReLU, PReLU\n",
    "from keras.optimizers import SGD, Adam\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\dataset\\\\train_x_xgboost.csv')\n",
    "train_y = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\dataset\\\\train_y_xgboost.csv')\n",
    "test_x = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\dataset\\\\test_x_xgboost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_nn = pd.read_csv('.//dataset//train_x_NN.csv')\n",
    "train_y_nn = pd.read_csv('.//dataset//train_y_NN.csv')\n",
    "test_x_nn = pd.read_csv('.//dataset//test_x_NN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Model1xgb,Model1xgb2, Model1NNproba,Model1NN2proba,Model1ramdom,Model2KMeans,Model2KNN,Model3logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv_classfier(model,train_x, train_y, test_x):\n",
    "    \n",
    "\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state= 71)\n",
    "    for i , (tr_idx, va_idx) in enumerate (kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "\n",
    "    tmp = np.stack(preds_test, axis =1)\n",
    "    mode_test, mode_counts = mode(tmp, axis=1)\n",
    "\n",
    "    preds_test = mode_test\n",
    "    preds_size = preds_test.shape[0]\n",
    "    preds_test = preds_test.reshape(preds_size,)\n",
    "    \n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv(model, train_x, train_y, test_x):\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "    \n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "    for i , (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "        \n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "    \n",
    "    preds_test = np.mean(preds_test, axis=0)\n",
    "    \n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:275: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:275: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:275: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:275: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:15:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06799\teval-error:0.07055\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06824\teval-error:0.07041\n",
      "[2]\ttrain-error:0.06760\teval-error:0.07070\n",
      "[3]\ttrain-error:0.06819\teval-error:0.07026\n",
      "[4]\ttrain-error:0.06716\teval-error:0.07011\n",
      "[5]\ttrain-error:0.06770\teval-error:0.06922\n",
      "[6]\ttrain-error:0.06731\teval-error:0.06937\n",
      "[7]\ttrain-error:0.06750\teval-error:0.06937\n",
      "[8]\ttrain-error:0.06741\teval-error:0.06967\n",
      "[9]\ttrain-error:0.06735\teval-error:0.06922\n",
      "[10]\ttrain-error:0.06701\teval-error:0.06864\n",
      "[11]\ttrain-error:0.06691\teval-error:0.06834\n",
      "[12]\ttrain-error:0.06677\teval-error:0.06804\n",
      "[13]\ttrain-error:0.06701\teval-error:0.06760\n",
      "[14]\ttrain-error:0.06696\teval-error:0.06731\n",
      "[15]\ttrain-error:0.06701\teval-error:0.06686\n",
      "[16]\ttrain-error:0.06657\teval-error:0.06672\n",
      "[17]\ttrain-error:0.06686\teval-error:0.06701\n",
      "[18]\ttrain-error:0.06677\teval-error:0.06657\n",
      "[19]\ttrain-error:0.06662\teval-error:0.06716\n",
      "[20]\ttrain-error:0.06657\teval-error:0.06657\n",
      "[21]\ttrain-error:0.06657\teval-error:0.06657\n",
      "[22]\ttrain-error:0.06637\teval-error:0.06642\n",
      "[23]\ttrain-error:0.06657\teval-error:0.06642\n",
      "[24]\ttrain-error:0.06632\teval-error:0.06657\n",
      "[25]\ttrain-error:0.06608\teval-error:0.06672\n",
      "[26]\ttrain-error:0.06613\teval-error:0.06686\n",
      "[27]\ttrain-error:0.06603\teval-error:0.06731\n",
      "[28]\ttrain-error:0.06583\teval-error:0.06701\n",
      "[29]\ttrain-error:0.06568\teval-error:0.06716\n",
      "[30]\ttrain-error:0.06573\teval-error:0.06672\n",
      "[31]\ttrain-error:0.06544\teval-error:0.06627\n",
      "[32]\ttrain-error:0.06534\teval-error:0.06598\n",
      "[33]\ttrain-error:0.06524\teval-error:0.06627\n",
      "[34]\ttrain-error:0.06504\teval-error:0.06627\n",
      "[35]\ttrain-error:0.06509\teval-error:0.06583\n",
      "[36]\ttrain-error:0.06475\teval-error:0.06598\n",
      "[37]\ttrain-error:0.06460\teval-error:0.06598\n",
      "[38]\ttrain-error:0.06455\teval-error:0.06539\n",
      "[39]\ttrain-error:0.06445\teval-error:0.06524\n",
      "[40]\ttrain-error:0.06426\teval-error:0.06524\n",
      "[41]\ttrain-error:0.06401\teval-error:0.06539\n",
      "[42]\ttrain-error:0.06386\teval-error:0.06509\n",
      "[43]\ttrain-error:0.06357\teval-error:0.06539\n",
      "[44]\ttrain-error:0.06312\teval-error:0.06524\n",
      "[45]\ttrain-error:0.06298\teval-error:0.06553\n",
      "[46]\ttrain-error:0.06308\teval-error:0.06568\n",
      "[47]\ttrain-error:0.06288\teval-error:0.06568\n",
      "[48]\ttrain-error:0.06273\teval-error:0.06568\n",
      "[49]\ttrain-error:0.06278\teval-error:0.06568\n",
      "[50]\ttrain-error:0.06258\teval-error:0.06568\n",
      "[51]\ttrain-error:0.06234\teval-error:0.06583\n",
      "[52]\ttrain-error:0.06180\teval-error:0.06568\n",
      "[53]\ttrain-error:0.06170\teval-error:0.06553\n",
      "[54]\ttrain-error:0.06150\teval-error:0.06568\n",
      "[55]\ttrain-error:0.06130\teval-error:0.06583\n",
      "[56]\ttrain-error:0.06125\teval-error:0.06539\n",
      "[57]\ttrain-error:0.06125\teval-error:0.06524\n",
      "[58]\ttrain-error:0.06135\teval-error:0.06524\n",
      "[59]\ttrain-error:0.06145\teval-error:0.06539\n",
      "[60]\ttrain-error:0.06091\teval-error:0.06495\n",
      "[61]\ttrain-error:0.06066\teval-error:0.06524\n",
      "[62]\ttrain-error:0.06052\teval-error:0.06524\n",
      "[63]\ttrain-error:0.06047\teval-error:0.06553\n",
      "[64]\ttrain-error:0.06052\teval-error:0.06568\n",
      "[65]\ttrain-error:0.06042\teval-error:0.06583\n",
      "[66]\ttrain-error:0.06022\teval-error:0.06539\n",
      "[67]\ttrain-error:0.06003\teval-error:0.06495\n",
      "[68]\ttrain-error:0.05988\teval-error:0.06509\n",
      "[69]\ttrain-error:0.06012\teval-error:0.06480\n",
      "[70]\ttrain-error:0.05998\teval-error:0.06509\n",
      "[71]\ttrain-error:0.05988\teval-error:0.06539\n",
      "[72]\ttrain-error:0.05963\teval-error:0.06539\n",
      "[73]\ttrain-error:0.05953\teval-error:0.06509\n",
      "[74]\ttrain-error:0.05924\teval-error:0.06524\n",
      "[75]\ttrain-error:0.05914\teval-error:0.06524\n",
      "[76]\ttrain-error:0.05914\teval-error:0.06539\n",
      "[77]\ttrain-error:0.05889\teval-error:0.06539\n",
      "[78]\ttrain-error:0.05880\teval-error:0.06539\n",
      "[79]\ttrain-error:0.05874\teval-error:0.06539\n",
      "[80]\ttrain-error:0.05840\teval-error:0.06583\n",
      "[81]\ttrain-error:0.05811\teval-error:0.06553\n",
      "[82]\ttrain-error:0.05806\teval-error:0.06553\n",
      "[83]\ttrain-error:0.05796\teval-error:0.06553\n",
      "[84]\ttrain-error:0.05781\teval-error:0.06568\n",
      "[85]\ttrain-error:0.05776\teval-error:0.06568\n",
      "[86]\ttrain-error:0.05761\teval-error:0.06568\n",
      "[87]\ttrain-error:0.05766\teval-error:0.06539\n",
      "[88]\ttrain-error:0.05737\teval-error:0.06553\n",
      "[89]\ttrain-error:0.05727\teval-error:0.06553\n",
      "Stopping. Best iteration:\n",
      "[69]\ttrain-error:0.06012\teval-error:0.06480\n",
      "\n",
      "[14:15:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06780\teval-error:0.07188\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06790\teval-error:0.07173\n",
      "[2]\ttrain-error:0.06785\teval-error:0.07114\n",
      "[3]\ttrain-error:0.06780\teval-error:0.07129\n",
      "[4]\ttrain-error:0.06775\teval-error:0.07114\n",
      "[5]\ttrain-error:0.06770\teval-error:0.07129\n",
      "[6]\ttrain-error:0.06750\teval-error:0.07070\n",
      "[7]\ttrain-error:0.06741\teval-error:0.07129\n",
      "[8]\ttrain-error:0.06735\teval-error:0.07114\n",
      "[9]\ttrain-error:0.06716\teval-error:0.07085\n",
      "[10]\ttrain-error:0.06691\teval-error:0.07114\n",
      "[11]\ttrain-error:0.06677\teval-error:0.07041\n",
      "[12]\ttrain-error:0.06647\teval-error:0.06982\n",
      "[13]\ttrain-error:0.06642\teval-error:0.06996\n",
      "[14]\ttrain-error:0.06617\teval-error:0.06996\n",
      "[15]\ttrain-error:0.06608\teval-error:0.06908\n",
      "[16]\ttrain-error:0.06627\teval-error:0.06922\n",
      "[17]\ttrain-error:0.06622\teval-error:0.06922\n",
      "[18]\ttrain-error:0.06603\teval-error:0.06922\n",
      "[19]\ttrain-error:0.06578\teval-error:0.06922\n",
      "[20]\ttrain-error:0.06598\teval-error:0.06952\n",
      "[21]\ttrain-error:0.06603\teval-error:0.06982\n",
      "[22]\ttrain-error:0.06593\teval-error:0.06967\n",
      "[23]\ttrain-error:0.06593\teval-error:0.06937\n",
      "[24]\ttrain-error:0.06583\teval-error:0.06952\n",
      "[25]\ttrain-error:0.06553\teval-error:0.06952\n",
      "[26]\ttrain-error:0.06568\teval-error:0.06952\n",
      "[27]\ttrain-error:0.06563\teval-error:0.06952\n",
      "[28]\ttrain-error:0.06544\teval-error:0.06967\n",
      "[29]\ttrain-error:0.06544\teval-error:0.06952\n",
      "[30]\ttrain-error:0.06544\teval-error:0.06952\n",
      "[31]\ttrain-error:0.06499\teval-error:0.06967\n",
      "[32]\ttrain-error:0.06480\teval-error:0.06982\n",
      "[33]\ttrain-error:0.06455\teval-error:0.06937\n",
      "[34]\ttrain-error:0.06470\teval-error:0.06937\n",
      "[35]\ttrain-error:0.06460\teval-error:0.06937\n",
      "Stopping. Best iteration:\n",
      "[15]\ttrain-error:0.06608\teval-error:0.06908\n",
      "\n",
      "[14:15:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06775\teval-error:0.07262\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06741\teval-error:0.07306\n",
      "[2]\ttrain-error:0.06745\teval-error:0.07306\n",
      "[3]\ttrain-error:0.06745\teval-error:0.07262\n",
      "[4]\ttrain-error:0.06735\teval-error:0.07203\n",
      "[5]\ttrain-error:0.06735\teval-error:0.07173\n",
      "[6]\ttrain-error:0.06711\teval-error:0.07188\n",
      "[7]\ttrain-error:0.06711\teval-error:0.07173\n",
      "[8]\ttrain-error:0.06711\teval-error:0.07129\n",
      "[9]\ttrain-error:0.06696\teval-error:0.07085\n",
      "[10]\ttrain-error:0.06667\teval-error:0.07085\n",
      "[11]\ttrain-error:0.06652\teval-error:0.07055\n",
      "[12]\ttrain-error:0.06657\teval-error:0.07085\n",
      "[13]\ttrain-error:0.06632\teval-error:0.07085\n",
      "[14]\ttrain-error:0.06627\teval-error:0.07085\n",
      "[15]\ttrain-error:0.06642\teval-error:0.07129\n",
      "[16]\ttrain-error:0.06647\teval-error:0.07114\n",
      "[17]\ttrain-error:0.06622\teval-error:0.07085\n",
      "[18]\ttrain-error:0.06622\teval-error:0.07114\n",
      "[19]\ttrain-error:0.06642\teval-error:0.07114\n",
      "[20]\ttrain-error:0.06642\teval-error:0.07100\n",
      "[21]\ttrain-error:0.06632\teval-error:0.07100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\ttrain-error:0.06622\teval-error:0.07100\n",
      "[23]\ttrain-error:0.06622\teval-error:0.07100\n",
      "[24]\ttrain-error:0.06632\teval-error:0.07055\n",
      "[25]\ttrain-error:0.06637\teval-error:0.07041\n",
      "[26]\ttrain-error:0.06627\teval-error:0.07070\n",
      "[27]\ttrain-error:0.06617\teval-error:0.07026\n",
      "[28]\ttrain-error:0.06632\teval-error:0.07055\n",
      "[29]\ttrain-error:0.06608\teval-error:0.07070\n",
      "[30]\ttrain-error:0.06593\teval-error:0.07055\n",
      "[31]\ttrain-error:0.06568\teval-error:0.07041\n",
      "[32]\ttrain-error:0.06553\teval-error:0.07085\n",
      "[33]\ttrain-error:0.06534\teval-error:0.07070\n",
      "[34]\ttrain-error:0.06519\teval-error:0.07026\n",
      "[35]\ttrain-error:0.06495\teval-error:0.07070\n",
      "[36]\ttrain-error:0.06499\teval-error:0.07100\n",
      "[37]\ttrain-error:0.06485\teval-error:0.07070\n",
      "[38]\ttrain-error:0.06460\teval-error:0.07085\n",
      "[39]\ttrain-error:0.06431\teval-error:0.07070\n",
      "[40]\ttrain-error:0.06406\teval-error:0.07100\n",
      "[41]\ttrain-error:0.06391\teval-error:0.07100\n",
      "[42]\ttrain-error:0.06376\teval-error:0.07085\n",
      "[43]\ttrain-error:0.06376\teval-error:0.07085\n",
      "[44]\ttrain-error:0.06342\teval-error:0.07041\n",
      "[45]\ttrain-error:0.06332\teval-error:0.07055\n",
      "[46]\ttrain-error:0.06327\teval-error:0.07055\n",
      "[47]\ttrain-error:0.06298\teval-error:0.07041\n",
      "Stopping. Best iteration:\n",
      "[27]\ttrain-error:0.06617\teval-error:0.07026\n",
      "\n",
      "[14:15:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06686\teval-error:0.07572\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06677\teval-error:0.07542\n",
      "[2]\ttrain-error:0.06642\teval-error:0.07439\n",
      "[3]\ttrain-error:0.06627\teval-error:0.07410\n",
      "[4]\ttrain-error:0.06667\teval-error:0.07439\n",
      "[5]\ttrain-error:0.06627\teval-error:0.07454\n",
      "[6]\ttrain-error:0.06642\teval-error:0.07498\n",
      "[7]\ttrain-error:0.06598\teval-error:0.07454\n",
      "[8]\ttrain-error:0.06608\teval-error:0.07454\n",
      "[9]\ttrain-error:0.06578\teval-error:0.07410\n",
      "[10]\ttrain-error:0.06539\teval-error:0.07424\n",
      "[11]\ttrain-error:0.06549\teval-error:0.07469\n",
      "[12]\ttrain-error:0.06544\teval-error:0.07454\n",
      "[13]\ttrain-error:0.06553\teval-error:0.07424\n",
      "[14]\ttrain-error:0.06558\teval-error:0.07410\n",
      "[15]\ttrain-error:0.06534\teval-error:0.07439\n",
      "[16]\ttrain-error:0.06509\teval-error:0.07424\n",
      "[17]\ttrain-error:0.06475\teval-error:0.07424\n",
      "[18]\ttrain-error:0.06480\teval-error:0.07439\n",
      "[19]\ttrain-error:0.06480\teval-error:0.07439\n",
      "[20]\ttrain-error:0.06480\teval-error:0.07439\n",
      "[21]\ttrain-error:0.06470\teval-error:0.07410\n",
      "[22]\ttrain-error:0.06450\teval-error:0.07380\n",
      "[23]\ttrain-error:0.06440\teval-error:0.07395\n",
      "[24]\ttrain-error:0.06435\teval-error:0.07410\n",
      "[25]\ttrain-error:0.06401\teval-error:0.07380\n",
      "[26]\ttrain-error:0.06416\teval-error:0.07424\n",
      "[27]\ttrain-error:0.06411\teval-error:0.07454\n",
      "[28]\ttrain-error:0.06396\teval-error:0.07424\n",
      "[29]\ttrain-error:0.06362\teval-error:0.07424\n",
      "[30]\ttrain-error:0.06366\teval-error:0.07454\n",
      "[31]\ttrain-error:0.06337\teval-error:0.07380\n",
      "[32]\ttrain-error:0.06322\teval-error:0.07380\n",
      "[33]\ttrain-error:0.06308\teval-error:0.07365\n",
      "[34]\ttrain-error:0.06312\teval-error:0.07336\n",
      "[35]\ttrain-error:0.06312\teval-error:0.07336\n",
      "[36]\ttrain-error:0.06308\teval-error:0.07321\n",
      "[37]\ttrain-error:0.06303\teval-error:0.07336\n",
      "[38]\ttrain-error:0.06278\teval-error:0.07306\n",
      "[39]\ttrain-error:0.06229\teval-error:0.07336\n",
      "[40]\ttrain-error:0.06229\teval-error:0.07336\n",
      "[41]\ttrain-error:0.06209\teval-error:0.07351\n",
      "[42]\ttrain-error:0.06189\teval-error:0.07321\n",
      "[43]\ttrain-error:0.06150\teval-error:0.07336\n",
      "[44]\ttrain-error:0.06125\teval-error:0.07306\n",
      "[45]\ttrain-error:0.06111\teval-error:0.07306\n",
      "[46]\ttrain-error:0.06125\teval-error:0.07321\n",
      "[47]\ttrain-error:0.06111\teval-error:0.07336\n",
      "[48]\ttrain-error:0.06086\teval-error:0.07380\n",
      "[49]\ttrain-error:0.06076\teval-error:0.07351\n",
      "[50]\ttrain-error:0.06066\teval-error:0.07306\n",
      "[51]\ttrain-error:0.06052\teval-error:0.07291\n",
      "[52]\ttrain-error:0.06042\teval-error:0.07277\n",
      "[53]\ttrain-error:0.06042\teval-error:0.07321\n",
      "[54]\ttrain-error:0.06032\teval-error:0.07306\n",
      "[55]\ttrain-error:0.05988\teval-error:0.07306\n",
      "[56]\ttrain-error:0.05988\teval-error:0.07321\n",
      "[57]\ttrain-error:0.05988\teval-error:0.07321\n",
      "[58]\ttrain-error:0.05968\teval-error:0.07306\n",
      "[59]\ttrain-error:0.05958\teval-error:0.07306\n",
      "[60]\ttrain-error:0.05943\teval-error:0.07306\n",
      "[61]\ttrain-error:0.05904\teval-error:0.07291\n",
      "[62]\ttrain-error:0.05899\teval-error:0.07277\n",
      "[63]\ttrain-error:0.05889\teval-error:0.07262\n",
      "[64]\ttrain-error:0.05870\teval-error:0.07262\n",
      "[65]\ttrain-error:0.05820\teval-error:0.07247\n",
      "[66]\ttrain-error:0.05825\teval-error:0.07247\n",
      "[67]\ttrain-error:0.05815\teval-error:0.07262\n",
      "[68]\ttrain-error:0.05815\teval-error:0.07247\n",
      "[69]\ttrain-error:0.05786\teval-error:0.07233\n",
      "[70]\ttrain-error:0.05756\teval-error:0.07218\n",
      "[71]\ttrain-error:0.05751\teval-error:0.07233\n",
      "[72]\ttrain-error:0.05756\teval-error:0.07218\n",
      "[73]\ttrain-error:0.05737\teval-error:0.07203\n",
      "[74]\ttrain-error:0.05737\teval-error:0.07203\n",
      "[75]\ttrain-error:0.05717\teval-error:0.07188\n",
      "[76]\ttrain-error:0.05717\teval-error:0.07188\n",
      "[77]\ttrain-error:0.05678\teval-error:0.07218\n",
      "[78]\ttrain-error:0.05658\teval-error:0.07218\n",
      "[79]\ttrain-error:0.05653\teval-error:0.07218\n",
      "[80]\ttrain-error:0.05648\teval-error:0.07218\n",
      "[81]\ttrain-error:0.05599\teval-error:0.07233\n",
      "[82]\ttrain-error:0.05584\teval-error:0.07233\n",
      "[83]\ttrain-error:0.05579\teval-error:0.07247\n",
      "[84]\ttrain-error:0.05570\teval-error:0.07262\n",
      "[85]\ttrain-error:0.05560\teval-error:0.07247\n",
      "[86]\ttrain-error:0.05555\teval-error:0.07247\n",
      "[87]\ttrain-error:0.05530\teval-error:0.07203\n",
      "[88]\ttrain-error:0.05535\teval-error:0.07233\n",
      "[89]\ttrain-error:0.05525\teval-error:0.07218\n",
      "[90]\ttrain-error:0.05520\teval-error:0.07203\n",
      "[91]\ttrain-error:0.05530\teval-error:0.07218\n",
      "[92]\ttrain-error:0.05515\teval-error:0.07233\n",
      "[93]\ttrain-error:0.05505\teval-error:0.07188\n",
      "[94]\ttrain-error:0.05501\teval-error:0.07188\n",
      "[95]\ttrain-error:0.05505\teval-error:0.07188\n",
      "Stopping. Best iteration:\n",
      "[75]\ttrain-error:0.05717\teval-error:0.07188\n",
      "\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2424 - accuracy: 0.9231 - val_loss: 0.2087 - val_accuracy: 0.9330\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2154 - accuracy: 0.9295 - val_loss: 0.2082 - val_accuracy: 0.9343\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2101 - accuracy: 0.9302 - val_loss: 0.2076 - val_accuracy: 0.9342\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9312 - val_loss: 0.2086 - val_accuracy: 0.9355\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9308 - val_loss: 0.2077 - val_accuracy: 0.9351\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2012 - accuracy: 0.9324 - val_loss: 0.2090 - val_accuracy: 0.9348\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2003 - accuracy: 0.9327 - val_loss: 0.2064 - val_accuracy: 0.9337\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1980 - accuracy: 0.9340 - val_loss: 0.2083 - val_accuracy: 0.9342\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1966 - accuracy: 0.9339 - val_loss: 0.2094 - val_accuracy: 0.9324\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1933 - accuracy: 0.9339 - val_loss: 0.2094 - val_accuracy: 0.9343\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1930 - accuracy: 0.9347 - val_loss: 0.2119 - val_accuracy: 0.9333\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1888 - accuracy: 0.9355 - val_loss: 0.2112 - val_accuracy: 0.9334\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1867 - accuracy: 0.9361 - val_loss: 0.2141 - val_accuracy: 0.9318\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1838 - accuracy: 0.9371 - val_loss: 0.2170 - val_accuracy: 0.9320\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1809 - accuracy: 0.9379 - val_loss: 0.2119 - val_accuracy: 0.9334\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1784 - accuracy: 0.9380 - val_loss: 0.2152 - val_accuracy: 0.9343\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1772 - accuracy: 0.9382 - val_loss: 0.2172 - val_accuracy: 0.9324\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1740 - accuracy: 0.9391 - val_loss: 0.2202 - val_accuracy: 0.9321\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1717 - accuracy: 0.9394 - val_loss: 0.2238 - val_accuracy: 0.9314\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.1674 - accuracy: 0.9405 - val_loss: 0.2240 - val_accuracy: 0.9317\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1660 - accuracy: 0.9421 - val_loss: 0.2251 - val_accuracy: 0.9305\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1621 - accuracy: 0.9428 - val_loss: 0.2277 - val_accuracy: 0.9305\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1636 - accuracy: 0.9429 - val_loss: 0.2237 - val_accuracy: 0.9314\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1575 - accuracy: 0.9451 - val_loss: 0.2341 - val_accuracy: 0.9309\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1541 - accuracy: 0.9446 - val_loss: 0.2293 - val_accuracy: 0.9300\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1532 - accuracy: 0.9470 - val_loss: 0.2329 - val_accuracy: 0.9323\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1488 - accuracy: 0.9466 - val_loss: 0.2321 - val_accuracy: 0.9286\n",
      "WARNING:tensorflow:From C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:122: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2469 - accuracy: 0.9217 - val_loss: 0.2186 - val_accuracy: 0.9293\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2114 - accuracy: 0.9312 - val_loss: 0.2149 - val_accuracy: 0.9309\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9314 - val_loss: 0.2160 - val_accuracy: 0.9302\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9318 - val_loss: 0.2144 - val_accuracy: 0.9299\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2019 - accuracy: 0.9329 - val_loss: 0.2171 - val_accuracy: 0.9296\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1999 - accuracy: 0.9331 - val_loss: 0.2152 - val_accuracy: 0.9294\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1983 - accuracy: 0.9336 - val_loss: 0.2179 - val_accuracy: 0.9297\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1957 - accuracy: 0.9343 - val_loss: 0.2166 - val_accuracy: 0.9286\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1941 - accuracy: 0.9343 - val_loss: 0.2220 - val_accuracy: 0.9292\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1935 - accuracy: 0.9347 - val_loss: 0.2227 - val_accuracy: 0.9293\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1903 - accuracy: 0.9362 - val_loss: 0.2218 - val_accuracy: 0.9280\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1885 - accuracy: 0.9362 - val_loss: 0.2203 - val_accuracy: 0.9278\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1837 - accuracy: 0.9359 - val_loss: 0.2238 - val_accuracy: 0.9286\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9371 - val_loss: 0.2289 - val_accuracy: 0.9271\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1814 - accuracy: 0.9383 - val_loss: 0.2280 - val_accuracy: 0.9268\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1782 - accuracy: 0.9380 - val_loss: 0.2265 - val_accuracy: 0.9268\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1762 - accuracy: 0.9397 - val_loss: 0.2262 - val_accuracy: 0.9266\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1734 - accuracy: 0.9393 - val_loss: 0.2285 - val_accuracy: 0.9269\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1697 - accuracy: 0.9410 - val_loss: 0.2303 - val_accuracy: 0.9261\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1668 - accuracy: 0.9410 - val_loss: 0.2334 - val_accuracy: 0.9263\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1645 - accuracy: 0.9432 - val_loss: 0.2338 - val_accuracy: 0.9269\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1616 - accuracy: 0.9432 - val_loss: 0.2369 - val_accuracy: 0.9243\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1585 - accuracy: 0.9440 - val_loss: 0.2374 - val_accuracy: 0.9240\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1556 - accuracy: 0.9450 - val_loss: 0.2442 - val_accuracy: 0.9235\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2396 - accuracy: 0.9247 - val_loss: 0.2161 - val_accuracy: 0.9315\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2134 - accuracy: 0.9303 - val_loss: 0.2176 - val_accuracy: 0.9305\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9316 - val_loss: 0.2146 - val_accuracy: 0.9306\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9324 - val_loss: 0.2176 - val_accuracy: 0.9302\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2020 - accuracy: 0.9329 - val_loss: 0.2154 - val_accuracy: 0.9306\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2007 - accuracy: 0.9325 - val_loss: 0.2190 - val_accuracy: 0.9309\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1968 - accuracy: 0.9335 - val_loss: 0.2190 - val_accuracy: 0.9305\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1959 - accuracy: 0.9331 - val_loss: 0.2188 - val_accuracy: 0.9317\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1933 - accuracy: 0.9344 - val_loss: 0.2226 - val_accuracy: 0.9311\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1915 - accuracy: 0.9347 - val_loss: 0.2197 - val_accuracy: 0.9296\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1890 - accuracy: 0.9364 - val_loss: 0.2222 - val_accuracy: 0.9311\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1856 - accuracy: 0.9358 - val_loss: 0.2233 - val_accuracy: 0.9289\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1854 - accuracy: 0.9375 - val_loss: 0.2266 - val_accuracy: 0.9297\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1835 - accuracy: 0.9374 - val_loss: 0.2230 - val_accuracy: 0.9297\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1805 - accuracy: 0.9377 - val_loss: 0.2258 - val_accuracy: 0.9289\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1770 - accuracy: 0.9401 - val_loss: 0.2318 - val_accuracy: 0.9296\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1735 - accuracy: 0.9399 - val_loss: 0.2295 - val_accuracy: 0.9305\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1725 - accuracy: 0.9410 - val_loss: 0.2372 - val_accuracy: 0.9289\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1697 - accuracy: 0.9398 - val_loss: 0.2390 - val_accuracy: 0.9275\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1679 - accuracy: 0.9425 - val_loss: 0.2366 - val_accuracy: 0.9269\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1650 - accuracy: 0.9412 - val_loss: 0.2399 - val_accuracy: 0.9293\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1624 - accuracy: 0.9432 - val_loss: 0.2390 - val_accuracy: 0.9302\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1591 - accuracy: 0.9445 - val_loss: 0.2379 - val_accuracy: 0.9271\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2347 - accuracy: 0.9274 - val_loss: 0.2148 - val_accuracy: 0.9271\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2116 - accuracy: 0.9309 - val_loss: 0.2145 - val_accuracy: 0.9281\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9318 - val_loss: 0.2169 - val_accuracy: 0.9277\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9333 - val_loss: 0.2160 - val_accuracy: 0.9272\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2007 - accuracy: 0.9352 - val_loss: 0.2178 - val_accuracy: 0.9278\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1996 - accuracy: 0.9335 - val_loss: 0.2176 - val_accuracy: 0.9268\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1966 - accuracy: 0.9345 - val_loss: 0.2187 - val_accuracy: 0.9272\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1950 - accuracy: 0.9359 - val_loss: 0.2214 - val_accuracy: 0.9266\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1922 - accuracy: 0.9358 - val_loss: 0.2182 - val_accuracy: 0.9283\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1930 - accuracy: 0.9362 - val_loss: 0.2194 - val_accuracy: 0.9281\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1881 - accuracy: 0.9374 - val_loss: 0.2245 - val_accuracy: 0.9249\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1879 - accuracy: 0.9374 - val_loss: 0.2229 - val_accuracy: 0.9252\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1830 - accuracy: 0.9377 - val_loss: 0.2265 - val_accuracy: 0.9250\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1806 - accuracy: 0.9393 - val_loss: 0.2275 - val_accuracy: 0.9252\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1789 - accuracy: 0.9388 - val_loss: 0.2271 - val_accuracy: 0.9253\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1760 - accuracy: 0.9399 - val_loss: 0.2306 - val_accuracy: 0.9234\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1739 - accuracy: 0.9411 - val_loss: 0.2332 - val_accuracy: 0.9253\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1722 - accuracy: 0.9414 - val_loss: 0.2339 - val_accuracy: 0.9234\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1694 - accuracy: 0.9423 - val_loss: 0.2368 - val_accuracy: 0.9244\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1650 - accuracy: 0.9436 - val_loss: 0.2394 - val_accuracy: 0.9241\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1622 - accuracy: 0.9431 - val_loss: 0.2413 - val_accuracy: 0.9238\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1628 - accuracy: 0.9450 - val_loss: 0.2434 - val_accuracy: 0.9241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:178: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:178: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:178: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:178: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:16:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06922\teval-error:0.07100\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06888\teval-error:0.06967\n",
      "[2]\ttrain-error:0.06962\teval-error:0.06819\n",
      "[3]\ttrain-error:0.06898\teval-error:0.06745\n",
      "[4]\ttrain-error:0.06809\teval-error:0.06686\n",
      "[5]\ttrain-error:0.06927\teval-error:0.06613\n",
      "[6]\ttrain-error:0.06903\teval-error:0.06598\n",
      "[7]\ttrain-error:0.06844\teval-error:0.06613\n",
      "[8]\ttrain-error:0.06819\teval-error:0.06627\n",
      "[9]\ttrain-error:0.06775\teval-error:0.06583\n",
      "[10]\ttrain-error:0.06775\teval-error:0.06583\n",
      "[11]\ttrain-error:0.06741\teval-error:0.06598\n",
      "[12]\ttrain-error:0.06741\teval-error:0.06598\n",
      "[13]\ttrain-error:0.06755\teval-error:0.06553\n",
      "[14]\ttrain-error:0.06750\teval-error:0.06568\n",
      "[15]\ttrain-error:0.06731\teval-error:0.06583\n",
      "[16]\ttrain-error:0.06711\teval-error:0.06553\n",
      "[17]\ttrain-error:0.06706\teval-error:0.06568\n",
      "[18]\ttrain-error:0.06686\teval-error:0.06583\n",
      "[19]\ttrain-error:0.06657\teval-error:0.06583\n",
      "[20]\ttrain-error:0.06672\teval-error:0.06613\n",
      "[21]\ttrain-error:0.06686\teval-error:0.06613\n",
      "[22]\ttrain-error:0.06686\teval-error:0.06598\n",
      "[23]\ttrain-error:0.06701\teval-error:0.06568\n",
      "[24]\ttrain-error:0.06677\teval-error:0.06568\n",
      "[25]\ttrain-error:0.06706\teval-error:0.06583\n",
      "[26]\ttrain-error:0.06667\teval-error:0.06568\n",
      "[27]\ttrain-error:0.06642\teval-error:0.06568\n",
      "[28]\ttrain-error:0.06662\teval-error:0.06553\n",
      "[29]\ttrain-error:0.06657\teval-error:0.06568\n",
      "[30]\ttrain-error:0.06608\teval-error:0.06568\n",
      "[31]\ttrain-error:0.06617\teval-error:0.06539\n",
      "[32]\ttrain-error:0.06608\teval-error:0.06553\n",
      "[33]\ttrain-error:0.06598\teval-error:0.06568\n",
      "[34]\ttrain-error:0.06603\teval-error:0.06553\n",
      "[35]\ttrain-error:0.06583\teval-error:0.06539\n",
      "[36]\ttrain-error:0.06568\teval-error:0.06524\n",
      "[37]\ttrain-error:0.06553\teval-error:0.06524\n",
      "[38]\ttrain-error:0.06539\teval-error:0.06539\n",
      "[39]\ttrain-error:0.06480\teval-error:0.06553\n",
      "[40]\ttrain-error:0.06470\teval-error:0.06539\n",
      "[41]\ttrain-error:0.06455\teval-error:0.06553\n",
      "[42]\ttrain-error:0.06421\teval-error:0.06539\n",
      "[43]\ttrain-error:0.06426\teval-error:0.06553\n",
      "[44]\ttrain-error:0.06416\teval-error:0.06568\n",
      "[45]\ttrain-error:0.06426\teval-error:0.06583\n",
      "[46]\ttrain-error:0.06406\teval-error:0.06568\n",
      "[47]\ttrain-error:0.06352\teval-error:0.06553\n",
      "[48]\ttrain-error:0.06327\teval-error:0.06568\n",
      "[49]\ttrain-error:0.06308\teval-error:0.06553\n",
      "[50]\ttrain-error:0.06288\teval-error:0.06553\n",
      "[51]\ttrain-error:0.06258\teval-error:0.06598\n",
      "[52]\ttrain-error:0.06239\teval-error:0.06568\n",
      "[53]\ttrain-error:0.06243\teval-error:0.06568\n",
      "[54]\ttrain-error:0.06234\teval-error:0.06539\n",
      "[55]\ttrain-error:0.06219\teval-error:0.06539\n",
      "[56]\ttrain-error:0.06234\teval-error:0.06539\n",
      "Stopping. Best iteration:\n",
      "[36]\ttrain-error:0.06568\teval-error:0.06524\n",
      "\n",
      "[14:16:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06937\teval-error:0.07100\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06888\teval-error:0.07011\n",
      "[2]\ttrain-error:0.06952\teval-error:0.07085\n",
      "[3]\ttrain-error:0.06893\teval-error:0.07100\n",
      "[4]\ttrain-error:0.06878\teval-error:0.07114\n",
      "[5]\ttrain-error:0.06908\teval-error:0.07114\n",
      "[6]\ttrain-error:0.06858\teval-error:0.07041\n",
      "[7]\ttrain-error:0.06829\teval-error:0.07070\n",
      "[8]\ttrain-error:0.06814\teval-error:0.07026\n",
      "[9]\ttrain-error:0.06760\teval-error:0.07011\n",
      "[10]\ttrain-error:0.06790\teval-error:0.07026\n",
      "[11]\ttrain-error:0.06780\teval-error:0.06982\n",
      "[12]\ttrain-error:0.06750\teval-error:0.06967\n",
      "[13]\ttrain-error:0.06745\teval-error:0.06996\n",
      "[14]\ttrain-error:0.06741\teval-error:0.06952\n",
      "[15]\ttrain-error:0.06706\teval-error:0.06952\n",
      "[16]\ttrain-error:0.06716\teval-error:0.06952\n",
      "[17]\ttrain-error:0.06677\teval-error:0.06922\n",
      "[18]\ttrain-error:0.06652\teval-error:0.06908\n",
      "[19]\ttrain-error:0.06667\teval-error:0.06893\n",
      "[20]\ttrain-error:0.06677\teval-error:0.06908\n",
      "[21]\ttrain-error:0.06681\teval-error:0.06908\n",
      "[22]\ttrain-error:0.06677\teval-error:0.06922\n",
      "[23]\ttrain-error:0.06657\teval-error:0.06893\n",
      "[24]\ttrain-error:0.06647\teval-error:0.06893\n",
      "[25]\ttrain-error:0.06622\teval-error:0.06908\n",
      "[26]\ttrain-error:0.06608\teval-error:0.06908\n",
      "[27]\ttrain-error:0.06617\teval-error:0.06893\n",
      "[28]\ttrain-error:0.06598\teval-error:0.06849\n",
      "[29]\ttrain-error:0.06603\teval-error:0.06864\n",
      "[30]\ttrain-error:0.06583\teval-error:0.06893\n",
      "[31]\ttrain-error:0.06534\teval-error:0.06878\n",
      "[32]\ttrain-error:0.06529\teval-error:0.06864\n",
      "[33]\ttrain-error:0.06529\teval-error:0.06878\n",
      "[34]\ttrain-error:0.06519\teval-error:0.06819\n",
      "[35]\ttrain-error:0.06489\teval-error:0.06893\n",
      "[36]\ttrain-error:0.06495\teval-error:0.06893\n",
      "[37]\ttrain-error:0.06460\teval-error:0.06834\n",
      "[38]\ttrain-error:0.06440\teval-error:0.06849\n",
      "[39]\ttrain-error:0.06440\teval-error:0.06790\n",
      "[40]\ttrain-error:0.06440\teval-error:0.06804\n",
      "[41]\ttrain-error:0.06431\teval-error:0.06819\n",
      "[42]\ttrain-error:0.06416\teval-error:0.06804\n",
      "[43]\ttrain-error:0.06381\teval-error:0.06790\n",
      "[44]\ttrain-error:0.06362\teval-error:0.06804\n",
      "[45]\ttrain-error:0.06317\teval-error:0.06834\n",
      "[46]\ttrain-error:0.06303\teval-error:0.06819\n",
      "[47]\ttrain-error:0.06288\teval-error:0.06849\n",
      "[48]\ttrain-error:0.06268\teval-error:0.06849\n",
      "[49]\ttrain-error:0.06253\teval-error:0.06804\n",
      "[50]\ttrain-error:0.06199\teval-error:0.06849\n",
      "[51]\ttrain-error:0.06189\teval-error:0.06790\n",
      "[52]\ttrain-error:0.06145\teval-error:0.06849\n",
      "[53]\ttrain-error:0.06121\teval-error:0.06878\n",
      "[54]\ttrain-error:0.06121\teval-error:0.06849\n",
      "[55]\ttrain-error:0.06111\teval-error:0.06922\n",
      "[56]\ttrain-error:0.06106\teval-error:0.06922\n",
      "[57]\ttrain-error:0.06091\teval-error:0.06908\n",
      "[58]\ttrain-error:0.06096\teval-error:0.06864\n",
      "[59]\ttrain-error:0.06081\teval-error:0.06878\n",
      "Stopping. Best iteration:\n",
      "[39]\ttrain-error:0.06440\teval-error:0.06790\n",
      "\n",
      "[14:16:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06873\teval-error:0.06996\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06893\teval-error:0.07114\n",
      "[2]\ttrain-error:0.06893\teval-error:0.07085\n",
      "[3]\ttrain-error:0.06873\teval-error:0.07026\n",
      "[4]\ttrain-error:0.06839\teval-error:0.07085\n",
      "[5]\ttrain-error:0.06873\teval-error:0.07011\n",
      "[6]\ttrain-error:0.06799\teval-error:0.06982\n",
      "[7]\ttrain-error:0.06795\teval-error:0.06982\n",
      "[8]\ttrain-error:0.06775\teval-error:0.07026\n",
      "[9]\ttrain-error:0.06790\teval-error:0.06967\n",
      "[10]\ttrain-error:0.06790\teval-error:0.06952\n",
      "[11]\ttrain-error:0.06770\teval-error:0.06937\n",
      "[12]\ttrain-error:0.06750\teval-error:0.06967\n",
      "[13]\ttrain-error:0.06741\teval-error:0.06937\n",
      "[14]\ttrain-error:0.06755\teval-error:0.06922\n",
      "[15]\ttrain-error:0.06745\teval-error:0.06937\n",
      "[16]\ttrain-error:0.06775\teval-error:0.06893\n",
      "[17]\ttrain-error:0.06735\teval-error:0.06922\n",
      "[18]\ttrain-error:0.06735\teval-error:0.06922\n",
      "[19]\ttrain-error:0.06731\teval-error:0.06922\n",
      "[20]\ttrain-error:0.06706\teval-error:0.06908\n",
      "[21]\ttrain-error:0.06686\teval-error:0.06908\n",
      "[22]\ttrain-error:0.06677\teval-error:0.06908\n",
      "[23]\ttrain-error:0.06662\teval-error:0.06908\n",
      "[24]\ttrain-error:0.06622\teval-error:0.06922\n",
      "[25]\ttrain-error:0.06642\teval-error:0.06922\n",
      "[26]\ttrain-error:0.06613\teval-error:0.06922\n",
      "[27]\ttrain-error:0.06578\teval-error:0.06982\n",
      "[28]\ttrain-error:0.06598\teval-error:0.06967\n",
      "[29]\ttrain-error:0.06583\teval-error:0.06982\n",
      "[30]\ttrain-error:0.06573\teval-error:0.06967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\ttrain-error:0.06549\teval-error:0.06952\n",
      "[32]\ttrain-error:0.06514\teval-error:0.06952\n",
      "[33]\ttrain-error:0.06489\teval-error:0.06922\n",
      "[34]\ttrain-error:0.06504\teval-error:0.06922\n",
      "[35]\ttrain-error:0.06499\teval-error:0.06878\n",
      "[36]\ttrain-error:0.06489\teval-error:0.06878\n",
      "[37]\ttrain-error:0.06470\teval-error:0.06849\n",
      "[38]\ttrain-error:0.06470\teval-error:0.06878\n",
      "[39]\ttrain-error:0.06480\teval-error:0.06864\n",
      "[40]\ttrain-error:0.06460\teval-error:0.06893\n",
      "[41]\ttrain-error:0.06406\teval-error:0.06893\n",
      "[42]\ttrain-error:0.06386\teval-error:0.06893\n",
      "[43]\ttrain-error:0.06357\teval-error:0.06922\n",
      "[44]\ttrain-error:0.06347\teval-error:0.06908\n",
      "[45]\ttrain-error:0.06347\teval-error:0.06893\n",
      "[46]\ttrain-error:0.06327\teval-error:0.06864\n",
      "[47]\ttrain-error:0.06322\teval-error:0.06893\n",
      "[48]\ttrain-error:0.06283\teval-error:0.06878\n",
      "[49]\ttrain-error:0.06268\teval-error:0.06864\n",
      "[50]\ttrain-error:0.06253\teval-error:0.06849\n",
      "[51]\ttrain-error:0.06224\teval-error:0.06864\n",
      "[52]\ttrain-error:0.06219\teval-error:0.06834\n",
      "[53]\ttrain-error:0.06219\teval-error:0.06819\n",
      "[54]\ttrain-error:0.06209\teval-error:0.06849\n",
      "[55]\ttrain-error:0.06189\teval-error:0.06819\n",
      "[56]\ttrain-error:0.06175\teval-error:0.06819\n",
      "[57]\ttrain-error:0.06150\teval-error:0.06834\n",
      "[58]\ttrain-error:0.06145\teval-error:0.06878\n",
      "[59]\ttrain-error:0.06125\teval-error:0.06878\n",
      "[60]\ttrain-error:0.06086\teval-error:0.06878\n",
      "[61]\ttrain-error:0.06096\teval-error:0.06893\n",
      "[62]\ttrain-error:0.06081\teval-error:0.06908\n",
      "[63]\ttrain-error:0.06062\teval-error:0.06922\n",
      "[64]\ttrain-error:0.06037\teval-error:0.06908\n",
      "[65]\ttrain-error:0.06032\teval-error:0.06893\n",
      "[66]\ttrain-error:0.06022\teval-error:0.06864\n",
      "[67]\ttrain-error:0.05993\teval-error:0.06878\n",
      "[68]\ttrain-error:0.05973\teval-error:0.06849\n",
      "[69]\ttrain-error:0.05993\teval-error:0.06819\n",
      "[70]\ttrain-error:0.05988\teval-error:0.06834\n",
      "[71]\ttrain-error:0.05973\teval-error:0.06804\n",
      "[72]\ttrain-error:0.05934\teval-error:0.06804\n",
      "[73]\ttrain-error:0.05934\teval-error:0.06790\n",
      "[74]\ttrain-error:0.05914\teval-error:0.06804\n",
      "[75]\ttrain-error:0.05929\teval-error:0.06790\n",
      "[76]\ttrain-error:0.05909\teval-error:0.06849\n",
      "[77]\ttrain-error:0.05889\teval-error:0.06849\n",
      "[78]\ttrain-error:0.05870\teval-error:0.06849\n",
      "[79]\ttrain-error:0.05860\teval-error:0.06804\n",
      "[80]\ttrain-error:0.05870\teval-error:0.06849\n",
      "[81]\ttrain-error:0.05884\teval-error:0.06849\n",
      "[82]\ttrain-error:0.05880\teval-error:0.06834\n",
      "[83]\ttrain-error:0.05860\teval-error:0.06864\n",
      "[84]\ttrain-error:0.05830\teval-error:0.06878\n",
      "[85]\ttrain-error:0.05825\teval-error:0.06849\n",
      "[86]\ttrain-error:0.05771\teval-error:0.06878\n",
      "[87]\ttrain-error:0.05766\teval-error:0.06878\n",
      "[88]\ttrain-error:0.05751\teval-error:0.06878\n",
      "[89]\ttrain-error:0.05742\teval-error:0.06937\n",
      "[90]\ttrain-error:0.05742\teval-error:0.06922\n",
      "[91]\ttrain-error:0.05707\teval-error:0.06908\n",
      "[92]\ttrain-error:0.05717\teval-error:0.06893\n",
      "[93]\ttrain-error:0.05707\teval-error:0.06893\n",
      "Stopping. Best iteration:\n",
      "[73]\ttrain-error:0.05934\teval-error:0.06790\n",
      "\n",
      "[14:16:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06854\teval-error:0.07351\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06780\teval-error:0.07321\n",
      "[2]\ttrain-error:0.06814\teval-error:0.07336\n",
      "[3]\ttrain-error:0.06765\teval-error:0.07410\n",
      "[4]\ttrain-error:0.06780\teval-error:0.07424\n",
      "[5]\ttrain-error:0.06839\teval-error:0.07498\n",
      "[6]\ttrain-error:0.06770\teval-error:0.07454\n",
      "[7]\ttrain-error:0.06731\teval-error:0.07439\n",
      "[8]\ttrain-error:0.06701\teval-error:0.07483\n",
      "[9]\ttrain-error:0.06735\teval-error:0.07454\n",
      "[10]\ttrain-error:0.06735\teval-error:0.07424\n",
      "[11]\ttrain-error:0.06706\teval-error:0.07380\n",
      "[12]\ttrain-error:0.06662\teval-error:0.07380\n",
      "[13]\ttrain-error:0.06652\teval-error:0.07380\n",
      "[14]\ttrain-error:0.06652\teval-error:0.07380\n",
      "[15]\ttrain-error:0.06627\teval-error:0.07454\n",
      "[16]\ttrain-error:0.06632\teval-error:0.07424\n",
      "[17]\ttrain-error:0.06617\teval-error:0.07439\n",
      "[18]\ttrain-error:0.06608\teval-error:0.07454\n",
      "[19]\ttrain-error:0.06588\teval-error:0.07424\n",
      "[20]\ttrain-error:0.06568\teval-error:0.07424\n",
      "[21]\ttrain-error:0.06573\teval-error:0.07439\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.06780\teval-error:0.07321\n",
      "\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.3782 - accuracy: 0.8728 - val_loss: 0.2768 - val_accuracy: 0.9256\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2780 - accuracy: 0.9209 - val_loss: 0.2485 - val_accuracy: 0.9256\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2547 - accuracy: 0.9213 - val_loss: 0.2327 - val_accuracy: 0.9271\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2425 - accuracy: 0.9232 - val_loss: 0.2253 - val_accuracy: 0.9323\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2342 - accuracy: 0.9250 - val_loss: 0.2212 - val_accuracy: 0.9325\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2302 - accuracy: 0.9272 - val_loss: 0.2184 - val_accuracy: 0.9327\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2290 - accuracy: 0.9271 - val_loss: 0.2170 - val_accuracy: 0.9325\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2253 - accuracy: 0.9275 - val_loss: 0.2155 - val_accuracy: 0.9328\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2254 - accuracy: 0.9276 - val_loss: 0.2146 - val_accuracy: 0.9323\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2243 - accuracy: 0.9277 - val_loss: 0.2139 - val_accuracy: 0.9325\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2229 - accuracy: 0.9283 - val_loss: 0.2134 - val_accuracy: 0.9324\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2227 - accuracy: 0.9284 - val_loss: 0.2129 - val_accuracy: 0.9328\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2211 - accuracy: 0.9282 - val_loss: 0.2125 - val_accuracy: 0.9324\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2217 - accuracy: 0.9282 - val_loss: 0.2124 - val_accuracy: 0.9323\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2190 - accuracy: 0.9294 - val_loss: 0.2117 - val_accuracy: 0.9330\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2201 - accuracy: 0.9283 - val_loss: 0.2116 - val_accuracy: 0.9330\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2199 - accuracy: 0.9284 - val_loss: 0.2114 - val_accuracy: 0.9327\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2196 - accuracy: 0.9287 - val_loss: 0.2110 - val_accuracy: 0.9330\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2193 - accuracy: 0.9283 - val_loss: 0.2108 - val_accuracy: 0.9325\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2185 - accuracy: 0.9276 - val_loss: 0.2106 - val_accuracy: 0.9330\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2187 - accuracy: 0.9282 - val_loss: 0.2107 - val_accuracy: 0.9331\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2176 - accuracy: 0.9286 - val_loss: 0.2106 - val_accuracy: 0.9331\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2179 - accuracy: 0.9288 - val_loss: 0.2105 - val_accuracy: 0.9330\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2167 - accuracy: 0.9295 - val_loss: 0.2101 - val_accuracy: 0.9327\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2171 - accuracy: 0.9284 - val_loss: 0.2101 - val_accuracy: 0.9327\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2160 - accuracy: 0.9299 - val_loss: 0.2097 - val_accuracy: 0.9330\n",
      "Epoch 27/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2172 - accuracy: 0.9283 - val_loss: 0.2096 - val_accuracy: 0.9331\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2155 - accuracy: 0.9299 - val_loss: 0.2097 - val_accuracy: 0.9328\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2166 - accuracy: 0.9289 - val_loss: 0.2094 - val_accuracy: 0.9328\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2166 - accuracy: 0.9292 - val_loss: 0.2093 - val_accuracy: 0.9328\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2148 - accuracy: 0.9294 - val_loss: 0.2090 - val_accuracy: 0.9331\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2147 - accuracy: 0.9297 - val_loss: 0.2091 - val_accuracy: 0.9333\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2149 - accuracy: 0.9284 - val_loss: 0.2091 - val_accuracy: 0.9331\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2142 - accuracy: 0.9281 - val_loss: 0.2087 - val_accuracy: 0.9331\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2148 - accuracy: 0.9289 - val_loss: 0.2090 - val_accuracy: 0.9333\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2148 - accuracy: 0.9281 - val_loss: 0.2086 - val_accuracy: 0.9331\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2135 - accuracy: 0.9291 - val_loss: 0.2085 - val_accuracy: 0.9330\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2128 - accuracy: 0.9295 - val_loss: 0.2083 - val_accuracy: 0.9333\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2144 - accuracy: 0.9294 - val_loss: 0.2085 - val_accuracy: 0.9328\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2139 - accuracy: 0.9291 - val_loss: 0.2084 - val_accuracy: 0.9330\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2133 - accuracy: 0.9300 - val_loss: 0.2082 - val_accuracy: 0.9331\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2128 - accuracy: 0.9295 - val_loss: 0.2081 - val_accuracy: 0.9331\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2119 - accuracy: 0.9292 - val_loss: 0.2079 - val_accuracy: 0.9336\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2112 - accuracy: 0.9294 - val_loss: 0.2080 - val_accuracy: 0.9330\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2121 - accuracy: 0.9302 - val_loss: 0.2079 - val_accuracy: 0.9336\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2113 - accuracy: 0.9303 - val_loss: 0.2078 - val_accuracy: 0.9333\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2143 - accuracy: 0.9289 - val_loss: 0.2077 - val_accuracy: 0.9334\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2128 - accuracy: 0.9299 - val_loss: 0.2076 - val_accuracy: 0.9334\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2129 - accuracy: 0.9292 - val_loss: 0.2077 - val_accuracy: 0.9337\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2127 - accuracy: 0.9289 - val_loss: 0.2078 - val_accuracy: 0.9334\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2114 - accuracy: 0.9296 - val_loss: 0.2076 - val_accuracy: 0.9340\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2109 - accuracy: 0.9305 - val_loss: 0.2075 - val_accuracy: 0.9340\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2111 - accuracy: 0.9293 - val_loss: 0.2077 - val_accuracy: 0.9342\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2116 - accuracy: 0.9297 - val_loss: 0.2075 - val_accuracy: 0.9339\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2105 - accuracy: 0.9293 - val_loss: 0.2077 - val_accuracy: 0.9342\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2099 - accuracy: 0.9301 - val_loss: 0.2076 - val_accuracy: 0.9343\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2112 - accuracy: 0.9293 - val_loss: 0.2075 - val_accuracy: 0.9342\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2091 - accuracy: 0.9307 - val_loss: 0.2075 - val_accuracy: 0.9345\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9301 - val_loss: 0.2073 - val_accuracy: 0.9339\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9294 - val_loss: 0.2072 - val_accuracy: 0.9343\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2091 - accuracy: 0.9293 - val_loss: 0.2071 - val_accuracy: 0.9340\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2098 - accuracy: 0.9306 - val_loss: 0.2070 - val_accuracy: 0.9340\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2094 - accuracy: 0.9294 - val_loss: 0.2070 - val_accuracy: 0.9343\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2104 - accuracy: 0.9304 - val_loss: 0.2070 - val_accuracy: 0.9342\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2101 - accuracy: 0.9302 - val_loss: 0.2069 - val_accuracy: 0.9345\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2090 - accuracy: 0.9296 - val_loss: 0.2072 - val_accuracy: 0.9340\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2099 - accuracy: 0.9302 - val_loss: 0.2068 - val_accuracy: 0.9342\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2087 - accuracy: 0.9305 - val_loss: 0.2067 - val_accuracy: 0.9342\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2099 - accuracy: 0.9297 - val_loss: 0.2067 - val_accuracy: 0.9340\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9305 - val_loss: 0.2068 - val_accuracy: 0.9342\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2093 - accuracy: 0.9301 - val_loss: 0.2068 - val_accuracy: 0.9342\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9309 - val_loss: 0.2070 - val_accuracy: 0.9340\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9295 - val_loss: 0.2068 - val_accuracy: 0.9340\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9298 - val_loss: 0.2066 - val_accuracy: 0.9339\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2076 - accuracy: 0.9302 - val_loss: 0.2067 - val_accuracy: 0.9342\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2077 - accuracy: 0.9313 - val_loss: 0.2067 - val_accuracy: 0.9342\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2076 - accuracy: 0.9318 - val_loss: 0.2067 - val_accuracy: 0.9342\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2067 - accuracy: 0.9305 - val_loss: 0.2065 - val_accuracy: 0.9342\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9299 - val_loss: 0.2066 - val_accuracy: 0.9345\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9304 - val_loss: 0.2065 - val_accuracy: 0.9339\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2074 - accuracy: 0.9301 - val_loss: 0.2065 - val_accuracy: 0.9337\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2091 - accuracy: 0.9303 - val_loss: 0.2066 - val_accuracy: 0.9337\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2077 - accuracy: 0.9309 - val_loss: 0.2067 - val_accuracy: 0.9340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2076 - accuracy: 0.9296 - val_loss: 0.2066 - val_accuracy: 0.9339\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2061 - accuracy: 0.9311 - val_loss: 0.2068 - val_accuracy: 0.9340\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9301 - val_loss: 0.2068 - val_accuracy: 0.9339\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9300 - val_loss: 0.2067 - val_accuracy: 0.9339\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9304 - val_loss: 0.2070 - val_accuracy: 0.9340\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9297 - val_loss: 0.2067 - val_accuracy: 0.9340\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9301 - val_loss: 0.2067 - val_accuracy: 0.9337\n",
      "Epoch 91/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9294 - val_loss: 0.2068 - val_accuracy: 0.9339\n",
      "Epoch 92/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9309 - val_loss: 0.2067 - val_accuracy: 0.9343\n",
      "Epoch 93/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9308 - val_loss: 0.2065 - val_accuracy: 0.9343\n",
      "Epoch 94/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9308 - val_loss: 0.2066 - val_accuracy: 0.9340\n",
      "Epoch 95/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2062 - accuracy: 0.9302 - val_loss: 0.2064 - val_accuracy: 0.9339\n",
      "Epoch 96/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9304 - val_loss: 0.2063 - val_accuracy: 0.9339\n",
      "Epoch 97/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9308 - val_loss: 0.2064 - val_accuracy: 0.9340\n",
      "Epoch 98/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9299 - val_loss: 0.2065 - val_accuracy: 0.9337\n",
      "Epoch 99/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9304 - val_loss: 0.2065 - val_accuracy: 0.9337\n",
      "Epoch 100/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9313 - val_loss: 0.2065 - val_accuracy: 0.9340\n",
      "Epoch 101/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9305 - val_loss: 0.2065 - val_accuracy: 0.9340\n",
      "Epoch 102/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9306 - val_loss: 0.2066 - val_accuracy: 0.9340\n",
      "Epoch 103/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9310 - val_loss: 0.2066 - val_accuracy: 0.9342\n",
      "Epoch 104/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9306 - val_loss: 0.2065 - val_accuracy: 0.9342\n",
      "Epoch 105/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9316 - val_loss: 0.2065 - val_accuracy: 0.9343\n",
      "Epoch 106/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9311 - val_loss: 0.2067 - val_accuracy: 0.9340\n",
      "Epoch 107/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9314 - val_loss: 0.2067 - val_accuracy: 0.9340\n",
      "Epoch 108/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9311 - val_loss: 0.2067 - val_accuracy: 0.9339\n",
      "Epoch 109/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2034 - accuracy: 0.9305 - val_loss: 0.2067 - val_accuracy: 0.9340\n",
      "Epoch 110/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9309 - val_loss: 0.2067 - val_accuracy: 0.9339\n",
      "Epoch 111/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2041 - accuracy: 0.9313 - val_loss: 0.2068 - val_accuracy: 0.9340\n",
      "Epoch 112/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9312 - val_loss: 0.2066 - val_accuracy: 0.9340\n",
      "Epoch 113/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9312 - val_loss: 0.2066 - val_accuracy: 0.9340\n",
      "Epoch 114/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9303 - val_loss: 0.2067 - val_accuracy: 0.9342\n",
      "Epoch 115/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9320 - val_loss: 0.2065 - val_accuracy: 0.9345\n",
      "Epoch 116/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9304 - val_loss: 0.2065 - val_accuracy: 0.9340\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3550 - accuracy: 0.9160 - val_loss: 0.2912 - val_accuracy: 0.9221\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2797 - accuracy: 0.9221 - val_loss: 0.2563 - val_accuracy: 0.9221\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2539 - accuracy: 0.9228 - val_loss: 0.2384 - val_accuracy: 0.9240\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2409 - accuracy: 0.9256 - val_loss: 0.2288 - val_accuracy: 0.9271\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2344 - accuracy: 0.9264 - val_loss: 0.2244 - val_accuracy: 0.9278\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2300 - accuracy: 0.9279 - val_loss: 0.2219 - val_accuracy: 0.9283\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2283 - accuracy: 0.9278 - val_loss: 0.2202 - val_accuracy: 0.9289\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2272 - accuracy: 0.9282 - val_loss: 0.2192 - val_accuracy: 0.9287\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2254 - accuracy: 0.9277 - val_loss: 0.2184 - val_accuracy: 0.9289\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2237 - accuracy: 0.9291 - val_loss: 0.2181 - val_accuracy: 0.9284\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2241 - accuracy: 0.9289 - val_loss: 0.2177 - val_accuracy: 0.9284\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2223 - accuracy: 0.9283 - val_loss: 0.2172 - val_accuracy: 0.9289\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2214 - accuracy: 0.9293 - val_loss: 0.2171 - val_accuracy: 0.9287\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2205 - accuracy: 0.9289 - val_loss: 0.2168 - val_accuracy: 0.9287\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2209 - accuracy: 0.9297 - val_loss: 0.2168 - val_accuracy: 0.9286\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2192 - accuracy: 0.9291 - val_loss: 0.2166 - val_accuracy: 0.9286\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2205 - accuracy: 0.9292 - val_loss: 0.2164 - val_accuracy: 0.9287\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2211 - accuracy: 0.9293 - val_loss: 0.2163 - val_accuracy: 0.9289\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2179 - accuracy: 0.9294 - val_loss: 0.2161 - val_accuracy: 0.9289\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2195 - accuracy: 0.9290 - val_loss: 0.2159 - val_accuracy: 0.9289\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2181 - accuracy: 0.9298 - val_loss: 0.2157 - val_accuracy: 0.9289\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2164 - accuracy: 0.9283 - val_loss: 0.2156 - val_accuracy: 0.9286\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2164 - accuracy: 0.9297 - val_loss: 0.2155 - val_accuracy: 0.9289\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2163 - accuracy: 0.9299 - val_loss: 0.2157 - val_accuracy: 0.9289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2157 - accuracy: 0.9289 - val_loss: 0.2156 - val_accuracy: 0.9287\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2165 - accuracy: 0.9297 - val_loss: 0.2155 - val_accuracy: 0.9287\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2160 - accuracy: 0.9304 - val_loss: 0.2154 - val_accuracy: 0.9292\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2154 - accuracy: 0.9307 - val_loss: 0.2153 - val_accuracy: 0.9292\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2141 - accuracy: 0.9308 - val_loss: 0.2151 - val_accuracy: 0.9292\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2133 - accuracy: 0.9297 - val_loss: 0.2151 - val_accuracy: 0.9290\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2137 - accuracy: 0.9303 - val_loss: 0.2151 - val_accuracy: 0.9289\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2133 - accuracy: 0.9294 - val_loss: 0.2149 - val_accuracy: 0.9292\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2136 - accuracy: 0.9298 - val_loss: 0.2149 - val_accuracy: 0.9297\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2123 - accuracy: 0.9296 - val_loss: 0.2148 - val_accuracy: 0.9296\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2138 - accuracy: 0.9301 - val_loss: 0.2147 - val_accuracy: 0.9293\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2132 - accuracy: 0.9294 - val_loss: 0.2147 - val_accuracy: 0.9296\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2127 - accuracy: 0.9298 - val_loss: 0.2146 - val_accuracy: 0.9294\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2130 - accuracy: 0.9307 - val_loss: 0.2146 - val_accuracy: 0.9297\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2129 - accuracy: 0.9296 - val_loss: 0.2146 - val_accuracy: 0.9297\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2116 - accuracy: 0.9302 - val_loss: 0.2145 - val_accuracy: 0.9299\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2119 - accuracy: 0.9298 - val_loss: 0.2144 - val_accuracy: 0.9299\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2121 - accuracy: 0.9306 - val_loss: 0.2143 - val_accuracy: 0.9300\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2122 - accuracy: 0.9294 - val_loss: 0.2143 - val_accuracy: 0.9302\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9309 - val_loss: 0.2143 - val_accuracy: 0.9300\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9313 - val_loss: 0.2143 - val_accuracy: 0.9299\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2103 - accuracy: 0.9311 - val_loss: 0.2143 - val_accuracy: 0.9300\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9308 - val_loss: 0.2143 - val_accuracy: 0.9302\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2109 - accuracy: 0.9300 - val_loss: 0.2143 - val_accuracy: 0.9303\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2106 - accuracy: 0.9307 - val_loss: 0.2142 - val_accuracy: 0.9305\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2100 - accuracy: 0.9312 - val_loss: 0.2143 - val_accuracy: 0.9305\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2090 - accuracy: 0.9306 - val_loss: 0.2142 - val_accuracy: 0.9305\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9307 - val_loss: 0.2144 - val_accuracy: 0.9305\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9305 - val_loss: 0.2143 - val_accuracy: 0.9305\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9308 - val_loss: 0.2141 - val_accuracy: 0.9305\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9301 - val_loss: 0.2142 - val_accuracy: 0.9303\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9309 - val_loss: 0.2142 - val_accuracy: 0.9305\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9307 - val_loss: 0.2142 - val_accuracy: 0.9305\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9310 - val_loss: 0.2141 - val_accuracy: 0.9305\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2074 - accuracy: 0.9312 - val_loss: 0.2143 - val_accuracy: 0.9303\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9309 - val_loss: 0.2143 - val_accuracy: 0.9306\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9314 - val_loss: 0.2141 - val_accuracy: 0.9306\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9315 - val_loss: 0.2142 - val_accuracy: 0.9305\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9312 - val_loss: 0.2141 - val_accuracy: 0.9306\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9307 - val_loss: 0.2141 - val_accuracy: 0.9308\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9309 - val_loss: 0.2141 - val_accuracy: 0.9303\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9303 - val_loss: 0.2140 - val_accuracy: 0.9306\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9314 - val_loss: 0.2141 - val_accuracy: 0.9305\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9303 - val_loss: 0.2141 - val_accuracy: 0.9306\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9308 - val_loss: 0.2141 - val_accuracy: 0.9311\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9306 - val_loss: 0.2140 - val_accuracy: 0.9305\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9306 - val_loss: 0.2141 - val_accuracy: 0.9314\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9318 - val_loss: 0.2140 - val_accuracy: 0.9312\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9319 - val_loss: 0.2140 - val_accuracy: 0.9306\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9308 - val_loss: 0.2141 - val_accuracy: 0.9312\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9309 - val_loss: 0.2141 - val_accuracy: 0.9308\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2066 - accuracy: 0.9312 - val_loss: 0.2142 - val_accuracy: 0.9314\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9313 - val_loss: 0.2141 - val_accuracy: 0.9311\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9320 - val_loss: 0.2141 - val_accuracy: 0.9314\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9313 - val_loss: 0.2140 - val_accuracy: 0.9314\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9311 - val_loss: 0.2140 - val_accuracy: 0.9309\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9313 - val_loss: 0.2141 - val_accuracy: 0.9309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9319 - val_loss: 0.2141 - val_accuracy: 0.9311\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9316 - val_loss: 0.2140 - val_accuracy: 0.9311\n",
      "Epoch 84/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9323 - val_loss: 0.2141 - val_accuracy: 0.9311\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9309 - val_loss: 0.2140 - val_accuracy: 0.9309\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9323 - val_loss: 0.2141 - val_accuracy: 0.9309\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9326 - val_loss: 0.2142 - val_accuracy: 0.9309\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9316 - val_loss: 0.2142 - val_accuracy: 0.9306\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9312 - val_loss: 0.2143 - val_accuracy: 0.9306\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2033 - accuracy: 0.9305 - val_loss: 0.2143 - val_accuracy: 0.9305\n",
      "Epoch 91/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2033 - accuracy: 0.9320 - val_loss: 0.2144 - val_accuracy: 0.9305\n",
      "Epoch 92/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9316 - val_loss: 0.2146 - val_accuracy: 0.9306\n",
      "Epoch 93/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9310 - val_loss: 0.2144 - val_accuracy: 0.9303\n",
      "Epoch 94/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2036 - accuracy: 0.9323 - val_loss: 0.2144 - val_accuracy: 0.9305\n",
      "Epoch 95/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9321 - val_loss: 0.2144 - val_accuracy: 0.9305\n",
      "Epoch 96/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9320 - val_loss: 0.2144 - val_accuracy: 0.9309\n",
      "Epoch 97/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9317 - val_loss: 0.2144 - val_accuracy: 0.9306\n",
      "Epoch 98/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2030 - accuracy: 0.9319 - val_loss: 0.2145 - val_accuracy: 0.9309\n",
      "Epoch 99/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9317 - val_loss: 0.2144 - val_accuracy: 0.9311\n",
      "Epoch 100/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9313 - val_loss: 0.2145 - val_accuracy: 0.9308\n",
      "Epoch 101/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2031 - accuracy: 0.9309 - val_loss: 0.2144 - val_accuracy: 0.9309\n",
      "Epoch 102/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9310 - val_loss: 0.2145 - val_accuracy: 0.9309\n",
      "Epoch 103/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2019 - accuracy: 0.9313 - val_loss: 0.2144 - val_accuracy: 0.9308\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3384 - accuracy: 0.9206 - val_loss: 0.2904 - val_accuracy: 0.9221\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2774 - accuracy: 0.9221 - val_loss: 0.2581 - val_accuracy: 0.9221\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2535 - accuracy: 0.9222 - val_loss: 0.2400 - val_accuracy: 0.9249\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2416 - accuracy: 0.9249 - val_loss: 0.2303 - val_accuracy: 0.9286\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2344 - accuracy: 0.9263 - val_loss: 0.2246 - val_accuracy: 0.9289\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2295 - accuracy: 0.9277 - val_loss: 0.2214 - val_accuracy: 0.9294\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2292 - accuracy: 0.9273 - val_loss: 0.2196 - val_accuracy: 0.9299\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2281 - accuracy: 0.9269 - val_loss: 0.2188 - val_accuracy: 0.9297\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2241 - accuracy: 0.9281 - val_loss: 0.2178 - val_accuracy: 0.9297\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2244 - accuracy: 0.9273 - val_loss: 0.2176 - val_accuracy: 0.9303\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2220 - accuracy: 0.9289 - val_loss: 0.2166 - val_accuracy: 0.9305\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2221 - accuracy: 0.9292 - val_loss: 0.2161 - val_accuracy: 0.9306\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2197 - accuracy: 0.9282 - val_loss: 0.2159 - val_accuracy: 0.9303\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2201 - accuracy: 0.9286 - val_loss: 0.2159 - val_accuracy: 0.9308\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2188 - accuracy: 0.9285 - val_loss: 0.2159 - val_accuracy: 0.9308\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2198 - accuracy: 0.9281 - val_loss: 0.2153 - val_accuracy: 0.9305\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2168 - accuracy: 0.9283 - val_loss: 0.2153 - val_accuracy: 0.9302\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2182 - accuracy: 0.9288 - val_loss: 0.2151 - val_accuracy: 0.9305\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2163 - accuracy: 0.9297 - val_loss: 0.2148 - val_accuracy: 0.9305\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2177 - accuracy: 0.9297 - val_loss: 0.2147 - val_accuracy: 0.9305\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2161 - accuracy: 0.9294 - val_loss: 0.2150 - val_accuracy: 0.9308\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2155 - accuracy: 0.9299 - val_loss: 0.2149 - val_accuracy: 0.9308\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2180 - accuracy: 0.9285 - val_loss: 0.2146 - val_accuracy: 0.9305\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2160 - accuracy: 0.9297 - val_loss: 0.2145 - val_accuracy: 0.9303\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2154 - accuracy: 0.9292 - val_loss: 0.2147 - val_accuracy: 0.9299\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2163 - accuracy: 0.9294 - val_loss: 0.2144 - val_accuracy: 0.9311\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2139 - accuracy: 0.9295 - val_loss: 0.2144 - val_accuracy: 0.9309\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2151 - accuracy: 0.9298 - val_loss: 0.2141 - val_accuracy: 0.9314\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2132 - accuracy: 0.9290 - val_loss: 0.2142 - val_accuracy: 0.9306\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2137 - accuracy: 0.9296 - val_loss: 0.2140 - val_accuracy: 0.9308\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2123 - accuracy: 0.9302 - val_loss: 0.2139 - val_accuracy: 0.9314\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2123 - accuracy: 0.9298 - val_loss: 0.2138 - val_accuracy: 0.9312\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2142 - accuracy: 0.9293 - val_loss: 0.2136 - val_accuracy: 0.9309\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.9301 - val_loss: 0.2137 - val_accuracy: 0.9311\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2123 - accuracy: 0.9303 - val_loss: 0.2138 - val_accuracy: 0.9311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2120 - accuracy: 0.9306 - val_loss: 0.2137 - val_accuracy: 0.9312\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2112 - accuracy: 0.9303 - val_loss: 0.2134 - val_accuracy: 0.9314\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2129 - accuracy: 0.9301 - val_loss: 0.2134 - val_accuracy: 0.9311\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9301 - val_loss: 0.2137 - val_accuracy: 0.9312\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2121 - accuracy: 0.9291 - val_loss: 0.2134 - val_accuracy: 0.9314\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2115 - accuracy: 0.9296 - val_loss: 0.2133 - val_accuracy: 0.9312\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9294 - val_loss: 0.2134 - val_accuracy: 0.9315\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2107 - accuracy: 0.9306 - val_loss: 0.2133 - val_accuracy: 0.9315\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2081 - accuracy: 0.9306 - val_loss: 0.2135 - val_accuracy: 0.9306\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9308 - val_loss: 0.2134 - val_accuracy: 0.9314\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9306 - val_loss: 0.2134 - val_accuracy: 0.9306\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9300 - val_loss: 0.2135 - val_accuracy: 0.9305\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2110 - accuracy: 0.9301 - val_loss: 0.2134 - val_accuracy: 0.9308\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9301 - val_loss: 0.2137 - val_accuracy: 0.9302\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9308 - val_loss: 0.2134 - val_accuracy: 0.9306\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9301 - val_loss: 0.2133 - val_accuracy: 0.9311\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9310 - val_loss: 0.2132 - val_accuracy: 0.9305\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9306 - val_loss: 0.2131 - val_accuracy: 0.9303\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9297 - val_loss: 0.2135 - val_accuracy: 0.9303\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9306 - val_loss: 0.2134 - val_accuracy: 0.9300\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9306 - val_loss: 0.2135 - val_accuracy: 0.9300\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9302 - val_loss: 0.2134 - val_accuracy: 0.9300\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2068 - accuracy: 0.9302 - val_loss: 0.2134 - val_accuracy: 0.9303\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9305 - val_loss: 0.2135 - val_accuracy: 0.9303\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9308 - val_loss: 0.2134 - val_accuracy: 0.9297\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9305 - val_loss: 0.2135 - val_accuracy: 0.9299\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9305 - val_loss: 0.2135 - val_accuracy: 0.9302\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9303 - val_loss: 0.2137 - val_accuracy: 0.9297\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2091 - accuracy: 0.9301 - val_loss: 0.2134 - val_accuracy: 0.9300\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9310 - val_loss: 0.2135 - val_accuracy: 0.9302\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9300 - val_loss: 0.2133 - val_accuracy: 0.9302\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9297 - val_loss: 0.2134 - val_accuracy: 0.9302\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2058 - accuracy: 0.9311 - val_loss: 0.2133 - val_accuracy: 0.9302\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9325 - val_loss: 0.2133 - val_accuracy: 0.9302\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2064 - accuracy: 0.9311 - val_loss: 0.2136 - val_accuracy: 0.9300\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9311 - val_loss: 0.2137 - val_accuracy: 0.9299\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9318 - val_loss: 0.2135 - val_accuracy: 0.9306\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9307 - val_loss: 0.2136 - val_accuracy: 0.9302\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3676 - accuracy: 0.8789 - val_loss: 0.2949 - val_accuracy: 0.9185\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2768 - accuracy: 0.9233 - val_loss: 0.2654 - val_accuracy: 0.9185\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2588 - accuracy: 0.9248 - val_loss: 0.2487 - val_accuracy: 0.9218\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2458 - accuracy: 0.9270 - val_loss: 0.2387 - val_accuracy: 0.9243\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2383 - accuracy: 0.9285 - val_loss: 0.2325 - val_accuracy: 0.9258\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2340 - accuracy: 0.9289 - val_loss: 0.2285 - val_accuracy: 0.9268\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2296 - accuracy: 0.9290 - val_loss: 0.2258 - val_accuracy: 0.9266\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2265 - accuracy: 0.9304 - val_loss: 0.2237 - val_accuracy: 0.9272\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2273 - accuracy: 0.9292 - val_loss: 0.2223 - val_accuracy: 0.9274\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2240 - accuracy: 0.9295 - val_loss: 0.2212 - val_accuracy: 0.9280\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2238 - accuracy: 0.9297 - val_loss: 0.2204 - val_accuracy: 0.9281\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2224 - accuracy: 0.9305 - val_loss: 0.2197 - val_accuracy: 0.9275\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2220 - accuracy: 0.9308 - val_loss: 0.2191 - val_accuracy: 0.9280\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2222 - accuracy: 0.9297 - val_loss: 0.2189 - val_accuracy: 0.9280\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2224 - accuracy: 0.9307 - val_loss: 0.2184 - val_accuracy: 0.9277\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2196 - accuracy: 0.9304 - val_loss: 0.2180 - val_accuracy: 0.9278\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2204 - accuracy: 0.9300 - val_loss: 0.2177 - val_accuracy: 0.9278\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2195 - accuracy: 0.9302 - val_loss: 0.2175 - val_accuracy: 0.9277\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2158 - accuracy: 0.9304 - val_loss: 0.2171 - val_accuracy: 0.9280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2180 - accuracy: 0.9303 - val_loss: 0.2168 - val_accuracy: 0.9280\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2168 - accuracy: 0.9306 - val_loss: 0.2167 - val_accuracy: 0.9280\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2169 - accuracy: 0.9302 - val_loss: 0.2164 - val_accuracy: 0.9280\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2188 - accuracy: 0.9300 - val_loss: 0.2163 - val_accuracy: 0.9280\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2153 - accuracy: 0.9299 - val_loss: 0.2162 - val_accuracy: 0.9280\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2165 - accuracy: 0.9299 - val_loss: 0.2160 - val_accuracy: 0.9278\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2157 - accuracy: 0.9304 - val_loss: 0.2160 - val_accuracy: 0.9280\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2158 - accuracy: 0.9304 - val_loss: 0.2157 - val_accuracy: 0.9281\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2159 - accuracy: 0.9300 - val_loss: 0.2157 - val_accuracy: 0.9277\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2151 - accuracy: 0.9306 - val_loss: 0.2156 - val_accuracy: 0.9281\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2147 - accuracy: 0.9307 - val_loss: 0.2156 - val_accuracy: 0.9274\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2136 - accuracy: 0.9314 - val_loss: 0.2154 - val_accuracy: 0.9281\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2131 - accuracy: 0.9314 - val_loss: 0.2153 - val_accuracy: 0.9278\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2134 - accuracy: 0.9319 - val_loss: 0.2153 - val_accuracy: 0.9277\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2114 - accuracy: 0.9321 - val_loss: 0.2151 - val_accuracy: 0.9277\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2136 - accuracy: 0.9318 - val_loss: 0.2151 - val_accuracy: 0.9278\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2134 - accuracy: 0.9317 - val_loss: 0.2149 - val_accuracy: 0.9281\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2129 - accuracy: 0.9313 - val_loss: 0.2149 - val_accuracy: 0.9271\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2133 - accuracy: 0.9306 - val_loss: 0.2149 - val_accuracy: 0.9272\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2125 - accuracy: 0.9315 - val_loss: 0.2148 - val_accuracy: 0.9278\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2114 - accuracy: 0.9318 - val_loss: 0.2147 - val_accuracy: 0.9271\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2120 - accuracy: 0.9313 - val_loss: 0.2145 - val_accuracy: 0.9275\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2114 - accuracy: 0.9316 - val_loss: 0.2145 - val_accuracy: 0.9272\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2124 - accuracy: 0.9314 - val_loss: 0.2145 - val_accuracy: 0.9274\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2116 - accuracy: 0.9313 - val_loss: 0.2145 - val_accuracy: 0.9274\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2126 - accuracy: 0.9312 - val_loss: 0.2144 - val_accuracy: 0.9272\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2107 - accuracy: 0.9323 - val_loss: 0.2144 - val_accuracy: 0.9277\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2108 - accuracy: 0.9311 - val_loss: 0.2144 - val_accuracy: 0.9275\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2092 - accuracy: 0.9315 - val_loss: 0.2144 - val_accuracy: 0.9274\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2111 - accuracy: 0.9319 - val_loss: 0.2143 - val_accuracy: 0.9275\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2121 - accuracy: 0.9312 - val_loss: 0.2144 - val_accuracy: 0.9274\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2117 - accuracy: 0.9317 - val_loss: 0.2143 - val_accuracy: 0.9272\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2101 - accuracy: 0.9317 - val_loss: 0.2142 - val_accuracy: 0.9272\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9323 - val_loss: 0.2142 - val_accuracy: 0.9274\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9316 - val_loss: 0.2141 - val_accuracy: 0.9272\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2113 - accuracy: 0.9312 - val_loss: 0.2141 - val_accuracy: 0.9275\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2101 - accuracy: 0.9312 - val_loss: 0.2141 - val_accuracy: 0.9278\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9311 - val_loss: 0.2142 - val_accuracy: 0.9278\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9317 - val_loss: 0.2140 - val_accuracy: 0.9275\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2071 - accuracy: 0.9327 - val_loss: 0.2140 - val_accuracy: 0.9274\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2090 - accuracy: 0.9317 - val_loss: 0.2140 - val_accuracy: 0.9272\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2079 - accuracy: 0.9320 - val_loss: 0.2140 - val_accuracy: 0.9272\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2096 - accuracy: 0.9321 - val_loss: 0.2140 - val_accuracy: 0.9272\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2100 - accuracy: 0.9319 - val_loss: 0.2140 - val_accuracy: 0.9272\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2083 - accuracy: 0.9319 - val_loss: 0.2139 - val_accuracy: 0.9268\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2090 - accuracy: 0.9314 - val_loss: 0.2140 - val_accuracy: 0.9268\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2072 - accuracy: 0.9316 - val_loss: 0.2139 - val_accuracy: 0.9272\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2080 - accuracy: 0.9317 - val_loss: 0.2138 - val_accuracy: 0.9272\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2080 - accuracy: 0.9318 - val_loss: 0.2137 - val_accuracy: 0.9269\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9317 - val_loss: 0.2138 - val_accuracy: 0.9271\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2076 - accuracy: 0.9317 - val_loss: 0.2139 - val_accuracy: 0.9268\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2080 - accuracy: 0.9319 - val_loss: 0.2139 - val_accuracy: 0.9272\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2087 - accuracy: 0.9318 - val_loss: 0.2139 - val_accuracy: 0.9268\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2072 - accuracy: 0.9314 - val_loss: 0.2139 - val_accuracy: 0.9271\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2059 - accuracy: 0.9323 - val_loss: 0.2140 - val_accuracy: 0.9271\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2087 - accuracy: 0.9324 - val_loss: 0.2140 - val_accuracy: 0.9272\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2064 - accuracy: 0.9328 - val_loss: 0.2140 - val_accuracy: 0.9268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9315 - val_loss: 0.2139 - val_accuracy: 0.9269\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2057 - accuracy: 0.9321 - val_loss: 0.2138 - val_accuracy: 0.9269\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9324 - val_loss: 0.2139 - val_accuracy: 0.9268\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2071 - accuracy: 0.9315 - val_loss: 0.2138 - val_accuracy: 0.9269\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9322 - val_loss: 0.2139 - val_accuracy: 0.9268\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9318 - val_loss: 0.2138 - val_accuracy: 0.9269\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9315 - val_loss: 0.2139 - val_accuracy: 0.9268\n",
      "Epoch 84/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9320 - val_loss: 0.2138 - val_accuracy: 0.9272\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9321 - val_loss: 0.2139 - val_accuracy: 0.9269\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9324 - val_loss: 0.2138 - val_accuracy: 0.9271\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9314 - val_loss: 0.2139 - val_accuracy: 0.9271\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9321 - val_loss: 0.2140 - val_accuracy: 0.9269\n"
     ]
    }
   ],
   "source": [
    "model1_a = Model2KNN()\n",
    "pred_train_1a , preds_test_1a = predict_cv_classfier(model1_a, train_x, train_y, test_x)\n",
    "\n",
    "model_1b = Model1xgb()\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_1b, train_x, train_y, test_x)\n",
    "\n",
    "model_1c = Model1NNproba()\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_1c, train_x_nn, train_y, test_x_nn)\n",
    "\n",
    "\n",
    "model_1d = Model1ramdom()\n",
    "pred_train_1d, pred_test_1d = predict_cv(model_1d, train_x, train_y, test_x)\n",
    "\n",
    "\n",
    "model_1e = Model1xgb2()\n",
    "pred_train_1e, pred_test_1e = predict_cv(model_1e, train_x, train_y, test_x)\n",
    "\n",
    "model_1f = Model1NN2proba()\n",
    "pred_train_1f, pred_test_1f = predict_cv(model_1f, train_x_nn, train_y, test_x_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.2561\n",
      "logloss: 0.2068\n",
      "logloss: 0.2125\n",
      "logloss: 0.2492\n",
      "logloss: 0.2129\n",
      "logloss: 0.2118\n"
     ]
    }
   ],
   "source": [
    "print(f'logloss: {log_loss(train_y, pred_train_1a, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1b, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1c, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1d, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1e, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1f, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_2 = pd.DataFrame({'pred_1a': pred_train_1a, 'pred_1b': pred_train_1b, 'pred_1c':pred_train_1c,'pred_1d':pred_train_1d, 'pred_1e':pred_train_1e, 'pred_1f': pred_train_1f})\n",
    "test_x_2 = pd.DataFrame({'pred_1a': preds_test_1a, 'pred_1b': pred_test_1b, 'pred_1c': pred_test_1c,'pred_1d':pred_test_1d, 'pred_1e':pred_test_1e, 'pred_1f': pred_test_1f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.2090\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model3logistic()\n",
    "pred_train_2, pred_test_2 = predict_cv(model_2, train_x_2, train_y, test_x_2)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(train_y,pred_train_2)\n",
    "auc_score = roc_auc_score(train_y,pred_train_2)\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC curve/AUC Score : {auc_score}')\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.797084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.062920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.035643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.002280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.060592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18045</th>\n",
       "      <td>18045</td>\n",
       "      <td>0.011949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18046</th>\n",
       "      <td>18046</td>\n",
       "      <td>0.005162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18047</th>\n",
       "      <td>18047</td>\n",
       "      <td>0.095813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18048</th>\n",
       "      <td>18048</td>\n",
       "      <td>0.013155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18049</th>\n",
       "      <td>18049</td>\n",
       "      <td>0.096498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18050 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         y\n",
       "0          0  0.797084\n",
       "1          1  0.062920\n",
       "2          2  0.035643\n",
       "3          3  0.002280\n",
       "4          4  0.060592\n",
       "...      ...       ...\n",
       "18045  18045  0.011949\n",
       "18046  18046  0.005162\n",
       "18047  18047  0.095813\n",
       "18048  18048  0.013155\n",
       "18049  18049  0.096498\n",
       "\n",
       "[18050 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\test.csv')\n",
    "id = test['id']\n",
    "pred = pd.DataFrame(pred_test_2)\n",
    "submit = pd.concat([id,pred], axis=1)\n",
    "submit.columns = ['id', 'y']\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('stack5.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python37164bit745322e800af484d9e7663a15d4e0767"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
