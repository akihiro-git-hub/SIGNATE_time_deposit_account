{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso,Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\dataset\\\\train_x_xgboost.csv')\n",
    "train_y = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\dataset\\\\train_y_xgboost.csv')\n",
    "test_x = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\dataset\\\\test_x_xgboost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_nn = pd.read_csv('.//dataset//train_x_NN.csv')\n",
    "train_y_nn = pd.read_csv('.//dataset//train_y_NN.csv')\n",
    "test_x_nn = pd.read_csv('.//dataset//test_x_NN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27095</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27096</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27097</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27098</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27099</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y\n",
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "...   ..\n",
       "27095  0\n",
       "27096  0\n",
       "27097  0\n",
       "27098  0\n",
       "27099  0\n",
       "\n",
       "[27100 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Model1xgb,Model1xgb2, Model1NN,Model1NN2,Model1ramdom,Model3logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv(model, train_x, train_y, test_x):\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "\n",
    "    # クロスバリデーションで学習・予測を行い、予測値とインデックスを保存する\n",
    "    for i, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "\n",
    "    # バリデーションデータに対する予測値を連結し、その後元の順序に並べ直す\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "\n",
    "    # テストデータに対する予測値の平均をとる\n",
    "    preds_test = np.mean(preds_test, axis=0)\n",
    "\n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:40:26] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06799\teval-error:0.07055\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06824\teval-error:0.07041\n",
      "[2]\ttrain-error:0.06760\teval-error:0.07070\n",
      "[3]\ttrain-error:0.06819\teval-error:0.07026\n",
      "[4]\ttrain-error:0.06716\teval-error:0.07011\n",
      "[5]\ttrain-error:0.06770\teval-error:0.06922\n",
      "[6]\ttrain-error:0.06731\teval-error:0.06937\n",
      "[7]\ttrain-error:0.06750\teval-error:0.06937\n",
      "[8]\ttrain-error:0.06741\teval-error:0.06967\n",
      "[9]\ttrain-error:0.06735\teval-error:0.06922\n",
      "[10]\ttrain-error:0.06701\teval-error:0.06864\n",
      "[11]\ttrain-error:0.06691\teval-error:0.06834\n",
      "[12]\ttrain-error:0.06677\teval-error:0.06804\n",
      "[13]\ttrain-error:0.06701\teval-error:0.06760\n",
      "[14]\ttrain-error:0.06696\teval-error:0.06731\n",
      "[15]\ttrain-error:0.06701\teval-error:0.06686\n",
      "[16]\ttrain-error:0.06657\teval-error:0.06672\n",
      "[17]\ttrain-error:0.06686\teval-error:0.06701\n",
      "[18]\ttrain-error:0.06677\teval-error:0.06657\n",
      "[19]\ttrain-error:0.06662\teval-error:0.06716\n",
      "[20]\ttrain-error:0.06657\teval-error:0.06657\n",
      "[21]\ttrain-error:0.06657\teval-error:0.06657\n",
      "[22]\ttrain-error:0.06637\teval-error:0.06642\n",
      "[23]\ttrain-error:0.06657\teval-error:0.06642\n",
      "[24]\ttrain-error:0.06632\teval-error:0.06657\n",
      "[25]\ttrain-error:0.06608\teval-error:0.06672\n",
      "[26]\ttrain-error:0.06613\teval-error:0.06686\n",
      "[27]\ttrain-error:0.06603\teval-error:0.06731\n",
      "[28]\ttrain-error:0.06583\teval-error:0.06701\n",
      "[29]\ttrain-error:0.06568\teval-error:0.06716\n",
      "[30]\ttrain-error:0.06573\teval-error:0.06672\n",
      "[31]\ttrain-error:0.06544\teval-error:0.06627\n",
      "[32]\ttrain-error:0.06534\teval-error:0.06598\n",
      "[33]\ttrain-error:0.06524\teval-error:0.06627\n",
      "[34]\ttrain-error:0.06504\teval-error:0.06627\n",
      "[35]\ttrain-error:0.06509\teval-error:0.06583\n",
      "[36]\ttrain-error:0.06475\teval-error:0.06598\n",
      "[37]\ttrain-error:0.06460\teval-error:0.06598\n",
      "[38]\ttrain-error:0.06455\teval-error:0.06539\n",
      "[39]\ttrain-error:0.06445\teval-error:0.06524\n",
      "[40]\ttrain-error:0.06426\teval-error:0.06524\n",
      "[41]\ttrain-error:0.06401\teval-error:0.06539\n",
      "[42]\ttrain-error:0.06386\teval-error:0.06509\n",
      "[43]\ttrain-error:0.06357\teval-error:0.06539\n",
      "[44]\ttrain-error:0.06312\teval-error:0.06524\n",
      "[45]\ttrain-error:0.06298\teval-error:0.06553\n",
      "[46]\ttrain-error:0.06308\teval-error:0.06568\n",
      "[47]\ttrain-error:0.06288\teval-error:0.06568\n",
      "[48]\ttrain-error:0.06273\teval-error:0.06568\n",
      "[49]\ttrain-error:0.06278\teval-error:0.06568\n",
      "[50]\ttrain-error:0.06258\teval-error:0.06568\n",
      "[51]\ttrain-error:0.06234\teval-error:0.06583\n",
      "[52]\ttrain-error:0.06180\teval-error:0.06568\n",
      "[53]\ttrain-error:0.06170\teval-error:0.06553\n",
      "[54]\ttrain-error:0.06150\teval-error:0.06568\n",
      "[55]\ttrain-error:0.06130\teval-error:0.06583\n",
      "[56]\ttrain-error:0.06125\teval-error:0.06539\n",
      "[57]\ttrain-error:0.06125\teval-error:0.06524\n",
      "[58]\ttrain-error:0.06135\teval-error:0.06524\n",
      "[59]\ttrain-error:0.06145\teval-error:0.06539\n",
      "[60]\ttrain-error:0.06091\teval-error:0.06495\n",
      "[61]\ttrain-error:0.06066\teval-error:0.06524\n",
      "[62]\ttrain-error:0.06052\teval-error:0.06524\n",
      "[63]\ttrain-error:0.06047\teval-error:0.06553\n",
      "[64]\ttrain-error:0.06052\teval-error:0.06568\n",
      "[65]\ttrain-error:0.06042\teval-error:0.06583\n",
      "[66]\ttrain-error:0.06022\teval-error:0.06539\n",
      "[67]\ttrain-error:0.06003\teval-error:0.06495\n",
      "[68]\ttrain-error:0.05988\teval-error:0.06509\n",
      "[69]\ttrain-error:0.06012\teval-error:0.06480\n",
      "[70]\ttrain-error:0.05998\teval-error:0.06509\n",
      "[71]\ttrain-error:0.05988\teval-error:0.06539\n",
      "[72]\ttrain-error:0.05963\teval-error:0.06539\n",
      "[73]\ttrain-error:0.05953\teval-error:0.06509\n",
      "[74]\ttrain-error:0.05924\teval-error:0.06524\n",
      "[75]\ttrain-error:0.05914\teval-error:0.06524\n",
      "[76]\ttrain-error:0.05914\teval-error:0.06539\n",
      "[77]\ttrain-error:0.05889\teval-error:0.06539\n",
      "[78]\ttrain-error:0.05880\teval-error:0.06539\n",
      "[79]\ttrain-error:0.05874\teval-error:0.06539\n",
      "[80]\ttrain-error:0.05840\teval-error:0.06583\n",
      "[81]\ttrain-error:0.05811\teval-error:0.06553\n",
      "[82]\ttrain-error:0.05806\teval-error:0.06553\n",
      "[83]\ttrain-error:0.05796\teval-error:0.06553\n",
      "[84]\ttrain-error:0.05781\teval-error:0.06568\n",
      "[85]\ttrain-error:0.05776\teval-error:0.06568\n",
      "[86]\ttrain-error:0.05761\teval-error:0.06568\n",
      "[87]\ttrain-error:0.05766\teval-error:0.06539\n",
      "[88]\ttrain-error:0.05737\teval-error:0.06553\n",
      "[89]\ttrain-error:0.05727\teval-error:0.06553\n",
      "Stopping. Best iteration:\n",
      "[69]\ttrain-error:0.06012\teval-error:0.06480\n",
      "\n",
      "[22:40:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06780\teval-error:0.07188\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06790\teval-error:0.07173\n",
      "[2]\ttrain-error:0.06785\teval-error:0.07114\n",
      "[3]\ttrain-error:0.06780\teval-error:0.07129\n",
      "[4]\ttrain-error:0.06775\teval-error:0.07114\n",
      "[5]\ttrain-error:0.06770\teval-error:0.07129\n",
      "[6]\ttrain-error:0.06750\teval-error:0.07070\n",
      "[7]\ttrain-error:0.06741\teval-error:0.07129\n",
      "[8]\ttrain-error:0.06735\teval-error:0.07114\n",
      "[9]\ttrain-error:0.06716\teval-error:0.07085\n",
      "[10]\ttrain-error:0.06691\teval-error:0.07114\n",
      "[11]\ttrain-error:0.06677\teval-error:0.07041\n",
      "[12]\ttrain-error:0.06647\teval-error:0.06982\n",
      "[13]\ttrain-error:0.06642\teval-error:0.06996\n",
      "[14]\ttrain-error:0.06617\teval-error:0.06996\n",
      "[15]\ttrain-error:0.06608\teval-error:0.06908\n",
      "[16]\ttrain-error:0.06627\teval-error:0.06922\n",
      "[17]\ttrain-error:0.06622\teval-error:0.06922\n",
      "[18]\ttrain-error:0.06603\teval-error:0.06922\n",
      "[19]\ttrain-error:0.06578\teval-error:0.06922\n",
      "[20]\ttrain-error:0.06598\teval-error:0.06952\n",
      "[21]\ttrain-error:0.06603\teval-error:0.06982\n",
      "[22]\ttrain-error:0.06593\teval-error:0.06967\n",
      "[23]\ttrain-error:0.06593\teval-error:0.06937\n",
      "[24]\ttrain-error:0.06583\teval-error:0.06952\n",
      "[25]\ttrain-error:0.06553\teval-error:0.06952\n",
      "[26]\ttrain-error:0.06568\teval-error:0.06952\n",
      "[27]\ttrain-error:0.06563\teval-error:0.06952\n",
      "[28]\ttrain-error:0.06544\teval-error:0.06967\n",
      "[29]\ttrain-error:0.06544\teval-error:0.06952\n",
      "[30]\ttrain-error:0.06544\teval-error:0.06952\n",
      "[31]\ttrain-error:0.06499\teval-error:0.06967\n",
      "[32]\ttrain-error:0.06480\teval-error:0.06982\n",
      "[33]\ttrain-error:0.06455\teval-error:0.06937\n",
      "[34]\ttrain-error:0.06470\teval-error:0.06937\n",
      "[35]\ttrain-error:0.06460\teval-error:0.06937\n",
      "Stopping. Best iteration:\n",
      "[15]\ttrain-error:0.06608\teval-error:0.06908\n",
      "\n",
      "[22:40:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06775\teval-error:0.07262\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06741\teval-error:0.07306\n",
      "[2]\ttrain-error:0.06745\teval-error:0.07306\n",
      "[3]\ttrain-error:0.06745\teval-error:0.07262\n",
      "[4]\ttrain-error:0.06735\teval-error:0.07203\n",
      "[5]\ttrain-error:0.06735\teval-error:0.07173\n",
      "[6]\ttrain-error:0.06711\teval-error:0.07188\n",
      "[7]\ttrain-error:0.06711\teval-error:0.07173\n",
      "[8]\ttrain-error:0.06711\teval-error:0.07129\n",
      "[9]\ttrain-error:0.06696\teval-error:0.07085\n",
      "[10]\ttrain-error:0.06667\teval-error:0.07085\n",
      "[11]\ttrain-error:0.06652\teval-error:0.07055\n",
      "[12]\ttrain-error:0.06657\teval-error:0.07085\n",
      "[13]\ttrain-error:0.06632\teval-error:0.07085\n",
      "[14]\ttrain-error:0.06627\teval-error:0.07085\n",
      "[15]\ttrain-error:0.06642\teval-error:0.07129\n",
      "[16]\ttrain-error:0.06647\teval-error:0.07114\n",
      "[17]\ttrain-error:0.06622\teval-error:0.07085\n",
      "[18]\ttrain-error:0.06622\teval-error:0.07114\n",
      "[19]\ttrain-error:0.06642\teval-error:0.07114\n",
      "[20]\ttrain-error:0.06642\teval-error:0.07100\n",
      "[21]\ttrain-error:0.06632\teval-error:0.07100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\ttrain-error:0.06622\teval-error:0.07100\n",
      "[23]\ttrain-error:0.06622\teval-error:0.07100\n",
      "[24]\ttrain-error:0.06632\teval-error:0.07055\n",
      "[25]\ttrain-error:0.06637\teval-error:0.07041\n",
      "[26]\ttrain-error:0.06627\teval-error:0.07070\n",
      "[27]\ttrain-error:0.06617\teval-error:0.07026\n",
      "[28]\ttrain-error:0.06632\teval-error:0.07055\n",
      "[29]\ttrain-error:0.06608\teval-error:0.07070\n",
      "[30]\ttrain-error:0.06593\teval-error:0.07055\n",
      "[31]\ttrain-error:0.06568\teval-error:0.07041\n",
      "[32]\ttrain-error:0.06553\teval-error:0.07085\n",
      "[33]\ttrain-error:0.06534\teval-error:0.07070\n",
      "[34]\ttrain-error:0.06519\teval-error:0.07026\n",
      "[35]\ttrain-error:0.06495\teval-error:0.07070\n",
      "[36]\ttrain-error:0.06499\teval-error:0.07100\n",
      "[37]\ttrain-error:0.06485\teval-error:0.07070\n",
      "[38]\ttrain-error:0.06460\teval-error:0.07085\n",
      "[39]\ttrain-error:0.06431\teval-error:0.07070\n",
      "[40]\ttrain-error:0.06406\teval-error:0.07100\n",
      "[41]\ttrain-error:0.06391\teval-error:0.07100\n",
      "[42]\ttrain-error:0.06376\teval-error:0.07085\n",
      "[43]\ttrain-error:0.06376\teval-error:0.07085\n",
      "[44]\ttrain-error:0.06342\teval-error:0.07041\n",
      "[45]\ttrain-error:0.06332\teval-error:0.07055\n",
      "[46]\ttrain-error:0.06327\teval-error:0.07055\n",
      "[47]\ttrain-error:0.06298\teval-error:0.07041\n",
      "Stopping. Best iteration:\n",
      "[27]\ttrain-error:0.06617\teval-error:0.07026\n",
      "\n",
      "[22:40:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06686\teval-error:0.07572\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06677\teval-error:0.07542\n",
      "[2]\ttrain-error:0.06642\teval-error:0.07439\n",
      "[3]\ttrain-error:0.06627\teval-error:0.07410\n",
      "[4]\ttrain-error:0.06667\teval-error:0.07439\n",
      "[5]\ttrain-error:0.06627\teval-error:0.07454\n",
      "[6]\ttrain-error:0.06642\teval-error:0.07498\n",
      "[7]\ttrain-error:0.06598\teval-error:0.07454\n",
      "[8]\ttrain-error:0.06608\teval-error:0.07454\n",
      "[9]\ttrain-error:0.06578\teval-error:0.07410\n",
      "[10]\ttrain-error:0.06539\teval-error:0.07424\n",
      "[11]\ttrain-error:0.06549\teval-error:0.07469\n",
      "[12]\ttrain-error:0.06544\teval-error:0.07454\n",
      "[13]\ttrain-error:0.06553\teval-error:0.07424\n",
      "[14]\ttrain-error:0.06558\teval-error:0.07410\n",
      "[15]\ttrain-error:0.06534\teval-error:0.07439\n",
      "[16]\ttrain-error:0.06509\teval-error:0.07424\n",
      "[17]\ttrain-error:0.06475\teval-error:0.07424\n",
      "[18]\ttrain-error:0.06480\teval-error:0.07439\n",
      "[19]\ttrain-error:0.06480\teval-error:0.07439\n",
      "[20]\ttrain-error:0.06480\teval-error:0.07439\n",
      "[21]\ttrain-error:0.06470\teval-error:0.07410\n",
      "[22]\ttrain-error:0.06450\teval-error:0.07380\n",
      "[23]\ttrain-error:0.06440\teval-error:0.07395\n",
      "[24]\ttrain-error:0.06435\teval-error:0.07410\n",
      "[25]\ttrain-error:0.06401\teval-error:0.07380\n",
      "[26]\ttrain-error:0.06416\teval-error:0.07424\n",
      "[27]\ttrain-error:0.06411\teval-error:0.07454\n",
      "[28]\ttrain-error:0.06396\teval-error:0.07424\n",
      "[29]\ttrain-error:0.06362\teval-error:0.07424\n",
      "[30]\ttrain-error:0.06366\teval-error:0.07454\n",
      "[31]\ttrain-error:0.06337\teval-error:0.07380\n",
      "[32]\ttrain-error:0.06322\teval-error:0.07380\n",
      "[33]\ttrain-error:0.06308\teval-error:0.07365\n",
      "[34]\ttrain-error:0.06312\teval-error:0.07336\n",
      "[35]\ttrain-error:0.06312\teval-error:0.07336\n",
      "[36]\ttrain-error:0.06308\teval-error:0.07321\n",
      "[37]\ttrain-error:0.06303\teval-error:0.07336\n",
      "[38]\ttrain-error:0.06278\teval-error:0.07306\n",
      "[39]\ttrain-error:0.06229\teval-error:0.07336\n",
      "[40]\ttrain-error:0.06229\teval-error:0.07336\n",
      "[41]\ttrain-error:0.06209\teval-error:0.07351\n",
      "[42]\ttrain-error:0.06189\teval-error:0.07321\n",
      "[43]\ttrain-error:0.06150\teval-error:0.07336\n",
      "[44]\ttrain-error:0.06125\teval-error:0.07306\n",
      "[45]\ttrain-error:0.06111\teval-error:0.07306\n",
      "[46]\ttrain-error:0.06125\teval-error:0.07321\n",
      "[47]\ttrain-error:0.06111\teval-error:0.07336\n",
      "[48]\ttrain-error:0.06086\teval-error:0.07380\n",
      "[49]\ttrain-error:0.06076\teval-error:0.07351\n",
      "[50]\ttrain-error:0.06066\teval-error:0.07306\n",
      "[51]\ttrain-error:0.06052\teval-error:0.07291\n",
      "[52]\ttrain-error:0.06042\teval-error:0.07277\n",
      "[53]\ttrain-error:0.06042\teval-error:0.07321\n",
      "[54]\ttrain-error:0.06032\teval-error:0.07306\n",
      "[55]\ttrain-error:0.05988\teval-error:0.07306\n",
      "[56]\ttrain-error:0.05988\teval-error:0.07321\n",
      "[57]\ttrain-error:0.05988\teval-error:0.07321\n",
      "[58]\ttrain-error:0.05968\teval-error:0.07306\n",
      "[59]\ttrain-error:0.05958\teval-error:0.07306\n",
      "[60]\ttrain-error:0.05943\teval-error:0.07306\n",
      "[61]\ttrain-error:0.05904\teval-error:0.07291\n",
      "[62]\ttrain-error:0.05899\teval-error:0.07277\n",
      "[63]\ttrain-error:0.05889\teval-error:0.07262\n",
      "[64]\ttrain-error:0.05870\teval-error:0.07262\n",
      "[65]\ttrain-error:0.05820\teval-error:0.07247\n",
      "[66]\ttrain-error:0.05825\teval-error:0.07247\n",
      "[67]\ttrain-error:0.05815\teval-error:0.07262\n",
      "[68]\ttrain-error:0.05815\teval-error:0.07247\n",
      "[69]\ttrain-error:0.05786\teval-error:0.07233\n",
      "[70]\ttrain-error:0.05756\teval-error:0.07218\n",
      "[71]\ttrain-error:0.05751\teval-error:0.07233\n",
      "[72]\ttrain-error:0.05756\teval-error:0.07218\n",
      "[73]\ttrain-error:0.05737\teval-error:0.07203\n",
      "[74]\ttrain-error:0.05737\teval-error:0.07203\n",
      "[75]\ttrain-error:0.05717\teval-error:0.07188\n",
      "[76]\ttrain-error:0.05717\teval-error:0.07188\n",
      "[77]\ttrain-error:0.05678\teval-error:0.07218\n",
      "[78]\ttrain-error:0.05658\teval-error:0.07218\n",
      "[79]\ttrain-error:0.05653\teval-error:0.07218\n",
      "[80]\ttrain-error:0.05648\teval-error:0.07218\n",
      "[81]\ttrain-error:0.05599\teval-error:0.07233\n",
      "[82]\ttrain-error:0.05584\teval-error:0.07233\n",
      "[83]\ttrain-error:0.05579\teval-error:0.07247\n",
      "[84]\ttrain-error:0.05570\teval-error:0.07262\n",
      "[85]\ttrain-error:0.05560\teval-error:0.07247\n",
      "[86]\ttrain-error:0.05555\teval-error:0.07247\n",
      "[87]\ttrain-error:0.05530\teval-error:0.07203\n",
      "[88]\ttrain-error:0.05535\teval-error:0.07233\n",
      "[89]\ttrain-error:0.05525\teval-error:0.07218\n",
      "[90]\ttrain-error:0.05520\teval-error:0.07203\n",
      "[91]\ttrain-error:0.05530\teval-error:0.07218\n",
      "[92]\ttrain-error:0.05515\teval-error:0.07233\n",
      "[93]\ttrain-error:0.05505\teval-error:0.07188\n",
      "[94]\ttrain-error:0.05501\teval-error:0.07188\n",
      "[95]\ttrain-error:0.05505\teval-error:0.07188\n",
      "Stopping. Best iteration:\n",
      "[75]\ttrain-error:0.05717\teval-error:0.07188\n",
      "\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2414 - accuracy: 0.9265 - val_loss: 0.2111 - val_accuracy: 0.9334\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2141 - accuracy: 0.9294 - val_loss: 0.2069 - val_accuracy: 0.9334\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2112 - accuracy: 0.9302 - val_loss: 0.2051 - val_accuracy: 0.9336\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2084 - accuracy: 0.9309 - val_loss: 0.2105 - val_accuracy: 0.9311\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9311 - val_loss: 0.2061 - val_accuracy: 0.9340\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2020 - accuracy: 0.9323 - val_loss: 0.2063 - val_accuracy: 0.9340\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2014 - accuracy: 0.9330 - val_loss: 0.2071 - val_accuracy: 0.9327\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1991 - accuracy: 0.9319 - val_loss: 0.2077 - val_accuracy: 0.9336\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1961 - accuracy: 0.9331 - val_loss: 0.2082 - val_accuracy: 0.9320\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1936 - accuracy: 0.9342 - val_loss: 0.2094 - val_accuracy: 0.9317\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1919 - accuracy: 0.9338 - val_loss: 0.2089 - val_accuracy: 0.9321\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1880 - accuracy: 0.9351 - val_loss: 0.2114 - val_accuracy: 0.9331\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1881 - accuracy: 0.9348 - val_loss: 0.2117 - val_accuracy: 0.9330\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1870 - accuracy: 0.9357 - val_loss: 0.2109 - val_accuracy: 0.9323\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1816 - accuracy: 0.9377 - val_loss: 0.2181 - val_accuracy: 0.9297\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1800 - accuracy: 0.9373 - val_loss: 0.2168 - val_accuracy: 0.9314\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1764 - accuracy: 0.9386 - val_loss: 0.2175 - val_accuracy: 0.9321\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1734 - accuracy: 0.9389 - val_loss: 0.2178 - val_accuracy: 0.9327\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1734 - accuracy: 0.9390 - val_loss: 0.2159 - val_accuracy: 0.9317\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1706 - accuracy: 0.9392 - val_loss: 0.2176 - val_accuracy: 0.9317\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1679 - accuracy: 0.9413 - val_loss: 0.2169 - val_accuracy: 0.9324\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1636 - accuracy: 0.9423 - val_loss: 0.2222 - val_accuracy: 0.9323\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1630 - accuracy: 0.9430 - val_loss: 0.2278 - val_accuracy: 0.9321\n",
      "WARNING:tensorflow:From C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:118: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2428 - accuracy: 0.9231 - val_loss: 0.2194 - val_accuracy: 0.9305\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2128 - accuracy: 0.9306 - val_loss: 0.2170 - val_accuracy: 0.9286\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2099 - accuracy: 0.9306 - val_loss: 0.2185 - val_accuracy: 0.9305\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9312 - val_loss: 0.2141 - val_accuracy: 0.9300\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2024 - accuracy: 0.9323 - val_loss: 0.2153 - val_accuracy: 0.9294\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2014 - accuracy: 0.9330 - val_loss: 0.2143 - val_accuracy: 0.9308\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1965 - accuracy: 0.9342 - val_loss: 0.2171 - val_accuracy: 0.9292\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1961 - accuracy: 0.9341 - val_loss: 0.2172 - val_accuracy: 0.9290\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1948 - accuracy: 0.9340 - val_loss: 0.2187 - val_accuracy: 0.9283\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1924 - accuracy: 0.9358 - val_loss: 0.2181 - val_accuracy: 0.9287\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1898 - accuracy: 0.9356 - val_loss: 0.2184 - val_accuracy: 0.9286\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1904 - accuracy: 0.9360 - val_loss: 0.2236 - val_accuracy: 0.9272\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1858 - accuracy: 0.9365 - val_loss: 0.2265 - val_accuracy: 0.9297\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1845 - accuracy: 0.9369 - val_loss: 0.2269 - val_accuracy: 0.9289\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1827 - accuracy: 0.9387 - val_loss: 0.2226 - val_accuracy: 0.9277\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1791 - accuracy: 0.9383 - val_loss: 0.2281 - val_accuracy: 0.9266\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1788 - accuracy: 0.9395 - val_loss: 0.2279 - val_accuracy: 0.9258\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1754 - accuracy: 0.9393 - val_loss: 0.2354 - val_accuracy: 0.9262\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1727 - accuracy: 0.9399 - val_loss: 0.2331 - val_accuracy: 0.9249\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1706 - accuracy: 0.9405 - val_loss: 0.2300 - val_accuracy: 0.9263\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1663 - accuracy: 0.9410 - val_loss: 0.2368 - val_accuracy: 0.9258\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1647 - accuracy: 0.9431 - val_loss: 0.2370 - val_accuracy: 0.9271\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1633 - accuracy: 0.9422 - val_loss: 0.2356 - val_accuracy: 0.9262\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1579 - accuracy: 0.9452 - val_loss: 0.2410 - val_accuracy: 0.9249\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2378 - accuracy: 0.9260 - val_loss: 0.2301 - val_accuracy: 0.9269\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2128 - accuracy: 0.9308 - val_loss: 0.2163 - val_accuracy: 0.9297\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9311 - val_loss: 0.2175 - val_accuracy: 0.9308\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2050 - accuracy: 0.9322 - val_loss: 0.2174 - val_accuracy: 0.9308\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2026 - accuracy: 0.9332 - val_loss: 0.2170 - val_accuracy: 0.9303\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1991 - accuracy: 0.9331 - val_loss: 0.2195 - val_accuracy: 0.9297\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1980 - accuracy: 0.9340 - val_loss: 0.2175 - val_accuracy: 0.9314\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1942 - accuracy: 0.9341 - val_loss: 0.2204 - val_accuracy: 0.9320\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1936 - accuracy: 0.9345 - val_loss: 0.2196 - val_accuracy: 0.9305\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1908 - accuracy: 0.9351 - val_loss: 0.2221 - val_accuracy: 0.9309\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1884 - accuracy: 0.9351 - val_loss: 0.2215 - val_accuracy: 0.9311\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1869 - accuracy: 0.9354 - val_loss: 0.2232 - val_accuracy: 0.9324\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1839 - accuracy: 0.9374 - val_loss: 0.2270 - val_accuracy: 0.9309\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1818 - accuracy: 0.9380 - val_loss: 0.2262 - val_accuracy: 0.9311\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1788 - accuracy: 0.9383 - val_loss: 0.2333 - val_accuracy: 0.9287\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1777 - accuracy: 0.9392 - val_loss: 0.2326 - val_accuracy: 0.9293\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1743 - accuracy: 0.9403 - val_loss: 0.2333 - val_accuracy: 0.9293\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1742 - accuracy: 0.9404 - val_loss: 0.2312 - val_accuracy: 0.9305\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1700 - accuracy: 0.9422 - val_loss: 0.2375 - val_accuracy: 0.9290\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1673 - accuracy: 0.9418 - val_loss: 0.2352 - val_accuracy: 0.9305\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1622 - accuracy: 0.9429 - val_loss: 0.2391 - val_accuracy: 0.9303\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1602 - accuracy: 0.9442 - val_loss: 0.2432 - val_accuracy: 0.9263\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2468 - accuracy: 0.9232 - val_loss: 0.2184 - val_accuracy: 0.9259\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2122 - accuracy: 0.9307 - val_loss: 0.2143 - val_accuracy: 0.9271\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2103 - accuracy: 0.9324 - val_loss: 0.2130 - val_accuracy: 0.9283\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2064 - accuracy: 0.9325 - val_loss: 0.2151 - val_accuracy: 0.9275\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.2024 - accuracy: 0.9327 - val_loss: 0.2163 - val_accuracy: 0.9277\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1991 - accuracy: 0.9341 - val_loss: 0.2141 - val_accuracy: 0.9275\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1981 - accuracy: 0.9340 - val_loss: 0.2184 - val_accuracy: 0.9280\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1967 - accuracy: 0.9344 - val_loss: 0.2192 - val_accuracy: 0.9274\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1935 - accuracy: 0.9355 - val_loss: 0.2163 - val_accuracy: 0.9269\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1928 - accuracy: 0.9364 - val_loss: 0.2217 - val_accuracy: 0.9271\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1899 - accuracy: 0.9362 - val_loss: 0.2186 - val_accuracy: 0.9274\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1873 - accuracy: 0.9370 - val_loss: 0.2218 - val_accuracy: 0.9263\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1863 - accuracy: 0.9377 - val_loss: 0.2207 - val_accuracy: 0.9265\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1840 - accuracy: 0.9383 - val_loss: 0.2193 - val_accuracy: 0.9258\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1812 - accuracy: 0.9403 - val_loss: 0.2225 - val_accuracy: 0.9255\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1793 - accuracy: 0.9385 - val_loss: 0.2268 - val_accuracy: 0.9262\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1772 - accuracy: 0.9394 - val_loss: 0.2309 - val_accuracy: 0.9265\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1751 - accuracy: 0.9413 - val_loss: 0.2267 - val_accuracy: 0.9247\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1717 - accuracy: 0.9412 - val_loss: 0.2319 - val_accuracy: 0.9221\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1704 - accuracy: 0.9418 - val_loss: 0.2321 - val_accuracy: 0.9259\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1668 - accuracy: 0.9437 - val_loss: 0.2348 - val_accuracy: 0.9247\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1642 - accuracy: 0.9434 - val_loss: 0.2370 - val_accuracy: 0.9237\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1629 - accuracy: 0.9440 - val_loss: 0.2386 - val_accuracy: 0.9237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:174: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:174: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:174: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:174: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:42:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06922\teval-error:0.07100\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06888\teval-error:0.06967\n",
      "[2]\ttrain-error:0.06962\teval-error:0.06819\n",
      "[3]\ttrain-error:0.06898\teval-error:0.06745\n",
      "[4]\ttrain-error:0.06809\teval-error:0.06686\n",
      "[5]\ttrain-error:0.06927\teval-error:0.06613\n",
      "[6]\ttrain-error:0.06903\teval-error:0.06598\n",
      "[7]\ttrain-error:0.06844\teval-error:0.06613\n",
      "[8]\ttrain-error:0.06819\teval-error:0.06627\n",
      "[9]\ttrain-error:0.06775\teval-error:0.06583\n",
      "[10]\ttrain-error:0.06775\teval-error:0.06583\n",
      "[11]\ttrain-error:0.06741\teval-error:0.06598\n",
      "[12]\ttrain-error:0.06741\teval-error:0.06598\n",
      "[13]\ttrain-error:0.06755\teval-error:0.06553\n",
      "[14]\ttrain-error:0.06750\teval-error:0.06568\n",
      "[15]\ttrain-error:0.06731\teval-error:0.06583\n",
      "[16]\ttrain-error:0.06711\teval-error:0.06553\n",
      "[17]\ttrain-error:0.06706\teval-error:0.06568\n",
      "[18]\ttrain-error:0.06686\teval-error:0.06583\n",
      "[19]\ttrain-error:0.06657\teval-error:0.06583\n",
      "[20]\ttrain-error:0.06672\teval-error:0.06613\n",
      "[21]\ttrain-error:0.06686\teval-error:0.06613\n",
      "[22]\ttrain-error:0.06686\teval-error:0.06598\n",
      "[23]\ttrain-error:0.06701\teval-error:0.06568\n",
      "[24]\ttrain-error:0.06677\teval-error:0.06568\n",
      "[25]\ttrain-error:0.06706\teval-error:0.06583\n",
      "[26]\ttrain-error:0.06667\teval-error:0.06568\n",
      "[27]\ttrain-error:0.06642\teval-error:0.06568\n",
      "[28]\ttrain-error:0.06662\teval-error:0.06553\n",
      "[29]\ttrain-error:0.06657\teval-error:0.06568\n",
      "[30]\ttrain-error:0.06608\teval-error:0.06568\n",
      "[31]\ttrain-error:0.06617\teval-error:0.06539\n",
      "[32]\ttrain-error:0.06608\teval-error:0.06553\n",
      "[33]\ttrain-error:0.06598\teval-error:0.06568\n",
      "[34]\ttrain-error:0.06603\teval-error:0.06553\n",
      "[35]\ttrain-error:0.06583\teval-error:0.06539\n",
      "[36]\ttrain-error:0.06568\teval-error:0.06524\n",
      "[37]\ttrain-error:0.06553\teval-error:0.06524\n",
      "[38]\ttrain-error:0.06539\teval-error:0.06539\n",
      "[39]\ttrain-error:0.06480\teval-error:0.06553\n",
      "[40]\ttrain-error:0.06470\teval-error:0.06539\n",
      "[41]\ttrain-error:0.06455\teval-error:0.06553\n",
      "[42]\ttrain-error:0.06421\teval-error:0.06539\n",
      "[43]\ttrain-error:0.06426\teval-error:0.06553\n",
      "[44]\ttrain-error:0.06416\teval-error:0.06568\n",
      "[45]\ttrain-error:0.06426\teval-error:0.06583\n",
      "[46]\ttrain-error:0.06406\teval-error:0.06568\n",
      "[47]\ttrain-error:0.06352\teval-error:0.06553\n",
      "[48]\ttrain-error:0.06327\teval-error:0.06568\n",
      "[49]\ttrain-error:0.06308\teval-error:0.06553\n",
      "[50]\ttrain-error:0.06288\teval-error:0.06553\n",
      "[51]\ttrain-error:0.06258\teval-error:0.06598\n",
      "[52]\ttrain-error:0.06239\teval-error:0.06568\n",
      "[53]\ttrain-error:0.06243\teval-error:0.06568\n",
      "[54]\ttrain-error:0.06234\teval-error:0.06539\n",
      "[55]\ttrain-error:0.06219\teval-error:0.06539\n",
      "[56]\ttrain-error:0.06234\teval-error:0.06539\n",
      "Stopping. Best iteration:\n",
      "[36]\ttrain-error:0.06568\teval-error:0.06524\n",
      "\n",
      "[22:42:09] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06937\teval-error:0.07100\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06888\teval-error:0.07011\n",
      "[2]\ttrain-error:0.06952\teval-error:0.07085\n",
      "[3]\ttrain-error:0.06893\teval-error:0.07100\n",
      "[4]\ttrain-error:0.06878\teval-error:0.07114\n",
      "[5]\ttrain-error:0.06908\teval-error:0.07114\n",
      "[6]\ttrain-error:0.06858\teval-error:0.07041\n",
      "[7]\ttrain-error:0.06829\teval-error:0.07070\n",
      "[8]\ttrain-error:0.06814\teval-error:0.07026\n",
      "[9]\ttrain-error:0.06760\teval-error:0.07011\n",
      "[10]\ttrain-error:0.06790\teval-error:0.07026\n",
      "[11]\ttrain-error:0.06780\teval-error:0.06982\n",
      "[12]\ttrain-error:0.06750\teval-error:0.06967\n",
      "[13]\ttrain-error:0.06745\teval-error:0.06996\n",
      "[14]\ttrain-error:0.06741\teval-error:0.06952\n",
      "[15]\ttrain-error:0.06706\teval-error:0.06952\n",
      "[16]\ttrain-error:0.06716\teval-error:0.06952\n",
      "[17]\ttrain-error:0.06677\teval-error:0.06922\n",
      "[18]\ttrain-error:0.06652\teval-error:0.06908\n",
      "[19]\ttrain-error:0.06667\teval-error:0.06893\n",
      "[20]\ttrain-error:0.06677\teval-error:0.06908\n",
      "[21]\ttrain-error:0.06681\teval-error:0.06908\n",
      "[22]\ttrain-error:0.06677\teval-error:0.06922\n",
      "[23]\ttrain-error:0.06657\teval-error:0.06893\n",
      "[24]\ttrain-error:0.06647\teval-error:0.06893\n",
      "[25]\ttrain-error:0.06622\teval-error:0.06908\n",
      "[26]\ttrain-error:0.06608\teval-error:0.06908\n",
      "[27]\ttrain-error:0.06617\teval-error:0.06893\n",
      "[28]\ttrain-error:0.06598\teval-error:0.06849\n",
      "[29]\ttrain-error:0.06603\teval-error:0.06864\n",
      "[30]\ttrain-error:0.06583\teval-error:0.06893\n",
      "[31]\ttrain-error:0.06534\teval-error:0.06878\n",
      "[32]\ttrain-error:0.06529\teval-error:0.06864\n",
      "[33]\ttrain-error:0.06529\teval-error:0.06878\n",
      "[34]\ttrain-error:0.06519\teval-error:0.06819\n",
      "[35]\ttrain-error:0.06489\teval-error:0.06893\n",
      "[36]\ttrain-error:0.06495\teval-error:0.06893\n",
      "[37]\ttrain-error:0.06460\teval-error:0.06834\n",
      "[38]\ttrain-error:0.06440\teval-error:0.06849\n",
      "[39]\ttrain-error:0.06440\teval-error:0.06790\n",
      "[40]\ttrain-error:0.06440\teval-error:0.06804\n",
      "[41]\ttrain-error:0.06431\teval-error:0.06819\n",
      "[42]\ttrain-error:0.06416\teval-error:0.06804\n",
      "[43]\ttrain-error:0.06381\teval-error:0.06790\n",
      "[44]\ttrain-error:0.06362\teval-error:0.06804\n",
      "[45]\ttrain-error:0.06317\teval-error:0.06834\n",
      "[46]\ttrain-error:0.06303\teval-error:0.06819\n",
      "[47]\ttrain-error:0.06288\teval-error:0.06849\n",
      "[48]\ttrain-error:0.06268\teval-error:0.06849\n",
      "[49]\ttrain-error:0.06253\teval-error:0.06804\n",
      "[50]\ttrain-error:0.06199\teval-error:0.06849\n",
      "[51]\ttrain-error:0.06189\teval-error:0.06790\n",
      "[52]\ttrain-error:0.06145\teval-error:0.06849\n",
      "[53]\ttrain-error:0.06121\teval-error:0.06878\n",
      "[54]\ttrain-error:0.06121\teval-error:0.06849\n",
      "[55]\ttrain-error:0.06111\teval-error:0.06922\n",
      "[56]\ttrain-error:0.06106\teval-error:0.06922\n",
      "[57]\ttrain-error:0.06091\teval-error:0.06908\n",
      "[58]\ttrain-error:0.06096\teval-error:0.06864\n",
      "[59]\ttrain-error:0.06081\teval-error:0.06878\n",
      "Stopping. Best iteration:\n",
      "[39]\ttrain-error:0.06440\teval-error:0.06790\n",
      "\n",
      "[22:42:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06873\teval-error:0.06996\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06893\teval-error:0.07114\n",
      "[2]\ttrain-error:0.06893\teval-error:0.07085\n",
      "[3]\ttrain-error:0.06873\teval-error:0.07026\n",
      "[4]\ttrain-error:0.06839\teval-error:0.07085\n",
      "[5]\ttrain-error:0.06873\teval-error:0.07011\n",
      "[6]\ttrain-error:0.06799\teval-error:0.06982\n",
      "[7]\ttrain-error:0.06795\teval-error:0.06982\n",
      "[8]\ttrain-error:0.06775\teval-error:0.07026\n",
      "[9]\ttrain-error:0.06790\teval-error:0.06967\n",
      "[10]\ttrain-error:0.06790\teval-error:0.06952\n",
      "[11]\ttrain-error:0.06770\teval-error:0.06937\n",
      "[12]\ttrain-error:0.06750\teval-error:0.06967\n",
      "[13]\ttrain-error:0.06741\teval-error:0.06937\n",
      "[14]\ttrain-error:0.06755\teval-error:0.06922\n",
      "[15]\ttrain-error:0.06745\teval-error:0.06937\n",
      "[16]\ttrain-error:0.06775\teval-error:0.06893\n",
      "[17]\ttrain-error:0.06735\teval-error:0.06922\n",
      "[18]\ttrain-error:0.06735\teval-error:0.06922\n",
      "[19]\ttrain-error:0.06731\teval-error:0.06922\n",
      "[20]\ttrain-error:0.06706\teval-error:0.06908\n",
      "[21]\ttrain-error:0.06686\teval-error:0.06908\n",
      "[22]\ttrain-error:0.06677\teval-error:0.06908\n",
      "[23]\ttrain-error:0.06662\teval-error:0.06908\n",
      "[24]\ttrain-error:0.06622\teval-error:0.06922\n",
      "[25]\ttrain-error:0.06642\teval-error:0.06922\n",
      "[26]\ttrain-error:0.06613\teval-error:0.06922\n",
      "[27]\ttrain-error:0.06578\teval-error:0.06982\n",
      "[28]\ttrain-error:0.06598\teval-error:0.06967\n",
      "[29]\ttrain-error:0.06583\teval-error:0.06982\n",
      "[30]\ttrain-error:0.06573\teval-error:0.06967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\ttrain-error:0.06549\teval-error:0.06952\n",
      "[32]\ttrain-error:0.06514\teval-error:0.06952\n",
      "[33]\ttrain-error:0.06489\teval-error:0.06922\n",
      "[34]\ttrain-error:0.06504\teval-error:0.06922\n",
      "[35]\ttrain-error:0.06499\teval-error:0.06878\n",
      "[36]\ttrain-error:0.06489\teval-error:0.06878\n",
      "[37]\ttrain-error:0.06470\teval-error:0.06849\n",
      "[38]\ttrain-error:0.06470\teval-error:0.06878\n",
      "[39]\ttrain-error:0.06480\teval-error:0.06864\n",
      "[40]\ttrain-error:0.06460\teval-error:0.06893\n",
      "[41]\ttrain-error:0.06406\teval-error:0.06893\n",
      "[42]\ttrain-error:0.06386\teval-error:0.06893\n",
      "[43]\ttrain-error:0.06357\teval-error:0.06922\n",
      "[44]\ttrain-error:0.06347\teval-error:0.06908\n",
      "[45]\ttrain-error:0.06347\teval-error:0.06893\n",
      "[46]\ttrain-error:0.06327\teval-error:0.06864\n",
      "[47]\ttrain-error:0.06322\teval-error:0.06893\n",
      "[48]\ttrain-error:0.06283\teval-error:0.06878\n",
      "[49]\ttrain-error:0.06268\teval-error:0.06864\n",
      "[50]\ttrain-error:0.06253\teval-error:0.06849\n",
      "[51]\ttrain-error:0.06224\teval-error:0.06864\n",
      "[52]\ttrain-error:0.06219\teval-error:0.06834\n",
      "[53]\ttrain-error:0.06219\teval-error:0.06819\n",
      "[54]\ttrain-error:0.06209\teval-error:0.06849\n",
      "[55]\ttrain-error:0.06189\teval-error:0.06819\n",
      "[56]\ttrain-error:0.06175\teval-error:0.06819\n",
      "[57]\ttrain-error:0.06150\teval-error:0.06834\n",
      "[58]\ttrain-error:0.06145\teval-error:0.06878\n",
      "[59]\ttrain-error:0.06125\teval-error:0.06878\n",
      "[60]\ttrain-error:0.06086\teval-error:0.06878\n",
      "[61]\ttrain-error:0.06096\teval-error:0.06893\n",
      "[62]\ttrain-error:0.06081\teval-error:0.06908\n",
      "[63]\ttrain-error:0.06062\teval-error:0.06922\n",
      "[64]\ttrain-error:0.06037\teval-error:0.06908\n",
      "[65]\ttrain-error:0.06032\teval-error:0.06893\n",
      "[66]\ttrain-error:0.06022\teval-error:0.06864\n",
      "[67]\ttrain-error:0.05993\teval-error:0.06878\n",
      "[68]\ttrain-error:0.05973\teval-error:0.06849\n",
      "[69]\ttrain-error:0.05993\teval-error:0.06819\n",
      "[70]\ttrain-error:0.05988\teval-error:0.06834\n",
      "[71]\ttrain-error:0.05973\teval-error:0.06804\n",
      "[72]\ttrain-error:0.05934\teval-error:0.06804\n",
      "[73]\ttrain-error:0.05934\teval-error:0.06790\n",
      "[74]\ttrain-error:0.05914\teval-error:0.06804\n",
      "[75]\ttrain-error:0.05929\teval-error:0.06790\n",
      "[76]\ttrain-error:0.05909\teval-error:0.06849\n",
      "[77]\ttrain-error:0.05889\teval-error:0.06849\n",
      "[78]\ttrain-error:0.05870\teval-error:0.06849\n",
      "[79]\ttrain-error:0.05860\teval-error:0.06804\n",
      "[80]\ttrain-error:0.05870\teval-error:0.06849\n",
      "[81]\ttrain-error:0.05884\teval-error:0.06849\n",
      "[82]\ttrain-error:0.05880\teval-error:0.06834\n",
      "[83]\ttrain-error:0.05860\teval-error:0.06864\n",
      "[84]\ttrain-error:0.05830\teval-error:0.06878\n",
      "[85]\ttrain-error:0.05825\teval-error:0.06849\n",
      "[86]\ttrain-error:0.05771\teval-error:0.06878\n",
      "[87]\ttrain-error:0.05766\teval-error:0.06878\n",
      "[88]\ttrain-error:0.05751\teval-error:0.06878\n",
      "[89]\ttrain-error:0.05742\teval-error:0.06937\n",
      "[90]\ttrain-error:0.05742\teval-error:0.06922\n",
      "[91]\ttrain-error:0.05707\teval-error:0.06908\n",
      "[92]\ttrain-error:0.05717\teval-error:0.06893\n",
      "[93]\ttrain-error:0.05707\teval-error:0.06893\n",
      "Stopping. Best iteration:\n",
      "[73]\ttrain-error:0.05934\teval-error:0.06790\n",
      "\n",
      "[22:42:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06854\teval-error:0.07351\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06780\teval-error:0.07321\n",
      "[2]\ttrain-error:0.06814\teval-error:0.07336\n",
      "[3]\ttrain-error:0.06765\teval-error:0.07410\n",
      "[4]\ttrain-error:0.06780\teval-error:0.07424\n",
      "[5]\ttrain-error:0.06839\teval-error:0.07498\n",
      "[6]\ttrain-error:0.06770\teval-error:0.07454\n",
      "[7]\ttrain-error:0.06731\teval-error:0.07439\n",
      "[8]\ttrain-error:0.06701\teval-error:0.07483\n",
      "[9]\ttrain-error:0.06735\teval-error:0.07454\n",
      "[10]\ttrain-error:0.06735\teval-error:0.07424\n",
      "[11]\ttrain-error:0.06706\teval-error:0.07380\n",
      "[12]\ttrain-error:0.06662\teval-error:0.07380\n",
      "[13]\ttrain-error:0.06652\teval-error:0.07380\n",
      "[14]\ttrain-error:0.06652\teval-error:0.07380\n",
      "[15]\ttrain-error:0.06627\teval-error:0.07454\n",
      "[16]\ttrain-error:0.06632\teval-error:0.07424\n",
      "[17]\ttrain-error:0.06617\teval-error:0.07439\n",
      "[18]\ttrain-error:0.06608\teval-error:0.07454\n",
      "[19]\ttrain-error:0.06588\teval-error:0.07424\n",
      "[20]\ttrain-error:0.06568\teval-error:0.07424\n",
      "[21]\ttrain-error:0.06573\teval-error:0.07439\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.06780\teval-error:0.07321\n",
      "\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.3607 - accuracy: 0.8892 - val_loss: 0.2758 - val_accuracy: 0.9256\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2785 - accuracy: 0.9209 - val_loss: 0.2476 - val_accuracy: 0.9256\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2575 - accuracy: 0.9214 - val_loss: 0.2348 - val_accuracy: 0.9283\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2464 - accuracy: 0.9243 - val_loss: 0.2263 - val_accuracy: 0.9305\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2378 - accuracy: 0.9252 - val_loss: 0.2228 - val_accuracy: 0.9317\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2364 - accuracy: 0.9254 - val_loss: 0.2204 - val_accuracy: 0.9320\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2331 - accuracy: 0.9262 - val_loss: 0.2184 - val_accuracy: 0.9323\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2318 - accuracy: 0.9267 - val_loss: 0.2169 - val_accuracy: 0.9325\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2288 - accuracy: 0.9269 - val_loss: 0.2164 - val_accuracy: 0.9323\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2268 - accuracy: 0.9278 - val_loss: 0.2152 - val_accuracy: 0.9321\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2262 - accuracy: 0.9271 - val_loss: 0.2142 - val_accuracy: 0.9324\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2236 - accuracy: 0.9284 - val_loss: 0.2136 - val_accuracy: 0.9324\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2234 - accuracy: 0.9281 - val_loss: 0.2134 - val_accuracy: 0.9327\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2237 - accuracy: 0.9278 - val_loss: 0.2126 - val_accuracy: 0.9327\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2238 - accuracy: 0.9273 - val_loss: 0.2125 - val_accuracy: 0.9327\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2225 - accuracy: 0.9281 - val_loss: 0.2118 - val_accuracy: 0.9330\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2217 - accuracy: 0.9279 - val_loss: 0.2111 - val_accuracy: 0.9333\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2217 - accuracy: 0.9283 - val_loss: 0.2114 - val_accuracy: 0.9331\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2210 - accuracy: 0.9281 - val_loss: 0.2110 - val_accuracy: 0.9333\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2198 - accuracy: 0.9285 - val_loss: 0.2105 - val_accuracy: 0.9333\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2201 - accuracy: 0.9280 - val_loss: 0.2103 - val_accuracy: 0.9331\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2190 - accuracy: 0.9278 - val_loss: 0.2102 - val_accuracy: 0.9331\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2185 - accuracy: 0.9287 - val_loss: 0.2099 - val_accuracy: 0.9333\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2209 - accuracy: 0.9276 - val_loss: 0.2097 - val_accuracy: 0.9334\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2173 - accuracy: 0.9280 - val_loss: 0.2098 - val_accuracy: 0.9334\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2179 - accuracy: 0.9280 - val_loss: 0.2097 - val_accuracy: 0.9333\n",
      "Epoch 27/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2178 - accuracy: 0.9284 - val_loss: 0.2090 - val_accuracy: 0.9330\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2183 - accuracy: 0.9288 - val_loss: 0.2093 - val_accuracy: 0.9334\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2166 - accuracy: 0.9285 - val_loss: 0.2090 - val_accuracy: 0.9336\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2167 - accuracy: 0.9282 - val_loss: 0.2089 - val_accuracy: 0.9337\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2172 - accuracy: 0.9287 - val_loss: 0.2085 - val_accuracy: 0.9334\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2175 - accuracy: 0.9281 - val_loss: 0.2086 - val_accuracy: 0.9339\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2145 - accuracy: 0.9294 - val_loss: 0.2082 - val_accuracy: 0.9337\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2153 - accuracy: 0.9287 - val_loss: 0.2081 - val_accuracy: 0.9340\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2140 - accuracy: 0.9291 - val_loss: 0.2081 - val_accuracy: 0.9337\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2157 - accuracy: 0.9287 - val_loss: 0.2079 - val_accuracy: 0.9343\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2144 - accuracy: 0.9286 - val_loss: 0.2077 - val_accuracy: 0.9340\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2149 - accuracy: 0.9291 - val_loss: 0.2078 - val_accuracy: 0.9339\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2144 - accuracy: 0.9283 - val_loss: 0.2084 - val_accuracy: 0.9342\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2161 - accuracy: 0.9295 - val_loss: 0.2078 - val_accuracy: 0.9345\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2157 - accuracy: 0.9287 - val_loss: 0.2074 - val_accuracy: 0.9339\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2140 - accuracy: 0.9289 - val_loss: 0.2076 - val_accuracy: 0.9343\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2137 - accuracy: 0.9286 - val_loss: 0.2073 - val_accuracy: 0.9342\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2140 - accuracy: 0.9291 - val_loss: 0.2072 - val_accuracy: 0.9346\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2150 - accuracy: 0.9290 - val_loss: 0.2072 - val_accuracy: 0.9343\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2140 - accuracy: 0.9293 - val_loss: 0.2068 - val_accuracy: 0.9340\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2140 - accuracy: 0.9293 - val_loss: 0.2069 - val_accuracy: 0.9345\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2119 - accuracy: 0.9302 - val_loss: 0.2070 - val_accuracy: 0.9345\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2145 - accuracy: 0.9287 - val_loss: 0.2070 - val_accuracy: 0.9346\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2124 - accuracy: 0.9294 - val_loss: 0.2066 - val_accuracy: 0.9345\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2137 - accuracy: 0.9293 - val_loss: 0.2068 - val_accuracy: 0.9345\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2122 - accuracy: 0.9289 - val_loss: 0.2066 - val_accuracy: 0.9346\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2117 - accuracy: 0.9295 - val_loss: 0.2067 - val_accuracy: 0.9345\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2116 - accuracy: 0.9298 - val_loss: 0.2067 - val_accuracy: 0.9345\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2122 - accuracy: 0.9288 - val_loss: 0.2065 - val_accuracy: 0.9345\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.9304 - val_loss: 0.2065 - val_accuracy: 0.9345\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2117 - accuracy: 0.9288 - val_loss: 0.2066 - val_accuracy: 0.9345\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2113 - accuracy: 0.9289 - val_loss: 0.2065 - val_accuracy: 0.9348\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2114 - accuracy: 0.9290 - val_loss: 0.2065 - val_accuracy: 0.9348\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2110 - accuracy: 0.9298 - val_loss: 0.2065 - val_accuracy: 0.9348\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2115 - accuracy: 0.9294 - val_loss: 0.2062 - val_accuracy: 0.9346\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2109 - accuracy: 0.9297 - val_loss: 0.2063 - val_accuracy: 0.9349\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2114 - accuracy: 0.9294 - val_loss: 0.2062 - val_accuracy: 0.9343\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2094 - accuracy: 0.9308 - val_loss: 0.2064 - val_accuracy: 0.9346\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2110 - accuracy: 0.9296 - val_loss: 0.2063 - val_accuracy: 0.9343\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2087 - accuracy: 0.9305 - val_loss: 0.2066 - val_accuracy: 0.9345\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2113 - accuracy: 0.9286 - val_loss: 0.2064 - val_accuracy: 0.9345\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9308 - val_loss: 0.2062 - val_accuracy: 0.9345\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9305 - val_loss: 0.2062 - val_accuracy: 0.9346\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9292 - val_loss: 0.2061 - val_accuracy: 0.9343\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9291 - val_loss: 0.2060 - val_accuracy: 0.9343\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9295 - val_loss: 0.2062 - val_accuracy: 0.9348\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2102 - accuracy: 0.9291 - val_loss: 0.2064 - val_accuracy: 0.9345\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2087 - accuracy: 0.9300 - val_loss: 0.2061 - val_accuracy: 0.9349\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2100 - accuracy: 0.9305 - val_loss: 0.2059 - val_accuracy: 0.9343\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2093 - accuracy: 0.9298 - val_loss: 0.2057 - val_accuracy: 0.9343\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2083 - accuracy: 0.9306 - val_loss: 0.2061 - val_accuracy: 0.9348\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2097 - accuracy: 0.9295 - val_loss: 0.2059 - val_accuracy: 0.9349\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2088 - accuracy: 0.9310 - val_loss: 0.2058 - val_accuracy: 0.9349\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9300 - val_loss: 0.2061 - val_accuracy: 0.9351\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9297 - val_loss: 0.2059 - val_accuracy: 0.9349\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9297 - val_loss: 0.2057 - val_accuracy: 0.9349\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2088 - accuracy: 0.9292 - val_loss: 0.2059 - val_accuracy: 0.9348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9299 - val_loss: 0.2058 - val_accuracy: 0.9348\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9301 - val_loss: 0.2058 - val_accuracy: 0.9348\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9301 - val_loss: 0.2057 - val_accuracy: 0.9351\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9301 - val_loss: 0.2054 - val_accuracy: 0.9345\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9300 - val_loss: 0.2056 - val_accuracy: 0.9346\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9304 - val_loss: 0.2058 - val_accuracy: 0.9352\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9299 - val_loss: 0.2055 - val_accuracy: 0.9349\n",
      "Epoch 91/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9303 - val_loss: 0.2056 - val_accuracy: 0.9351\n",
      "Epoch 92/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2087 - accuracy: 0.9303 - val_loss: 0.2056 - val_accuracy: 0.9349\n",
      "Epoch 93/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9297 - val_loss: 0.2055 - val_accuracy: 0.9345\n",
      "Epoch 94/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2081 - accuracy: 0.9300 - val_loss: 0.2053 - val_accuracy: 0.9346\n",
      "Epoch 95/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9302 - val_loss: 0.2059 - val_accuracy: 0.9354\n",
      "Epoch 96/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2055 - accuracy: 0.9302 - val_loss: 0.2055 - val_accuracy: 0.9351\n",
      "Epoch 97/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9299 - val_loss: 0.2054 - val_accuracy: 0.9349\n",
      "Epoch 98/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2064 - accuracy: 0.9300 - val_loss: 0.2055 - val_accuracy: 0.9346\n",
      "Epoch 99/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2055 - accuracy: 0.9298 - val_loss: 0.2054 - val_accuracy: 0.9346\n",
      "Epoch 100/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2076 - accuracy: 0.9298 - val_loss: 0.2054 - val_accuracy: 0.9351\n",
      "Epoch 101/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9315 - val_loss: 0.2055 - val_accuracy: 0.9349\n",
      "Epoch 102/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9311 - val_loss: 0.2053 - val_accuracy: 0.9348\n",
      "Epoch 103/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2064 - accuracy: 0.9302 - val_loss: 0.2055 - val_accuracy: 0.9351\n",
      "Epoch 104/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9302 - val_loss: 0.2056 - val_accuracy: 0.9352\n",
      "Epoch 105/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9314 - val_loss: 0.2055 - val_accuracy: 0.9351\n",
      "Epoch 106/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9301 - val_loss: 0.2052 - val_accuracy: 0.9351\n",
      "Epoch 107/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9297 - val_loss: 0.2055 - val_accuracy: 0.9348\n",
      "Epoch 108/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9312 - val_loss: 0.2052 - val_accuracy: 0.9351\n",
      "Epoch 109/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9303 - val_loss: 0.2054 - val_accuracy: 0.9349\n",
      "Epoch 110/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9302 - val_loss: 0.2053 - val_accuracy: 0.9351\n",
      "Epoch 111/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9306 - val_loss: 0.2053 - val_accuracy: 0.9349\n",
      "Epoch 112/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9301 - val_loss: 0.2055 - val_accuracy: 0.9349\n",
      "Epoch 113/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2041 - accuracy: 0.9318 - val_loss: 0.2053 - val_accuracy: 0.9349\n",
      "Epoch 114/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9298 - val_loss: 0.2056 - val_accuracy: 0.9351\n",
      "Epoch 115/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9299 - val_loss: 0.2054 - val_accuracy: 0.9351\n",
      "Epoch 116/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9304 - val_loss: 0.2054 - val_accuracy: 0.9352\n",
      "Epoch 117/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9310 - val_loss: 0.2058 - val_accuracy: 0.9352\n",
      "Epoch 118/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9299 - val_loss: 0.2053 - val_accuracy: 0.9348\n",
      "Epoch 119/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2041 - accuracy: 0.9318 - val_loss: 0.2053 - val_accuracy: 0.9351\n",
      "Epoch 120/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9310 - val_loss: 0.2053 - val_accuracy: 0.9346\n",
      "Epoch 121/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9313 - val_loss: 0.2052 - val_accuracy: 0.9351\n",
      "Epoch 122/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9310 - val_loss: 0.2053 - val_accuracy: 0.9354\n",
      "Epoch 123/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9309 - val_loss: 0.2054 - val_accuracy: 0.9348\n",
      "Epoch 124/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9306 - val_loss: 0.2053 - val_accuracy: 0.9354\n",
      "Epoch 125/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2033 - accuracy: 0.9308 - val_loss: 0.2052 - val_accuracy: 0.9351\n",
      "Epoch 126/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9313 - val_loss: 0.2054 - val_accuracy: 0.9351\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.3548 - accuracy: 0.8920 - val_loss: 0.2863 - val_accuracy: 0.9221\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2725 - accuracy: 0.9222 - val_loss: 0.2531 - val_accuracy: 0.9222\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2492 - accuracy: 0.9243 - val_loss: 0.2366 - val_accuracy: 0.9253\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2408 - accuracy: 0.9259 - val_loss: 0.2293 - val_accuracy: 0.9269\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2343 - accuracy: 0.9270 - val_loss: 0.2254 - val_accuracy: 0.9278\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2292 - accuracy: 0.9266 - val_loss: 0.2230 - val_accuracy: 0.9294\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2283 - accuracy: 0.9280 - val_loss: 0.2215 - val_accuracy: 0.9299\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2258 - accuracy: 0.9280 - val_loss: 0.2206 - val_accuracy: 0.9294\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2243 - accuracy: 0.9287 - val_loss: 0.2199 - val_accuracy: 0.9299\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2231 - accuracy: 0.9289 - val_loss: 0.2193 - val_accuracy: 0.9297\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2228 - accuracy: 0.9282 - val_loss: 0.2185 - val_accuracy: 0.9300\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2229 - accuracy: 0.9280 - val_loss: 0.2183 - val_accuracy: 0.9302\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2221 - accuracy: 0.9289 - val_loss: 0.2180 - val_accuracy: 0.9299\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2221 - accuracy: 0.9295 - val_loss: 0.2176 - val_accuracy: 0.9296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2211 - accuracy: 0.9286 - val_loss: 0.2175 - val_accuracy: 0.9299\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2205 - accuracy: 0.9285 - val_loss: 0.2173 - val_accuracy: 0.9299\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2186 - accuracy: 0.9294 - val_loss: 0.2170 - val_accuracy: 0.9299\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2192 - accuracy: 0.9295 - val_loss: 0.2168 - val_accuracy: 0.9300\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2174 - accuracy: 0.9290 - val_loss: 0.2167 - val_accuracy: 0.9300\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2167 - accuracy: 0.9292 - val_loss: 0.2166 - val_accuracy: 0.9303\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2182 - accuracy: 0.9299 - val_loss: 0.2163 - val_accuracy: 0.9302\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2170 - accuracy: 0.9290 - val_loss: 0.2161 - val_accuracy: 0.9303\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2164 - accuracy: 0.9296 - val_loss: 0.2161 - val_accuracy: 0.9302\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2165 - accuracy: 0.9294 - val_loss: 0.2160 - val_accuracy: 0.9300\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2148 - accuracy: 0.9296 - val_loss: 0.2157 - val_accuracy: 0.9305\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2168 - accuracy: 0.9297 - val_loss: 0.2157 - val_accuracy: 0.9305\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2152 - accuracy: 0.9304 - val_loss: 0.2156 - val_accuracy: 0.9303\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2163 - accuracy: 0.9292 - val_loss: 0.2153 - val_accuracy: 0.9303\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2131 - accuracy: 0.9296 - val_loss: 0.2153 - val_accuracy: 0.9302\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2144 - accuracy: 0.9293 - val_loss: 0.2152 - val_accuracy: 0.9305\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2156 - accuracy: 0.9300 - val_loss: 0.2151 - val_accuracy: 0.9306\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2148 - accuracy: 0.9301 - val_loss: 0.2151 - val_accuracy: 0.9302\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2122 - accuracy: 0.9301 - val_loss: 0.2151 - val_accuracy: 0.9303\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2141 - accuracy: 0.9294 - val_loss: 0.2150 - val_accuracy: 0.9300\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2108 - accuracy: 0.9310 - val_loss: 0.2149 - val_accuracy: 0.9303\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2141 - accuracy: 0.9298 - val_loss: 0.2148 - val_accuracy: 0.9303\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2136 - accuracy: 0.9293 - val_loss: 0.2148 - val_accuracy: 0.9305\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2128 - accuracy: 0.9305 - val_loss: 0.2148 - val_accuracy: 0.9305\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2116 - accuracy: 0.9302 - val_loss: 0.2148 - val_accuracy: 0.9309\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2120 - accuracy: 0.9307 - val_loss: 0.2145 - val_accuracy: 0.9303\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2128 - accuracy: 0.9307 - val_loss: 0.2145 - val_accuracy: 0.9302\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2114 - accuracy: 0.9304 - val_loss: 0.2145 - val_accuracy: 0.9306\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9304 - val_loss: 0.2144 - val_accuracy: 0.9306\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2104 - accuracy: 0.9308 - val_loss: 0.2143 - val_accuracy: 0.9306\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9298 - val_loss: 0.2142 - val_accuracy: 0.9303\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2108 - accuracy: 0.9307 - val_loss: 0.2141 - val_accuracy: 0.9305\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2115 - accuracy: 0.9311 - val_loss: 0.2142 - val_accuracy: 0.9302\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2109 - accuracy: 0.9309 - val_loss: 0.2142 - val_accuracy: 0.9302\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2109 - accuracy: 0.9316 - val_loss: 0.2141 - val_accuracy: 0.9306\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2115 - accuracy: 0.9308 - val_loss: 0.2140 - val_accuracy: 0.9305\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2098 - accuracy: 0.9311 - val_loss: 0.2143 - val_accuracy: 0.9305\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2094 - accuracy: 0.9312 - val_loss: 0.2141 - val_accuracy: 0.9308\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2099 - accuracy: 0.9306 - val_loss: 0.2140 - val_accuracy: 0.9302\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9316 - val_loss: 0.2137 - val_accuracy: 0.9299\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9316 - val_loss: 0.2137 - val_accuracy: 0.9297\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9312 - val_loss: 0.2137 - val_accuracy: 0.9300\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9308 - val_loss: 0.2137 - val_accuracy: 0.9302\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2100 - accuracy: 0.9312 - val_loss: 0.2137 - val_accuracy: 0.9297\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2095 - accuracy: 0.9311 - val_loss: 0.2136 - val_accuracy: 0.9299\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9308 - val_loss: 0.2136 - val_accuracy: 0.9299\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2088 - accuracy: 0.9320 - val_loss: 0.2135 - val_accuracy: 0.9299\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2097 - accuracy: 0.9306 - val_loss: 0.2134 - val_accuracy: 0.9299\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9318 - val_loss: 0.2134 - val_accuracy: 0.9299\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9315 - val_loss: 0.2134 - val_accuracy: 0.9299\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2072 - accuracy: 0.9310 - val_loss: 0.2134 - val_accuracy: 0.9299\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9316 - val_loss: 0.2134 - val_accuracy: 0.9299\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2080 - accuracy: 0.9317 - val_loss: 0.2134 - val_accuracy: 0.9300\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9309 - val_loss: 0.2134 - val_accuracy: 0.9299\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9323 - val_loss: 0.2134 - val_accuracy: 0.9297\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9311 - val_loss: 0.2135 - val_accuracy: 0.9302\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9313 - val_loss: 0.2135 - val_accuracy: 0.9302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9307 - val_loss: 0.2135 - val_accuracy: 0.9300\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9313 - val_loss: 0.2136 - val_accuracy: 0.9296\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2086 - accuracy: 0.9307 - val_loss: 0.2136 - val_accuracy: 0.9296\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2075 - accuracy: 0.9309 - val_loss: 0.2136 - val_accuracy: 0.9296\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9314 - val_loss: 0.2135 - val_accuracy: 0.9296\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9319 - val_loss: 0.2136 - val_accuracy: 0.9294\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9323 - val_loss: 0.2135 - val_accuracy: 0.9296\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9318 - val_loss: 0.2135 - val_accuracy: 0.9296\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9310 - val_loss: 0.2134 - val_accuracy: 0.9293\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2064 - accuracy: 0.9319 - val_loss: 0.2133 - val_accuracy: 0.9297\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2061 - accuracy: 0.9315 - val_loss: 0.2133 - val_accuracy: 0.9299\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2048 - accuracy: 0.9318 - val_loss: 0.2133 - val_accuracy: 0.9296\n",
      "Epoch 84/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9300 - val_loss: 0.2134 - val_accuracy: 0.9294\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9311 - val_loss: 0.2133 - val_accuracy: 0.9297\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9310 - val_loss: 0.2132 - val_accuracy: 0.9297\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2041 - accuracy: 0.9319 - val_loss: 0.2134 - val_accuracy: 0.9299\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9319 - val_loss: 0.2134 - val_accuracy: 0.9299\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2026 - accuracy: 0.9323 - val_loss: 0.2133 - val_accuracy: 0.9293\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9321 - val_loss: 0.2134 - val_accuracy: 0.9299\n",
      "Epoch 91/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9314 - val_loss: 0.2134 - val_accuracy: 0.9299\n",
      "Epoch 92/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9323 - val_loss: 0.2133 - val_accuracy: 0.9297\n",
      "Epoch 93/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9323 - val_loss: 0.2133 - val_accuracy: 0.9296\n",
      "Epoch 94/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9323 - val_loss: 0.2132 - val_accuracy: 0.9297\n",
      "Epoch 95/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9328 - val_loss: 0.2131 - val_accuracy: 0.9300\n",
      "Epoch 96/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9323 - val_loss: 0.2131 - val_accuracy: 0.9297\n",
      "Epoch 97/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9316 - val_loss: 0.2131 - val_accuracy: 0.9294\n",
      "Epoch 98/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9321 - val_loss: 0.2132 - val_accuracy: 0.9294\n",
      "Epoch 99/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9316 - val_loss: 0.2133 - val_accuracy: 0.9292\n",
      "Epoch 100/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2019 - accuracy: 0.9320 - val_loss: 0.2135 - val_accuracy: 0.9294\n",
      "Epoch 101/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9317 - val_loss: 0.2135 - val_accuracy: 0.9292\n",
      "Epoch 102/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2033 - accuracy: 0.9330 - val_loss: 0.2136 - val_accuracy: 0.9296\n",
      "Epoch 103/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9318 - val_loss: 0.2135 - val_accuracy: 0.9296\n",
      "Epoch 104/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9318 - val_loss: 0.2134 - val_accuracy: 0.9296\n",
      "Epoch 105/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2019 - accuracy: 0.9331 - val_loss: 0.2134 - val_accuracy: 0.9297\n",
      "Epoch 106/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2013 - accuracy: 0.9329 - val_loss: 0.2133 - val_accuracy: 0.9293\n",
      "Epoch 107/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2036 - accuracy: 0.9305 - val_loss: 0.2134 - val_accuracy: 0.9294\n",
      "Epoch 108/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9318 - val_loss: 0.2134 - val_accuracy: 0.9290\n",
      "Epoch 109/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9328 - val_loss: 0.2133 - val_accuracy: 0.9294\n",
      "Epoch 110/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9315 - val_loss: 0.2133 - val_accuracy: 0.9294\n",
      "Epoch 111/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2019 - accuracy: 0.9318 - val_loss: 0.2133 - val_accuracy: 0.9293\n",
      "Epoch 112/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2031 - accuracy: 0.9316 - val_loss: 0.2134 - val_accuracy: 0.9292\n",
      "Epoch 113/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9321 - val_loss: 0.2133 - val_accuracy: 0.9293\n",
      "Epoch 114/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2010 - accuracy: 0.9323 - val_loss: 0.2134 - val_accuracy: 0.9297\n",
      "Epoch 115/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2017 - accuracy: 0.9325 - val_loss: 0.2134 - val_accuracy: 0.9290\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3649 - accuracy: 0.9118 - val_loss: 0.2942 - val_accuracy: 0.9221\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2796 - accuracy: 0.9221 - val_loss: 0.2596 - val_accuracy: 0.9221\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2563 - accuracy: 0.9224 - val_loss: 0.2438 - val_accuracy: 0.9240\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2437 - accuracy: 0.9234 - val_loss: 0.2347 - val_accuracy: 0.9269\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2385 - accuracy: 0.9259 - val_loss: 0.2298 - val_accuracy: 0.9277\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2325 - accuracy: 0.9279 - val_loss: 0.2266 - val_accuracy: 0.9287\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2309 - accuracy: 0.9271 - val_loss: 0.2245 - val_accuracy: 0.9284\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2269 - accuracy: 0.9283 - val_loss: 0.2229 - val_accuracy: 0.9289\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2261 - accuracy: 0.9281 - val_loss: 0.2222 - val_accuracy: 0.9289\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2240 - accuracy: 0.9282 - val_loss: 0.2207 - val_accuracy: 0.9294\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2240 - accuracy: 0.9283 - val_loss: 0.2201 - val_accuracy: 0.9292\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2216 - accuracy: 0.9290 - val_loss: 0.2193 - val_accuracy: 0.9292\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2225 - accuracy: 0.9286 - val_loss: 0.2189 - val_accuracy: 0.9296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2211 - accuracy: 0.9292 - val_loss: 0.2190 - val_accuracy: 0.9290\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2214 - accuracy: 0.9292 - val_loss: 0.2180 - val_accuracy: 0.9293\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2202 - accuracy: 0.9296 - val_loss: 0.2176 - val_accuracy: 0.9297\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2191 - accuracy: 0.9295 - val_loss: 0.2177 - val_accuracy: 0.9293\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2177 - accuracy: 0.9295 - val_loss: 0.2173 - val_accuracy: 0.9297\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2180 - accuracy: 0.9297 - val_loss: 0.2167 - val_accuracy: 0.9300\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2178 - accuracy: 0.9283 - val_loss: 0.2166 - val_accuracy: 0.9302\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2170 - accuracy: 0.9298 - val_loss: 0.2168 - val_accuracy: 0.9289\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2173 - accuracy: 0.9296 - val_loss: 0.2164 - val_accuracy: 0.9296\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2171 - accuracy: 0.9291 - val_loss: 0.2163 - val_accuracy: 0.9299\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2165 - accuracy: 0.9297 - val_loss: 0.2163 - val_accuracy: 0.9297\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2170 - accuracy: 0.9302 - val_loss: 0.2160 - val_accuracy: 0.9300\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2158 - accuracy: 0.9291 - val_loss: 0.2159 - val_accuracy: 0.9302\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2146 - accuracy: 0.9300 - val_loss: 0.2157 - val_accuracy: 0.9303\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2146 - accuracy: 0.9296 - val_loss: 0.2157 - val_accuracy: 0.9299\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2156 - accuracy: 0.9299 - val_loss: 0.2155 - val_accuracy: 0.9305\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2127 - accuracy: 0.9293 - val_loss: 0.2155 - val_accuracy: 0.9303\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2126 - accuracy: 0.9300 - val_loss: 0.2153 - val_accuracy: 0.9303\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2127 - accuracy: 0.9297 - val_loss: 0.2152 - val_accuracy: 0.9302\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2142 - accuracy: 0.9293 - val_loss: 0.2152 - val_accuracy: 0.9300\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.9299 - val_loss: 0.2151 - val_accuracy: 0.9302\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2133 - accuracy: 0.9303 - val_loss: 0.2155 - val_accuracy: 0.9296\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2119 - accuracy: 0.9300 - val_loss: 0.2151 - val_accuracy: 0.9303\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2125 - accuracy: 0.9307 - val_loss: 0.2150 - val_accuracy: 0.9300\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2127 - accuracy: 0.9302 - val_loss: 0.2150 - val_accuracy: 0.9299\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2116 - accuracy: 0.9310 - val_loss: 0.2147 - val_accuracy: 0.9300\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2114 - accuracy: 0.9298 - val_loss: 0.2152 - val_accuracy: 0.9300\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2108 - accuracy: 0.9297 - val_loss: 0.2146 - val_accuracy: 0.9303\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2098 - accuracy: 0.9304 - val_loss: 0.2146 - val_accuracy: 0.9303\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2106 - accuracy: 0.9313 - val_loss: 0.2145 - val_accuracy: 0.9302\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2108 - accuracy: 0.9294 - val_loss: 0.2148 - val_accuracy: 0.9306\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9306 - val_loss: 0.2147 - val_accuracy: 0.9302\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.9309 - val_loss: 0.2147 - val_accuracy: 0.9297\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9297 - val_loss: 0.2142 - val_accuracy: 0.9303\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2100 - accuracy: 0.9312 - val_loss: 0.2143 - val_accuracy: 0.9300\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2116 - accuracy: 0.9304 - val_loss: 0.2143 - val_accuracy: 0.9305\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9310 - val_loss: 0.2143 - val_accuracy: 0.9303\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9310 - val_loss: 0.2143 - val_accuracy: 0.9302\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9307 - val_loss: 0.2147 - val_accuracy: 0.9305\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2104 - accuracy: 0.9297 - val_loss: 0.2144 - val_accuracy: 0.9303\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2103 - accuracy: 0.9305 - val_loss: 0.2144 - val_accuracy: 0.9302\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9307 - val_loss: 0.2145 - val_accuracy: 0.9305\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9304 - val_loss: 0.2144 - val_accuracy: 0.9305\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9309 - val_loss: 0.2145 - val_accuracy: 0.9306\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9300 - val_loss: 0.2144 - val_accuracy: 0.9306\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9303 - val_loss: 0.2142 - val_accuracy: 0.9305\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9303 - val_loss: 0.2144 - val_accuracy: 0.9308\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9311 - val_loss: 0.2142 - val_accuracy: 0.9303\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9312 - val_loss: 0.2142 - val_accuracy: 0.9308\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9305 - val_loss: 0.2142 - val_accuracy: 0.9305\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9308 - val_loss: 0.2143 - val_accuracy: 0.9303\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9307 - val_loss: 0.2143 - val_accuracy: 0.9306\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9309 - val_loss: 0.2142 - val_accuracy: 0.9305\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9311 - val_loss: 0.2142 - val_accuracy: 0.9306\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9310 - val_loss: 0.2143 - val_accuracy: 0.9306\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9308 - val_loss: 0.2142 - val_accuracy: 0.9308\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9312 - val_loss: 0.2144 - val_accuracy: 0.9305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9310 - val_loss: 0.2143 - val_accuracy: 0.9305\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9311 - val_loss: 0.2142 - val_accuracy: 0.9309\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9308 - val_loss: 0.2144 - val_accuracy: 0.9308\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9313 - val_loss: 0.2143 - val_accuracy: 0.9308\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9316 - val_loss: 0.2143 - val_accuracy: 0.9306\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9304 - val_loss: 0.2144 - val_accuracy: 0.9305\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9313 - val_loss: 0.2144 - val_accuracy: 0.9306\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9303 - val_loss: 0.2144 - val_accuracy: 0.9300\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9319 - val_loss: 0.2145 - val_accuracy: 0.9306\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9303 - val_loss: 0.2143 - val_accuracy: 0.9302\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9309 - val_loss: 0.2144 - val_accuracy: 0.9300\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9316 - val_loss: 0.2145 - val_accuracy: 0.9305\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2055 - accuracy: 0.9316 - val_loss: 0.2145 - val_accuracy: 0.9306\n",
      "Epoch 84/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9304 - val_loss: 0.2147 - val_accuracy: 0.9303\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9303 - val_loss: 0.2147 - val_accuracy: 0.9305\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9314 - val_loss: 0.2150 - val_accuracy: 0.9300\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9311 - val_loss: 0.2146 - val_accuracy: 0.9303\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3483 - accuracy: 0.9062 - val_loss: 0.2927 - val_accuracy: 0.9185\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2736 - accuracy: 0.9234 - val_loss: 0.2573 - val_accuracy: 0.9188\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2501 - accuracy: 0.9249 - val_loss: 0.2408 - val_accuracy: 0.9225\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2387 - accuracy: 0.9274 - val_loss: 0.2330 - val_accuracy: 0.9246\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2334 - accuracy: 0.9282 - val_loss: 0.2290 - val_accuracy: 0.9250\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2302 - accuracy: 0.9292 - val_loss: 0.2268 - val_accuracy: 0.9249\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2282 - accuracy: 0.9281 - val_loss: 0.2255 - val_accuracy: 0.9259\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2270 - accuracy: 0.9278 - val_loss: 0.2239 - val_accuracy: 0.9262\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2264 - accuracy: 0.9284 - val_loss: 0.2229 - val_accuracy: 0.9262\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2236 - accuracy: 0.9299 - val_loss: 0.2220 - val_accuracy: 0.9268\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2214 - accuracy: 0.9303 - val_loss: 0.2212 - val_accuracy: 0.9271\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2215 - accuracy: 0.9299 - val_loss: 0.2206 - val_accuracy: 0.9274\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2193 - accuracy: 0.9297 - val_loss: 0.2200 - val_accuracy: 0.9271\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2210 - accuracy: 0.9304 - val_loss: 0.2197 - val_accuracy: 0.9271\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2191 - accuracy: 0.9296 - val_loss: 0.2193 - val_accuracy: 0.9272\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2202 - accuracy: 0.9299 - val_loss: 0.2193 - val_accuracy: 0.9265\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2188 - accuracy: 0.9299 - val_loss: 0.2186 - val_accuracy: 0.9271\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2194 - accuracy: 0.9292 - val_loss: 0.2186 - val_accuracy: 0.9271\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2172 - accuracy: 0.9305 - val_loss: 0.2180 - val_accuracy: 0.9274\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2159 - accuracy: 0.9303 - val_loss: 0.2177 - val_accuracy: 0.9272\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2162 - accuracy: 0.9301 - val_loss: 0.2177 - val_accuracy: 0.9269\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2170 - accuracy: 0.9297 - val_loss: 0.2174 - val_accuracy: 0.9272\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2153 - accuracy: 0.9309 - val_loss: 0.2174 - val_accuracy: 0.9274\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2154 - accuracy: 0.9310 - val_loss: 0.2170 - val_accuracy: 0.9277\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2143 - accuracy: 0.9307 - val_loss: 0.2169 - val_accuracy: 0.9274\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2152 - accuracy: 0.9291 - val_loss: 0.2168 - val_accuracy: 0.9269\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2147 - accuracy: 0.9311 - val_loss: 0.2165 - val_accuracy: 0.9272\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2141 - accuracy: 0.9305 - val_loss: 0.2164 - val_accuracy: 0.9271\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2127 - accuracy: 0.9301 - val_loss: 0.2163 - val_accuracy: 0.9272\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2126 - accuracy: 0.9313 - val_loss: 0.2161 - val_accuracy: 0.9274\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2127 - accuracy: 0.9313 - val_loss: 0.2161 - val_accuracy: 0.9272\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2139 - accuracy: 0.9313 - val_loss: 0.2159 - val_accuracy: 0.9275\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2127 - accuracy: 0.9307 - val_loss: 0.2159 - val_accuracy: 0.9268\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2122 - accuracy: 0.9303 - val_loss: 0.2157 - val_accuracy: 0.9272\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2124 - accuracy: 0.9316 - val_loss: 0.2155 - val_accuracy: 0.9271\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2113 - accuracy: 0.9302 - val_loss: 0.2154 - val_accuracy: 0.9272\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2108 - accuracy: 0.9319 - val_loss: 0.2152 - val_accuracy: 0.9272\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2117 - accuracy: 0.9306 - val_loss: 0.2152 - val_accuracy: 0.9272\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2113 - accuracy: 0.9300 - val_loss: 0.2151 - val_accuracy: 0.9271\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9305 - val_loss: 0.2150 - val_accuracy: 0.9272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9312 - val_loss: 0.2150 - val_accuracy: 0.9277\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2104 - accuracy: 0.9306 - val_loss: 0.2150 - val_accuracy: 0.9275\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2118 - accuracy: 0.9309 - val_loss: 0.2149 - val_accuracy: 0.9275\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2123 - accuracy: 0.9306 - val_loss: 0.2149 - val_accuracy: 0.9277\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2099 - accuracy: 0.9305 - val_loss: 0.2147 - val_accuracy: 0.9277\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9315 - val_loss: 0.2146 - val_accuracy: 0.9274\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2109 - accuracy: 0.9309 - val_loss: 0.2145 - val_accuracy: 0.9275\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9319 - val_loss: 0.2145 - val_accuracy: 0.9272\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9324 - val_loss: 0.2144 - val_accuracy: 0.9271\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2101 - accuracy: 0.9312 - val_loss: 0.2143 - val_accuracy: 0.9272\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2100 - accuracy: 0.9321 - val_loss: 0.2142 - val_accuracy: 0.9277\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9312 - val_loss: 0.2143 - val_accuracy: 0.9277\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9318 - val_loss: 0.2141 - val_accuracy: 0.9278\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9314 - val_loss: 0.2141 - val_accuracy: 0.9272\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9320 - val_loss: 0.2141 - val_accuracy: 0.9272\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9313 - val_loss: 0.2141 - val_accuracy: 0.9271\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9311 - val_loss: 0.2139 - val_accuracy: 0.9277\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2084 - accuracy: 0.9302 - val_loss: 0.2139 - val_accuracy: 0.9278\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2082 - accuracy: 0.9308 - val_loss: 0.2139 - val_accuracy: 0.9278\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9313 - val_loss: 0.2139 - val_accuracy: 0.9277\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9316 - val_loss: 0.2139 - val_accuracy: 0.9271\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9320 - val_loss: 0.2139 - val_accuracy: 0.9274\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9321 - val_loss: 0.2139 - val_accuracy: 0.9275\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9322 - val_loss: 0.2138 - val_accuracy: 0.9272\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9310 - val_loss: 0.2139 - val_accuracy: 0.9275\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9320 - val_loss: 0.2138 - val_accuracy: 0.9272\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9319 - val_loss: 0.2139 - val_accuracy: 0.9275\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9314 - val_loss: 0.2138 - val_accuracy: 0.9277\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9317 - val_loss: 0.2137 - val_accuracy: 0.9278\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9323 - val_loss: 0.2137 - val_accuracy: 0.9275\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9321 - val_loss: 0.2138 - val_accuracy: 0.9274\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9321 - val_loss: 0.2137 - val_accuracy: 0.9275\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9321 - val_loss: 0.2137 - val_accuracy: 0.9274\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9327 - val_loss: 0.2137 - val_accuracy: 0.9274\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9317 - val_loss: 0.2137 - val_accuracy: 0.9275\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9319 - val_loss: 0.2137 - val_accuracy: 0.9277\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9319 - val_loss: 0.2137 - val_accuracy: 0.9277\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9316 - val_loss: 0.2135 - val_accuracy: 0.9280\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9320 - val_loss: 0.2136 - val_accuracy: 0.9283\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9325 - val_loss: 0.2136 - val_accuracy: 0.9284\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9331 - val_loss: 0.2137 - val_accuracy: 0.9280\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9325 - val_loss: 0.2136 - val_accuracy: 0.9286\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2036 - accuracy: 0.9320 - val_loss: 0.2136 - val_accuracy: 0.9283\n",
      "Epoch 84/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9328 - val_loss: 0.2137 - val_accuracy: 0.9277\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2045 - accuracy: 0.9330 - val_loss: 0.2136 - val_accuracy: 0.9278\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2054 - accuracy: 0.9317 - val_loss: 0.2136 - val_accuracy: 0.9284\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9326 - val_loss: 0.2136 - val_accuracy: 0.9283\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9320 - val_loss: 0.2137 - val_accuracy: 0.9281\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9327 - val_loss: 0.2136 - val_accuracy: 0.9280\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2041 - accuracy: 0.9325 - val_loss: 0.2137 - val_accuracy: 0.9281\n",
      "Epoch 91/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9316 - val_loss: 0.2138 - val_accuracy: 0.9278\n",
      "Epoch 92/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9315 - val_loss: 0.2136 - val_accuracy: 0.9286\n",
      "Epoch 93/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9332 - val_loss: 0.2136 - val_accuracy: 0.9284\n",
      "Epoch 94/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9325 - val_loss: 0.2137 - val_accuracy: 0.9284\n",
      "Epoch 95/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9323 - val_loss: 0.2137 - val_accuracy: 0.9286\n",
      "Epoch 96/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2040 - accuracy: 0.9324 - val_loss: 0.2137 - val_accuracy: 0.9281\n",
      "Epoch 97/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9323 - val_loss: 0.2137 - val_accuracy: 0.9283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9324 - val_loss: 0.2138 - val_accuracy: 0.9284\n",
      "logloss: 0.2068\n",
      "logloss: 0.2122\n",
      "logloss: 0.2492\n",
      "logloss: 0.2129\n",
      "logloss: 0.2115\n"
     ]
    }
   ],
   "source": [
    "# 1層目のモデル\n",
    "# pred_train_1a, pred_train_1bは、学習データのクロスバリデーションでの予測値\n",
    "# pred_test_1a, pred_test_1bは、テストデータの予測値\n",
    "model_1a = Model1xgb()\n",
    "pred_train_1a, pred_test_1a = predict_cv(model_1a, train_x, train_y, test_x)\n",
    "\n",
    "model_1b = Model1NN()\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_1b, train_x_nn, train_y, test_x_nn)\n",
    "\n",
    "\n",
    "model_1c = Model1ramdom()\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_1c, train_x, train_y, test_x)\n",
    "\n",
    "\n",
    "model_1d = Model1xgb2()\n",
    "pred_train_1d, pred_test_1d = predict_cv(model_1d, train_x, train_y, test_x)\n",
    "\n",
    "model_1e = Model1NN2()\n",
    "pred_train_1e, pred_test_1e = predict_cv(model_1e, train_x_nn, train_y, test_x_nn)\n",
    "\n",
    "\n",
    "# 1層目のモデルの評価\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1a, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1b, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1c, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1d, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1e, eps=1e-7):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測値を特徴量としてデータフレームを作成\n",
    "train_x_2 = pd.DataFrame({'pred_1a': pred_train_1a, 'pred_1b': pred_train_1b, 'pred_1c':pred_train_1c,'pred_1d':pred_train_1d, 'pred_1e':pred_train_1e})\n",
    "test_x_2 = pd.DataFrame({'pred_1a': pred_test_1a, 'pred_1b': pred_test_1b, 'pred_1c': pred_test_1c,'pred_1d':pred_test_1d, 'pred_1e':pred_test_1e})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_2.to_csv('train_x_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_2.to_csv('test_x_2.csv', index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.2083\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model3logistic()\n",
    "pred_train_2, pred_test_2 = predict_cv(model_2, train_x_2, train_y, test_x_2)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(train_y,pred_train_2)\n",
    "auc_score = roc_auc_score(train_y,pred_train_2)\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC curve/AUC Score : {auc_score}')\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18050"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.804121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18045</th>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18046</th>\n",
       "      <td>0.006510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18047</th>\n",
       "      <td>0.087581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18048</th>\n",
       "      <td>0.011804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18049</th>\n",
       "      <td>0.102301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18050 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0      0.804121\n",
       "1      0.064889\n",
       "2      0.032542\n",
       "3      0.003470\n",
       "4      0.062356\n",
       "...         ...\n",
       "18045  0.013428\n",
       "18046  0.006510\n",
       "18047  0.087581\n",
       "18048  0.011804\n",
       "18049  0.102301\n",
       "\n",
       "[18050 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.DataFrame(pred_test_2)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.804121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.064889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.032542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.003470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.062356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18045</th>\n",
       "      <td>18045</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18046</th>\n",
       "      <td>18046</td>\n",
       "      <td>0.006510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18047</th>\n",
       "      <td>18047</td>\n",
       "      <td>0.087581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18048</th>\n",
       "      <td>18048</td>\n",
       "      <td>0.011804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18049</th>\n",
       "      <td>18049</td>\n",
       "      <td>0.102301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18050 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         y\n",
       "0          0  0.804121\n",
       "1          1  0.064889\n",
       "2          2  0.032542\n",
       "3          3  0.003470\n",
       "4          4  0.062356\n",
       "...      ...       ...\n",
       "18045  18045  0.013428\n",
       "18046  18046  0.006510\n",
       "18047  18047  0.087581\n",
       "18048  18048  0.011804\n",
       "18049  18049  0.102301\n",
       "\n",
       "[18050 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\test.csv')\n",
    "id = test['id']\n",
    "pred = pd.DataFrame(pred_test_2)\n",
    "submit = pd.concat([id,pred], axis=1)\n",
    "submit.columns = ['id', 'y']\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('stack1.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python37164bit745322e800af484d9e7663a15d4e0767"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
