{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso,Ridge\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers.advanced_activations import ReLU, PReLU\n",
    "from keras.optimizers import SGD, Adam\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\dataset\\\\train_x_xgboost.csv')\n",
    "train_y = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\dataset\\\\train_y_xgboost.csv')\n",
    "test_x = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\dataset\\\\test_x_xgboost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_nn = pd.read_csv('.//dataset//train_x_NN.csv')\n",
    "train_y_nn = pd.read_csv('.//dataset//train_y_NN.csv')\n",
    "test_x_nn = pd.read_csv('.//dataset//test_x_NN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Model1xgb,Model1xgb2, Model1NNproba,Model1NN2proba,Model1ramdom,Model2KMeans,Model2KNN,Model3logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv_classfier(model,train_x, train_y, test_x):\n",
    "    \n",
    "\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state= 71)\n",
    "    for i , (tr_idx, va_idx) in enumerate (kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "\n",
    "    tmp = np.stack(preds_test, axis =1)\n",
    "    mode_test, mode_counts = mode(tmp, axis=1)\n",
    "\n",
    "    preds_test = mode_test\n",
    "    preds_size = preds_test.shape[0]\n",
    "    preds_test = preds_test.reshape(preds_size,)\n",
    "    \n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv(model, train_x, train_y, test_x):\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "    \n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "    for i , (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "        \n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "    \n",
    "    preds_test = np.mean(preds_test, axis=0)\n",
    "    \n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-meansを省いた"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:275: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:275: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:275: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:275: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:38:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06799\teval-error:0.07055\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06824\teval-error:0.07041\n",
      "[2]\ttrain-error:0.06760\teval-error:0.07070\n",
      "[3]\ttrain-error:0.06819\teval-error:0.07026\n",
      "[4]\ttrain-error:0.06716\teval-error:0.07011\n",
      "[5]\ttrain-error:0.06770\teval-error:0.06922\n",
      "[6]\ttrain-error:0.06731\teval-error:0.06937\n",
      "[7]\ttrain-error:0.06750\teval-error:0.06937\n",
      "[8]\ttrain-error:0.06741\teval-error:0.06967\n",
      "[9]\ttrain-error:0.06735\teval-error:0.06922\n",
      "[10]\ttrain-error:0.06701\teval-error:0.06864\n",
      "[11]\ttrain-error:0.06691\teval-error:0.06834\n",
      "[12]\ttrain-error:0.06677\teval-error:0.06804\n",
      "[13]\ttrain-error:0.06701\teval-error:0.06760\n",
      "[14]\ttrain-error:0.06696\teval-error:0.06731\n",
      "[15]\ttrain-error:0.06701\teval-error:0.06686\n",
      "[16]\ttrain-error:0.06657\teval-error:0.06672\n",
      "[17]\ttrain-error:0.06686\teval-error:0.06701\n",
      "[18]\ttrain-error:0.06677\teval-error:0.06657\n",
      "[19]\ttrain-error:0.06662\teval-error:0.06716\n",
      "[20]\ttrain-error:0.06657\teval-error:0.06657\n",
      "[21]\ttrain-error:0.06657\teval-error:0.06657\n",
      "[22]\ttrain-error:0.06637\teval-error:0.06642\n",
      "[23]\ttrain-error:0.06657\teval-error:0.06642\n",
      "[24]\ttrain-error:0.06632\teval-error:0.06657\n",
      "[25]\ttrain-error:0.06608\teval-error:0.06672\n",
      "[26]\ttrain-error:0.06613\teval-error:0.06686\n",
      "[27]\ttrain-error:0.06603\teval-error:0.06731\n",
      "[28]\ttrain-error:0.06583\teval-error:0.06701\n",
      "[29]\ttrain-error:0.06568\teval-error:0.06716\n",
      "[30]\ttrain-error:0.06573\teval-error:0.06672\n",
      "[31]\ttrain-error:0.06544\teval-error:0.06627\n",
      "[32]\ttrain-error:0.06534\teval-error:0.06598\n",
      "[33]\ttrain-error:0.06524\teval-error:0.06627\n",
      "[34]\ttrain-error:0.06504\teval-error:0.06627\n",
      "[35]\ttrain-error:0.06509\teval-error:0.06583\n",
      "[36]\ttrain-error:0.06475\teval-error:0.06598\n",
      "[37]\ttrain-error:0.06460\teval-error:0.06598\n",
      "[38]\ttrain-error:0.06455\teval-error:0.06539\n",
      "[39]\ttrain-error:0.06445\teval-error:0.06524\n",
      "[40]\ttrain-error:0.06426\teval-error:0.06524\n",
      "[41]\ttrain-error:0.06401\teval-error:0.06539\n",
      "[42]\ttrain-error:0.06386\teval-error:0.06509\n",
      "[43]\ttrain-error:0.06357\teval-error:0.06539\n",
      "[44]\ttrain-error:0.06312\teval-error:0.06524\n",
      "[45]\ttrain-error:0.06298\teval-error:0.06553\n",
      "[46]\ttrain-error:0.06308\teval-error:0.06568\n",
      "[47]\ttrain-error:0.06288\teval-error:0.06568\n",
      "[48]\ttrain-error:0.06273\teval-error:0.06568\n",
      "[49]\ttrain-error:0.06278\teval-error:0.06568\n",
      "[50]\ttrain-error:0.06258\teval-error:0.06568\n",
      "[51]\ttrain-error:0.06234\teval-error:0.06583\n",
      "[52]\ttrain-error:0.06180\teval-error:0.06568\n",
      "[53]\ttrain-error:0.06170\teval-error:0.06553\n",
      "[54]\ttrain-error:0.06150\teval-error:0.06568\n",
      "[55]\ttrain-error:0.06130\teval-error:0.06583\n",
      "[56]\ttrain-error:0.06125\teval-error:0.06539\n",
      "[57]\ttrain-error:0.06125\teval-error:0.06524\n",
      "[58]\ttrain-error:0.06135\teval-error:0.06524\n",
      "[59]\ttrain-error:0.06145\teval-error:0.06539\n",
      "[60]\ttrain-error:0.06091\teval-error:0.06495\n",
      "[61]\ttrain-error:0.06066\teval-error:0.06524\n",
      "[62]\ttrain-error:0.06052\teval-error:0.06524\n",
      "[63]\ttrain-error:0.06047\teval-error:0.06553\n",
      "[64]\ttrain-error:0.06052\teval-error:0.06568\n",
      "[65]\ttrain-error:0.06042\teval-error:0.06583\n",
      "[66]\ttrain-error:0.06022\teval-error:0.06539\n",
      "[67]\ttrain-error:0.06003\teval-error:0.06495\n",
      "[68]\ttrain-error:0.05988\teval-error:0.06509\n",
      "[69]\ttrain-error:0.06012\teval-error:0.06480\n",
      "[70]\ttrain-error:0.05998\teval-error:0.06509\n",
      "[71]\ttrain-error:0.05988\teval-error:0.06539\n",
      "[72]\ttrain-error:0.05963\teval-error:0.06539\n",
      "[73]\ttrain-error:0.05953\teval-error:0.06509\n",
      "[74]\ttrain-error:0.05924\teval-error:0.06524\n",
      "[75]\ttrain-error:0.05914\teval-error:0.06524\n",
      "[76]\ttrain-error:0.05914\teval-error:0.06539\n",
      "[77]\ttrain-error:0.05889\teval-error:0.06539\n",
      "[78]\ttrain-error:0.05880\teval-error:0.06539\n",
      "[79]\ttrain-error:0.05874\teval-error:0.06539\n",
      "[80]\ttrain-error:0.05840\teval-error:0.06583\n",
      "[81]\ttrain-error:0.05811\teval-error:0.06553\n",
      "[82]\ttrain-error:0.05806\teval-error:0.06553\n",
      "[83]\ttrain-error:0.05796\teval-error:0.06553\n",
      "[84]\ttrain-error:0.05781\teval-error:0.06568\n",
      "[85]\ttrain-error:0.05776\teval-error:0.06568\n",
      "[86]\ttrain-error:0.05761\teval-error:0.06568\n",
      "[87]\ttrain-error:0.05766\teval-error:0.06539\n",
      "[88]\ttrain-error:0.05737\teval-error:0.06553\n",
      "[89]\ttrain-error:0.05727\teval-error:0.06553\n",
      "Stopping. Best iteration:\n",
      "[69]\ttrain-error:0.06012\teval-error:0.06480\n",
      "\n",
      "[14:38:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06780\teval-error:0.07188\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06790\teval-error:0.07173\n",
      "[2]\ttrain-error:0.06785\teval-error:0.07114\n",
      "[3]\ttrain-error:0.06780\teval-error:0.07129\n",
      "[4]\ttrain-error:0.06775\teval-error:0.07114\n",
      "[5]\ttrain-error:0.06770\teval-error:0.07129\n",
      "[6]\ttrain-error:0.06750\teval-error:0.07070\n",
      "[7]\ttrain-error:0.06741\teval-error:0.07129\n",
      "[8]\ttrain-error:0.06735\teval-error:0.07114\n",
      "[9]\ttrain-error:0.06716\teval-error:0.07085\n",
      "[10]\ttrain-error:0.06691\teval-error:0.07114\n",
      "[11]\ttrain-error:0.06677\teval-error:0.07041\n",
      "[12]\ttrain-error:0.06647\teval-error:0.06982\n",
      "[13]\ttrain-error:0.06642\teval-error:0.06996\n",
      "[14]\ttrain-error:0.06617\teval-error:0.06996\n",
      "[15]\ttrain-error:0.06608\teval-error:0.06908\n",
      "[16]\ttrain-error:0.06627\teval-error:0.06922\n",
      "[17]\ttrain-error:0.06622\teval-error:0.06922\n",
      "[18]\ttrain-error:0.06603\teval-error:0.06922\n",
      "[19]\ttrain-error:0.06578\teval-error:0.06922\n",
      "[20]\ttrain-error:0.06598\teval-error:0.06952\n",
      "[21]\ttrain-error:0.06603\teval-error:0.06982\n",
      "[22]\ttrain-error:0.06593\teval-error:0.06967\n",
      "[23]\ttrain-error:0.06593\teval-error:0.06937\n",
      "[24]\ttrain-error:0.06583\teval-error:0.06952\n",
      "[25]\ttrain-error:0.06553\teval-error:0.06952\n",
      "[26]\ttrain-error:0.06568\teval-error:0.06952\n",
      "[27]\ttrain-error:0.06563\teval-error:0.06952\n",
      "[28]\ttrain-error:0.06544\teval-error:0.06967\n",
      "[29]\ttrain-error:0.06544\teval-error:0.06952\n",
      "[30]\ttrain-error:0.06544\teval-error:0.06952\n",
      "[31]\ttrain-error:0.06499\teval-error:0.06967\n",
      "[32]\ttrain-error:0.06480\teval-error:0.06982\n",
      "[33]\ttrain-error:0.06455\teval-error:0.06937\n",
      "[34]\ttrain-error:0.06470\teval-error:0.06937\n",
      "[35]\ttrain-error:0.06460\teval-error:0.06937\n",
      "Stopping. Best iteration:\n",
      "[15]\ttrain-error:0.06608\teval-error:0.06908\n",
      "\n",
      "[14:38:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06775\teval-error:0.07262\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06741\teval-error:0.07306\n",
      "[2]\ttrain-error:0.06745\teval-error:0.07306\n",
      "[3]\ttrain-error:0.06745\teval-error:0.07262\n",
      "[4]\ttrain-error:0.06735\teval-error:0.07203\n",
      "[5]\ttrain-error:0.06735\teval-error:0.07173\n",
      "[6]\ttrain-error:0.06711\teval-error:0.07188\n",
      "[7]\ttrain-error:0.06711\teval-error:0.07173\n",
      "[8]\ttrain-error:0.06711\teval-error:0.07129\n",
      "[9]\ttrain-error:0.06696\teval-error:0.07085\n",
      "[10]\ttrain-error:0.06667\teval-error:0.07085\n",
      "[11]\ttrain-error:0.06652\teval-error:0.07055\n",
      "[12]\ttrain-error:0.06657\teval-error:0.07085\n",
      "[13]\ttrain-error:0.06632\teval-error:0.07085\n",
      "[14]\ttrain-error:0.06627\teval-error:0.07085\n",
      "[15]\ttrain-error:0.06642\teval-error:0.07129\n",
      "[16]\ttrain-error:0.06647\teval-error:0.07114\n",
      "[17]\ttrain-error:0.06622\teval-error:0.07085\n",
      "[18]\ttrain-error:0.06622\teval-error:0.07114\n",
      "[19]\ttrain-error:0.06642\teval-error:0.07114\n",
      "[20]\ttrain-error:0.06642\teval-error:0.07100\n",
      "[21]\ttrain-error:0.06632\teval-error:0.07100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\ttrain-error:0.06622\teval-error:0.07100\n",
      "[23]\ttrain-error:0.06622\teval-error:0.07100\n",
      "[24]\ttrain-error:0.06632\teval-error:0.07055\n",
      "[25]\ttrain-error:0.06637\teval-error:0.07041\n",
      "[26]\ttrain-error:0.06627\teval-error:0.07070\n",
      "[27]\ttrain-error:0.06617\teval-error:0.07026\n",
      "[28]\ttrain-error:0.06632\teval-error:0.07055\n",
      "[29]\ttrain-error:0.06608\teval-error:0.07070\n",
      "[30]\ttrain-error:0.06593\teval-error:0.07055\n",
      "[31]\ttrain-error:0.06568\teval-error:0.07041\n",
      "[32]\ttrain-error:0.06553\teval-error:0.07085\n",
      "[33]\ttrain-error:0.06534\teval-error:0.07070\n",
      "[34]\ttrain-error:0.06519\teval-error:0.07026\n",
      "[35]\ttrain-error:0.06495\teval-error:0.07070\n",
      "[36]\ttrain-error:0.06499\teval-error:0.07100\n",
      "[37]\ttrain-error:0.06485\teval-error:0.07070\n",
      "[38]\ttrain-error:0.06460\teval-error:0.07085\n",
      "[39]\ttrain-error:0.06431\teval-error:0.07070\n",
      "[40]\ttrain-error:0.06406\teval-error:0.07100\n",
      "[41]\ttrain-error:0.06391\teval-error:0.07100\n",
      "[42]\ttrain-error:0.06376\teval-error:0.07085\n",
      "[43]\ttrain-error:0.06376\teval-error:0.07085\n",
      "[44]\ttrain-error:0.06342\teval-error:0.07041\n",
      "[45]\ttrain-error:0.06332\teval-error:0.07055\n",
      "[46]\ttrain-error:0.06327\teval-error:0.07055\n",
      "[47]\ttrain-error:0.06298\teval-error:0.07041\n",
      "Stopping. Best iteration:\n",
      "[27]\ttrain-error:0.06617\teval-error:0.07026\n",
      "\n",
      "[14:38:15] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06686\teval-error:0.07572\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06677\teval-error:0.07542\n",
      "[2]\ttrain-error:0.06642\teval-error:0.07439\n",
      "[3]\ttrain-error:0.06627\teval-error:0.07410\n",
      "[4]\ttrain-error:0.06667\teval-error:0.07439\n",
      "[5]\ttrain-error:0.06627\teval-error:0.07454\n",
      "[6]\ttrain-error:0.06642\teval-error:0.07498\n",
      "[7]\ttrain-error:0.06598\teval-error:0.07454\n",
      "[8]\ttrain-error:0.06608\teval-error:0.07454\n",
      "[9]\ttrain-error:0.06578\teval-error:0.07410\n",
      "[10]\ttrain-error:0.06539\teval-error:0.07424\n",
      "[11]\ttrain-error:0.06549\teval-error:0.07469\n",
      "[12]\ttrain-error:0.06544\teval-error:0.07454\n",
      "[13]\ttrain-error:0.06553\teval-error:0.07424\n",
      "[14]\ttrain-error:0.06558\teval-error:0.07410\n",
      "[15]\ttrain-error:0.06534\teval-error:0.07439\n",
      "[16]\ttrain-error:0.06509\teval-error:0.07424\n",
      "[17]\ttrain-error:0.06475\teval-error:0.07424\n",
      "[18]\ttrain-error:0.06480\teval-error:0.07439\n",
      "[19]\ttrain-error:0.06480\teval-error:0.07439\n",
      "[20]\ttrain-error:0.06480\teval-error:0.07439\n",
      "[21]\ttrain-error:0.06470\teval-error:0.07410\n",
      "[22]\ttrain-error:0.06450\teval-error:0.07380\n",
      "[23]\ttrain-error:0.06440\teval-error:0.07395\n",
      "[24]\ttrain-error:0.06435\teval-error:0.07410\n",
      "[25]\ttrain-error:0.06401\teval-error:0.07380\n",
      "[26]\ttrain-error:0.06416\teval-error:0.07424\n",
      "[27]\ttrain-error:0.06411\teval-error:0.07454\n",
      "[28]\ttrain-error:0.06396\teval-error:0.07424\n",
      "[29]\ttrain-error:0.06362\teval-error:0.07424\n",
      "[30]\ttrain-error:0.06366\teval-error:0.07454\n",
      "[31]\ttrain-error:0.06337\teval-error:0.07380\n",
      "[32]\ttrain-error:0.06322\teval-error:0.07380\n",
      "[33]\ttrain-error:0.06308\teval-error:0.07365\n",
      "[34]\ttrain-error:0.06312\teval-error:0.07336\n",
      "[35]\ttrain-error:0.06312\teval-error:0.07336\n",
      "[36]\ttrain-error:0.06308\teval-error:0.07321\n",
      "[37]\ttrain-error:0.06303\teval-error:0.07336\n",
      "[38]\ttrain-error:0.06278\teval-error:0.07306\n",
      "[39]\ttrain-error:0.06229\teval-error:0.07336\n",
      "[40]\ttrain-error:0.06229\teval-error:0.07336\n",
      "[41]\ttrain-error:0.06209\teval-error:0.07351\n",
      "[42]\ttrain-error:0.06189\teval-error:0.07321\n",
      "[43]\ttrain-error:0.06150\teval-error:0.07336\n",
      "[44]\ttrain-error:0.06125\teval-error:0.07306\n",
      "[45]\ttrain-error:0.06111\teval-error:0.07306\n",
      "[46]\ttrain-error:0.06125\teval-error:0.07321\n",
      "[47]\ttrain-error:0.06111\teval-error:0.07336\n",
      "[48]\ttrain-error:0.06086\teval-error:0.07380\n",
      "[49]\ttrain-error:0.06076\teval-error:0.07351\n",
      "[50]\ttrain-error:0.06066\teval-error:0.07306\n",
      "[51]\ttrain-error:0.06052\teval-error:0.07291\n",
      "[52]\ttrain-error:0.06042\teval-error:0.07277\n",
      "[53]\ttrain-error:0.06042\teval-error:0.07321\n",
      "[54]\ttrain-error:0.06032\teval-error:0.07306\n",
      "[55]\ttrain-error:0.05988\teval-error:0.07306\n",
      "[56]\ttrain-error:0.05988\teval-error:0.07321\n",
      "[57]\ttrain-error:0.05988\teval-error:0.07321\n",
      "[58]\ttrain-error:0.05968\teval-error:0.07306\n",
      "[59]\ttrain-error:0.05958\teval-error:0.07306\n",
      "[60]\ttrain-error:0.05943\teval-error:0.07306\n",
      "[61]\ttrain-error:0.05904\teval-error:0.07291\n",
      "[62]\ttrain-error:0.05899\teval-error:0.07277\n",
      "[63]\ttrain-error:0.05889\teval-error:0.07262\n",
      "[64]\ttrain-error:0.05870\teval-error:0.07262\n",
      "[65]\ttrain-error:0.05820\teval-error:0.07247\n",
      "[66]\ttrain-error:0.05825\teval-error:0.07247\n",
      "[67]\ttrain-error:0.05815\teval-error:0.07262\n",
      "[68]\ttrain-error:0.05815\teval-error:0.07247\n",
      "[69]\ttrain-error:0.05786\teval-error:0.07233\n",
      "[70]\ttrain-error:0.05756\teval-error:0.07218\n",
      "[71]\ttrain-error:0.05751\teval-error:0.07233\n",
      "[72]\ttrain-error:0.05756\teval-error:0.07218\n",
      "[73]\ttrain-error:0.05737\teval-error:0.07203\n",
      "[74]\ttrain-error:0.05737\teval-error:0.07203\n",
      "[75]\ttrain-error:0.05717\teval-error:0.07188\n",
      "[76]\ttrain-error:0.05717\teval-error:0.07188\n",
      "[77]\ttrain-error:0.05678\teval-error:0.07218\n",
      "[78]\ttrain-error:0.05658\teval-error:0.07218\n",
      "[79]\ttrain-error:0.05653\teval-error:0.07218\n",
      "[80]\ttrain-error:0.05648\teval-error:0.07218\n",
      "[81]\ttrain-error:0.05599\teval-error:0.07233\n",
      "[82]\ttrain-error:0.05584\teval-error:0.07233\n",
      "[83]\ttrain-error:0.05579\teval-error:0.07247\n",
      "[84]\ttrain-error:0.05570\teval-error:0.07262\n",
      "[85]\ttrain-error:0.05560\teval-error:0.07247\n",
      "[86]\ttrain-error:0.05555\teval-error:0.07247\n",
      "[87]\ttrain-error:0.05530\teval-error:0.07203\n",
      "[88]\ttrain-error:0.05535\teval-error:0.07233\n",
      "[89]\ttrain-error:0.05525\teval-error:0.07218\n",
      "[90]\ttrain-error:0.05520\teval-error:0.07203\n",
      "[91]\ttrain-error:0.05530\teval-error:0.07218\n",
      "[92]\ttrain-error:0.05515\teval-error:0.07233\n",
      "[93]\ttrain-error:0.05505\teval-error:0.07188\n",
      "[94]\ttrain-error:0.05501\teval-error:0.07188\n",
      "[95]\ttrain-error:0.05505\teval-error:0.07188\n",
      "Stopping. Best iteration:\n",
      "[75]\ttrain-error:0.05717\teval-error:0.07188\n",
      "\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2397 - accuracy: 0.9253 - val_loss: 0.2089 - val_accuracy: 0.9317\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2179 - accuracy: 0.9293 - val_loss: 0.2067 - val_accuracy: 0.9336\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9305 - val_loss: 0.2076 - val_accuracy: 0.9327\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9312 - val_loss: 0.2076 - val_accuracy: 0.9324\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9319 - val_loss: 0.2078 - val_accuracy: 0.9314\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2014 - accuracy: 0.9325 - val_loss: 0.2096 - val_accuracy: 0.9320\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2003 - accuracy: 0.9332 - val_loss: 0.2110 - val_accuracy: 0.9306\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1985 - accuracy: 0.9335 - val_loss: 0.2094 - val_accuracy: 0.9324\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1964 - accuracy: 0.9339 - val_loss: 0.2109 - val_accuracy: 0.9305\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1947 - accuracy: 0.9340 - val_loss: 0.2094 - val_accuracy: 0.9325\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1918 - accuracy: 0.9344 - val_loss: 0.2072 - val_accuracy: 0.9334\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1894 - accuracy: 0.9361 - val_loss: 0.2082 - val_accuracy: 0.9336\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1877 - accuracy: 0.9353 - val_loss: 0.2096 - val_accuracy: 0.9330\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1852 - accuracy: 0.9365 - val_loss: 0.2106 - val_accuracy: 0.9318\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1843 - accuracy: 0.9376 - val_loss: 0.2126 - val_accuracy: 0.9318\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1797 - accuracy: 0.9380 - val_loss: 0.2122 - val_accuracy: 0.9325\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1768 - accuracy: 0.9394 - val_loss: 0.2191 - val_accuracy: 0.9315\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1747 - accuracy: 0.9406 - val_loss: 0.2163 - val_accuracy: 0.9302\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1720 - accuracy: 0.9405 - val_loss: 0.2191 - val_accuracy: 0.9309\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1703 - accuracy: 0.9420 - val_loss: 0.2193 - val_accuracy: 0.9327\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.1673 - accuracy: 0.9422 - val_loss: 0.2212 - val_accuracy: 0.9297\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.1647 - accuracy: 0.9419 - val_loss: 0.2213 - val_accuracy: 0.9296\n",
      "WARNING:tensorflow:From C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:122: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2379 - accuracy: 0.9262 - val_loss: 0.2196 - val_accuracy: 0.9283\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2137 - accuracy: 0.9295 - val_loss: 0.2145 - val_accuracy: 0.9305\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9319 - val_loss: 0.2149 - val_accuracy: 0.9289\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9318 - val_loss: 0.2151 - val_accuracy: 0.9296\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2017 - accuracy: 0.9314 - val_loss: 0.2174 - val_accuracy: 0.9292\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1984 - accuracy: 0.9339 - val_loss: 0.2163 - val_accuracy: 0.9287\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1978 - accuracy: 0.9332 - val_loss: 0.2179 - val_accuracy: 0.9296\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1960 - accuracy: 0.9349 - val_loss: 0.2186 - val_accuracy: 0.9300\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1948 - accuracy: 0.9344 - val_loss: 0.2186 - val_accuracy: 0.9287\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1907 - accuracy: 0.9348 - val_loss: 0.2234 - val_accuracy: 0.9266\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1890 - accuracy: 0.9359 - val_loss: 0.2217 - val_accuracy: 0.9286\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1873 - accuracy: 0.9360 - val_loss: 0.2200 - val_accuracy: 0.9281\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1851 - accuracy: 0.9364 - val_loss: 0.2230 - val_accuracy: 0.9272\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1842 - accuracy: 0.9382 - val_loss: 0.2234 - val_accuracy: 0.9271\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1794 - accuracy: 0.9385 - val_loss: 0.2268 - val_accuracy: 0.9258\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1769 - accuracy: 0.9380 - val_loss: 0.2255 - val_accuracy: 0.9258\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1755 - accuracy: 0.9389 - val_loss: 0.2297 - val_accuracy: 0.9261\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1708 - accuracy: 0.9407 - val_loss: 0.2316 - val_accuracy: 0.9256\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1687 - accuracy: 0.9419 - val_loss: 0.2334 - val_accuracy: 0.9268\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1674 - accuracy: 0.9418 - val_loss: 0.2418 - val_accuracy: 0.9244\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1625 - accuracy: 0.9434 - val_loss: 0.2424 - val_accuracy: 0.9274\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1622 - accuracy: 0.9431 - val_loss: 0.2387 - val_accuracy: 0.9253\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2416 - accuracy: 0.9265 - val_loss: 0.2194 - val_accuracy: 0.9303\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2129 - accuracy: 0.9298 - val_loss: 0.2187 - val_accuracy: 0.9302\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9305 - val_loss: 0.2172 - val_accuracy: 0.9302\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9325 - val_loss: 0.2191 - val_accuracy: 0.9286\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.9330 - val_loss: 0.2178 - val_accuracy: 0.9312\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2001 - accuracy: 0.9325 - val_loss: 0.2315 - val_accuracy: 0.9240\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1987 - accuracy: 0.9333 - val_loss: 0.2184 - val_accuracy: 0.9325\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1953 - accuracy: 0.9347 - val_loss: 0.2208 - val_accuracy: 0.9309\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1927 - accuracy: 0.9340 - val_loss: 0.2239 - val_accuracy: 0.9305\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1924 - accuracy: 0.9354 - val_loss: 0.2217 - val_accuracy: 0.9306\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1882 - accuracy: 0.9362 - val_loss: 0.2253 - val_accuracy: 0.9294\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1873 - accuracy: 0.9359 - val_loss: 0.2248 - val_accuracy: 0.9306\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1854 - accuracy: 0.9365 - val_loss: 0.2324 - val_accuracy: 0.9303\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1825 - accuracy: 0.9373 - val_loss: 0.2273 - val_accuracy: 0.9281\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1809 - accuracy: 0.9387 - val_loss: 0.2276 - val_accuracy: 0.9303\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1772 - accuracy: 0.9389 - val_loss: 0.2289 - val_accuracy: 0.9290\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1740 - accuracy: 0.9397 - val_loss: 0.2313 - val_accuracy: 0.9302\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1745 - accuracy: 0.9403 - val_loss: 0.2323 - val_accuracy: 0.9294\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1695 - accuracy: 0.9409 - val_loss: 0.2358 - val_accuracy: 0.9281\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1663 - accuracy: 0.9411 - val_loss: 0.2341 - val_accuracy: 0.9283\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1621 - accuracy: 0.9442 - val_loss: 0.2447 - val_accuracy: 0.9274\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1596 - accuracy: 0.9425 - val_loss: 0.2423 - val_accuracy: 0.9284\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1595 - accuracy: 0.9446 - val_loss: 0.2410 - val_accuracy: 0.9287\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2375 - accuracy: 0.9267 - val_loss: 0.2172 - val_accuracy: 0.9261\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2121 - accuracy: 0.9311 - val_loss: 0.2202 - val_accuracy: 0.9272\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9314 - val_loss: 0.2148 - val_accuracy: 0.9268\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9329 - val_loss: 0.2163 - val_accuracy: 0.9271\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2014 - accuracy: 0.9336 - val_loss: 0.2171 - val_accuracy: 0.9275\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2006 - accuracy: 0.9349 - val_loss: 0.2164 - val_accuracy: 0.9271\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1951 - accuracy: 0.9358 - val_loss: 0.2188 - val_accuracy: 0.9258\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1949 - accuracy: 0.9355 - val_loss: 0.2167 - val_accuracy: 0.9261\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1936 - accuracy: 0.9356 - val_loss: 0.2198 - val_accuracy: 0.9263\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1916 - accuracy: 0.9363 - val_loss: 0.2226 - val_accuracy: 0.9252\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1884 - accuracy: 0.9370 - val_loss: 0.2188 - val_accuracy: 0.9262\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1863 - accuracy: 0.9379 - val_loss: 0.2228 - val_accuracy: 0.9256\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1848 - accuracy: 0.9378 - val_loss: 0.2273 - val_accuracy: 0.9255\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1817 - accuracy: 0.9391 - val_loss: 0.2237 - val_accuracy: 0.9250\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1794 - accuracy: 0.9391 - val_loss: 0.2278 - val_accuracy: 0.9263\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1770 - accuracy: 0.9400 - val_loss: 0.2308 - val_accuracy: 0.9249\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1745 - accuracy: 0.9402 - val_loss: 0.2343 - val_accuracy: 0.9240\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1708 - accuracy: 0.9419 - val_loss: 0.2324 - val_accuracy: 0.9231\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1684 - accuracy: 0.9429 - val_loss: 0.2345 - val_accuracy: 0.9228\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1685 - accuracy: 0.9423 - val_loss: 0.2379 - val_accuracy: 0.9231\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1656 - accuracy: 0.9427 - val_loss: 0.2381 - val_accuracy: 0.9244\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1614 - accuracy: 0.9451 - val_loss: 0.2421 - val_accuracy: 0.9244\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1587 - accuracy: 0.9446 - val_loss: 0.2452 - val_accuracy: 0.9244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:178: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:178: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:178: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:178: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06922\teval-error:0.07100\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06888\teval-error:0.06967\n",
      "[2]\ttrain-error:0.06962\teval-error:0.06819\n",
      "[3]\ttrain-error:0.06898\teval-error:0.06745\n",
      "[4]\ttrain-error:0.06809\teval-error:0.06686\n",
      "[5]\ttrain-error:0.06927\teval-error:0.06613\n",
      "[6]\ttrain-error:0.06903\teval-error:0.06598\n",
      "[7]\ttrain-error:0.06844\teval-error:0.06613\n",
      "[8]\ttrain-error:0.06819\teval-error:0.06627\n",
      "[9]\ttrain-error:0.06775\teval-error:0.06583\n",
      "[10]\ttrain-error:0.06775\teval-error:0.06583\n",
      "[11]\ttrain-error:0.06741\teval-error:0.06598\n",
      "[12]\ttrain-error:0.06741\teval-error:0.06598\n",
      "[13]\ttrain-error:0.06755\teval-error:0.06553\n",
      "[14]\ttrain-error:0.06750\teval-error:0.06568\n",
      "[15]\ttrain-error:0.06731\teval-error:0.06583\n",
      "[16]\ttrain-error:0.06711\teval-error:0.06553\n",
      "[17]\ttrain-error:0.06706\teval-error:0.06568\n",
      "[18]\ttrain-error:0.06686\teval-error:0.06583\n",
      "[19]\ttrain-error:0.06657\teval-error:0.06583\n",
      "[20]\ttrain-error:0.06672\teval-error:0.06613\n",
      "[21]\ttrain-error:0.06686\teval-error:0.06613\n",
      "[22]\ttrain-error:0.06686\teval-error:0.06598\n",
      "[23]\ttrain-error:0.06701\teval-error:0.06568\n",
      "[24]\ttrain-error:0.06677\teval-error:0.06568\n",
      "[25]\ttrain-error:0.06706\teval-error:0.06583\n",
      "[26]\ttrain-error:0.06667\teval-error:0.06568\n",
      "[27]\ttrain-error:0.06642\teval-error:0.06568\n",
      "[28]\ttrain-error:0.06662\teval-error:0.06553\n",
      "[29]\ttrain-error:0.06657\teval-error:0.06568\n",
      "[30]\ttrain-error:0.06608\teval-error:0.06568\n",
      "[31]\ttrain-error:0.06617\teval-error:0.06539\n",
      "[32]\ttrain-error:0.06608\teval-error:0.06553\n",
      "[33]\ttrain-error:0.06598\teval-error:0.06568\n",
      "[34]\ttrain-error:0.06603\teval-error:0.06553\n",
      "[35]\ttrain-error:0.06583\teval-error:0.06539\n",
      "[36]\ttrain-error:0.06568\teval-error:0.06524\n",
      "[37]\ttrain-error:0.06553\teval-error:0.06524\n",
      "[38]\ttrain-error:0.06539\teval-error:0.06539\n",
      "[39]\ttrain-error:0.06480\teval-error:0.06553\n",
      "[40]\ttrain-error:0.06470\teval-error:0.06539\n",
      "[41]\ttrain-error:0.06455\teval-error:0.06553\n",
      "[42]\ttrain-error:0.06421\teval-error:0.06539\n",
      "[43]\ttrain-error:0.06426\teval-error:0.06553\n",
      "[44]\ttrain-error:0.06416\teval-error:0.06568\n",
      "[45]\ttrain-error:0.06426\teval-error:0.06583\n",
      "[46]\ttrain-error:0.06406\teval-error:0.06568\n",
      "[47]\ttrain-error:0.06352\teval-error:0.06553\n",
      "[48]\ttrain-error:0.06327\teval-error:0.06568\n",
      "[49]\ttrain-error:0.06308\teval-error:0.06553\n",
      "[50]\ttrain-error:0.06288\teval-error:0.06553\n",
      "[51]\ttrain-error:0.06258\teval-error:0.06598\n",
      "[52]\ttrain-error:0.06239\teval-error:0.06568\n",
      "[53]\ttrain-error:0.06243\teval-error:0.06568\n",
      "[54]\ttrain-error:0.06234\teval-error:0.06539\n",
      "[55]\ttrain-error:0.06219\teval-error:0.06539\n",
      "[56]\ttrain-error:0.06234\teval-error:0.06539\n",
      "Stopping. Best iteration:\n",
      "[36]\ttrain-error:0.06568\teval-error:0.06524\n",
      "\n",
      "[14:40:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06937\teval-error:0.07100\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06888\teval-error:0.07011\n",
      "[2]\ttrain-error:0.06952\teval-error:0.07085\n",
      "[3]\ttrain-error:0.06893\teval-error:0.07100\n",
      "[4]\ttrain-error:0.06878\teval-error:0.07114\n",
      "[5]\ttrain-error:0.06908\teval-error:0.07114\n",
      "[6]\ttrain-error:0.06858\teval-error:0.07041\n",
      "[7]\ttrain-error:0.06829\teval-error:0.07070\n",
      "[8]\ttrain-error:0.06814\teval-error:0.07026\n",
      "[9]\ttrain-error:0.06760\teval-error:0.07011\n",
      "[10]\ttrain-error:0.06790\teval-error:0.07026\n",
      "[11]\ttrain-error:0.06780\teval-error:0.06982\n",
      "[12]\ttrain-error:0.06750\teval-error:0.06967\n",
      "[13]\ttrain-error:0.06745\teval-error:0.06996\n",
      "[14]\ttrain-error:0.06741\teval-error:0.06952\n",
      "[15]\ttrain-error:0.06706\teval-error:0.06952\n",
      "[16]\ttrain-error:0.06716\teval-error:0.06952\n",
      "[17]\ttrain-error:0.06677\teval-error:0.06922\n",
      "[18]\ttrain-error:0.06652\teval-error:0.06908\n",
      "[19]\ttrain-error:0.06667\teval-error:0.06893\n",
      "[20]\ttrain-error:0.06677\teval-error:0.06908\n",
      "[21]\ttrain-error:0.06681\teval-error:0.06908\n",
      "[22]\ttrain-error:0.06677\teval-error:0.06922\n",
      "[23]\ttrain-error:0.06657\teval-error:0.06893\n",
      "[24]\ttrain-error:0.06647\teval-error:0.06893\n",
      "[25]\ttrain-error:0.06622\teval-error:0.06908\n",
      "[26]\ttrain-error:0.06608\teval-error:0.06908\n",
      "[27]\ttrain-error:0.06617\teval-error:0.06893\n",
      "[28]\ttrain-error:0.06598\teval-error:0.06849\n",
      "[29]\ttrain-error:0.06603\teval-error:0.06864\n",
      "[30]\ttrain-error:0.06583\teval-error:0.06893\n",
      "[31]\ttrain-error:0.06534\teval-error:0.06878\n",
      "[32]\ttrain-error:0.06529\teval-error:0.06864\n",
      "[33]\ttrain-error:0.06529\teval-error:0.06878\n",
      "[34]\ttrain-error:0.06519\teval-error:0.06819\n",
      "[35]\ttrain-error:0.06489\teval-error:0.06893\n",
      "[36]\ttrain-error:0.06495\teval-error:0.06893\n",
      "[37]\ttrain-error:0.06460\teval-error:0.06834\n",
      "[38]\ttrain-error:0.06440\teval-error:0.06849\n",
      "[39]\ttrain-error:0.06440\teval-error:0.06790\n",
      "[40]\ttrain-error:0.06440\teval-error:0.06804\n",
      "[41]\ttrain-error:0.06431\teval-error:0.06819\n",
      "[42]\ttrain-error:0.06416\teval-error:0.06804\n",
      "[43]\ttrain-error:0.06381\teval-error:0.06790\n",
      "[44]\ttrain-error:0.06362\teval-error:0.06804\n",
      "[45]\ttrain-error:0.06317\teval-error:0.06834\n",
      "[46]\ttrain-error:0.06303\teval-error:0.06819\n",
      "[47]\ttrain-error:0.06288\teval-error:0.06849\n",
      "[48]\ttrain-error:0.06268\teval-error:0.06849\n",
      "[49]\ttrain-error:0.06253\teval-error:0.06804\n",
      "[50]\ttrain-error:0.06199\teval-error:0.06849\n",
      "[51]\ttrain-error:0.06189\teval-error:0.06790\n",
      "[52]\ttrain-error:0.06145\teval-error:0.06849\n",
      "[53]\ttrain-error:0.06121\teval-error:0.06878\n",
      "[54]\ttrain-error:0.06121\teval-error:0.06849\n",
      "[55]\ttrain-error:0.06111\teval-error:0.06922\n",
      "[56]\ttrain-error:0.06106\teval-error:0.06922\n",
      "[57]\ttrain-error:0.06091\teval-error:0.06908\n",
      "[58]\ttrain-error:0.06096\teval-error:0.06864\n",
      "[59]\ttrain-error:0.06081\teval-error:0.06878\n",
      "Stopping. Best iteration:\n",
      "[39]\ttrain-error:0.06440\teval-error:0.06790\n",
      "\n",
      "[14:40:09] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06873\teval-error:0.06996\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06893\teval-error:0.07114\n",
      "[2]\ttrain-error:0.06893\teval-error:0.07085\n",
      "[3]\ttrain-error:0.06873\teval-error:0.07026\n",
      "[4]\ttrain-error:0.06839\teval-error:0.07085\n",
      "[5]\ttrain-error:0.06873\teval-error:0.07011\n",
      "[6]\ttrain-error:0.06799\teval-error:0.06982\n",
      "[7]\ttrain-error:0.06795\teval-error:0.06982\n",
      "[8]\ttrain-error:0.06775\teval-error:0.07026\n",
      "[9]\ttrain-error:0.06790\teval-error:0.06967\n",
      "[10]\ttrain-error:0.06790\teval-error:0.06952\n",
      "[11]\ttrain-error:0.06770\teval-error:0.06937\n",
      "[12]\ttrain-error:0.06750\teval-error:0.06967\n",
      "[13]\ttrain-error:0.06741\teval-error:0.06937\n",
      "[14]\ttrain-error:0.06755\teval-error:0.06922\n",
      "[15]\ttrain-error:0.06745\teval-error:0.06937\n",
      "[16]\ttrain-error:0.06775\teval-error:0.06893\n",
      "[17]\ttrain-error:0.06735\teval-error:0.06922\n",
      "[18]\ttrain-error:0.06735\teval-error:0.06922\n",
      "[19]\ttrain-error:0.06731\teval-error:0.06922\n",
      "[20]\ttrain-error:0.06706\teval-error:0.06908\n",
      "[21]\ttrain-error:0.06686\teval-error:0.06908\n",
      "[22]\ttrain-error:0.06677\teval-error:0.06908\n",
      "[23]\ttrain-error:0.06662\teval-error:0.06908\n",
      "[24]\ttrain-error:0.06622\teval-error:0.06922\n",
      "[25]\ttrain-error:0.06642\teval-error:0.06922\n",
      "[26]\ttrain-error:0.06613\teval-error:0.06922\n",
      "[27]\ttrain-error:0.06578\teval-error:0.06982\n",
      "[28]\ttrain-error:0.06598\teval-error:0.06967\n",
      "[29]\ttrain-error:0.06583\teval-error:0.06982\n",
      "[30]\ttrain-error:0.06573\teval-error:0.06967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\ttrain-error:0.06549\teval-error:0.06952\n",
      "[32]\ttrain-error:0.06514\teval-error:0.06952\n",
      "[33]\ttrain-error:0.06489\teval-error:0.06922\n",
      "[34]\ttrain-error:0.06504\teval-error:0.06922\n",
      "[35]\ttrain-error:0.06499\teval-error:0.06878\n",
      "[36]\ttrain-error:0.06489\teval-error:0.06878\n",
      "[37]\ttrain-error:0.06470\teval-error:0.06849\n",
      "[38]\ttrain-error:0.06470\teval-error:0.06878\n",
      "[39]\ttrain-error:0.06480\teval-error:0.06864\n",
      "[40]\ttrain-error:0.06460\teval-error:0.06893\n",
      "[41]\ttrain-error:0.06406\teval-error:0.06893\n",
      "[42]\ttrain-error:0.06386\teval-error:0.06893\n",
      "[43]\ttrain-error:0.06357\teval-error:0.06922\n",
      "[44]\ttrain-error:0.06347\teval-error:0.06908\n",
      "[45]\ttrain-error:0.06347\teval-error:0.06893\n",
      "[46]\ttrain-error:0.06327\teval-error:0.06864\n",
      "[47]\ttrain-error:0.06322\teval-error:0.06893\n",
      "[48]\ttrain-error:0.06283\teval-error:0.06878\n",
      "[49]\ttrain-error:0.06268\teval-error:0.06864\n",
      "[50]\ttrain-error:0.06253\teval-error:0.06849\n",
      "[51]\ttrain-error:0.06224\teval-error:0.06864\n",
      "[52]\ttrain-error:0.06219\teval-error:0.06834\n",
      "[53]\ttrain-error:0.06219\teval-error:0.06819\n",
      "[54]\ttrain-error:0.06209\teval-error:0.06849\n",
      "[55]\ttrain-error:0.06189\teval-error:0.06819\n",
      "[56]\ttrain-error:0.06175\teval-error:0.06819\n",
      "[57]\ttrain-error:0.06150\teval-error:0.06834\n",
      "[58]\ttrain-error:0.06145\teval-error:0.06878\n",
      "[59]\ttrain-error:0.06125\teval-error:0.06878\n",
      "[60]\ttrain-error:0.06086\teval-error:0.06878\n",
      "[61]\ttrain-error:0.06096\teval-error:0.06893\n",
      "[62]\ttrain-error:0.06081\teval-error:0.06908\n",
      "[63]\ttrain-error:0.06062\teval-error:0.06922\n",
      "[64]\ttrain-error:0.06037\teval-error:0.06908\n",
      "[65]\ttrain-error:0.06032\teval-error:0.06893\n",
      "[66]\ttrain-error:0.06022\teval-error:0.06864\n",
      "[67]\ttrain-error:0.05993\teval-error:0.06878\n",
      "[68]\ttrain-error:0.05973\teval-error:0.06849\n",
      "[69]\ttrain-error:0.05993\teval-error:0.06819\n",
      "[70]\ttrain-error:0.05988\teval-error:0.06834\n",
      "[71]\ttrain-error:0.05973\teval-error:0.06804\n",
      "[72]\ttrain-error:0.05934\teval-error:0.06804\n",
      "[73]\ttrain-error:0.05934\teval-error:0.06790\n",
      "[74]\ttrain-error:0.05914\teval-error:0.06804\n",
      "[75]\ttrain-error:0.05929\teval-error:0.06790\n",
      "[76]\ttrain-error:0.05909\teval-error:0.06849\n",
      "[77]\ttrain-error:0.05889\teval-error:0.06849\n",
      "[78]\ttrain-error:0.05870\teval-error:0.06849\n",
      "[79]\ttrain-error:0.05860\teval-error:0.06804\n",
      "[80]\ttrain-error:0.05870\teval-error:0.06849\n",
      "[81]\ttrain-error:0.05884\teval-error:0.06849\n",
      "[82]\ttrain-error:0.05880\teval-error:0.06834\n",
      "[83]\ttrain-error:0.05860\teval-error:0.06864\n",
      "[84]\ttrain-error:0.05830\teval-error:0.06878\n",
      "[85]\ttrain-error:0.05825\teval-error:0.06849\n",
      "[86]\ttrain-error:0.05771\teval-error:0.06878\n",
      "[87]\ttrain-error:0.05766\teval-error:0.06878\n",
      "[88]\ttrain-error:0.05751\teval-error:0.06878\n",
      "[89]\ttrain-error:0.05742\teval-error:0.06937\n",
      "[90]\ttrain-error:0.05742\teval-error:0.06922\n",
      "[91]\ttrain-error:0.05707\teval-error:0.06908\n",
      "[92]\ttrain-error:0.05717\teval-error:0.06893\n",
      "[93]\ttrain-error:0.05707\teval-error:0.06893\n",
      "Stopping. Best iteration:\n",
      "[73]\ttrain-error:0.05934\teval-error:0.06790\n",
      "\n",
      "[14:40:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06854\teval-error:0.07351\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06780\teval-error:0.07321\n",
      "[2]\ttrain-error:0.06814\teval-error:0.07336\n",
      "[3]\ttrain-error:0.06765\teval-error:0.07410\n",
      "[4]\ttrain-error:0.06780\teval-error:0.07424\n",
      "[5]\ttrain-error:0.06839\teval-error:0.07498\n",
      "[6]\ttrain-error:0.06770\teval-error:0.07454\n",
      "[7]\ttrain-error:0.06731\teval-error:0.07439\n",
      "[8]\ttrain-error:0.06701\teval-error:0.07483\n",
      "[9]\ttrain-error:0.06735\teval-error:0.07454\n",
      "[10]\ttrain-error:0.06735\teval-error:0.07424\n",
      "[11]\ttrain-error:0.06706\teval-error:0.07380\n",
      "[12]\ttrain-error:0.06662\teval-error:0.07380\n",
      "[13]\ttrain-error:0.06652\teval-error:0.07380\n",
      "[14]\ttrain-error:0.06652\teval-error:0.07380\n",
      "[15]\ttrain-error:0.06627\teval-error:0.07454\n",
      "[16]\ttrain-error:0.06632\teval-error:0.07424\n",
      "[17]\ttrain-error:0.06617\teval-error:0.07439\n",
      "[18]\ttrain-error:0.06608\teval-error:0.07454\n",
      "[19]\ttrain-error:0.06588\teval-error:0.07424\n",
      "[20]\ttrain-error:0.06568\teval-error:0.07424\n",
      "[21]\ttrain-error:0.06573\teval-error:0.07439\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-error:0.06780\teval-error:0.07321\n",
      "\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3581 - accuracy: 0.8975 - val_loss: 0.2753 - val_accuracy: 0.9256\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2810 - accuracy: 0.9209 - val_loss: 0.2498 - val_accuracy: 0.9256\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2606 - accuracy: 0.9214 - val_loss: 0.2357 - val_accuracy: 0.9263\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2471 - accuracy: 0.9226 - val_loss: 0.2274 - val_accuracy: 0.9292\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2398 - accuracy: 0.9250 - val_loss: 0.2232 - val_accuracy: 0.9309\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2363 - accuracy: 0.9257 - val_loss: 0.2210 - val_accuracy: 0.9308\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2334 - accuracy: 0.9269 - val_loss: 0.2191 - val_accuracy: 0.9309\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2307 - accuracy: 0.9271 - val_loss: 0.2176 - val_accuracy: 0.9311\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2302 - accuracy: 0.9275 - val_loss: 0.2164 - val_accuracy: 0.9309\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2280 - accuracy: 0.9272 - val_loss: 0.2163 - val_accuracy: 0.9311\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2263 - accuracy: 0.9270 - val_loss: 0.2151 - val_accuracy: 0.9308\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2259 - accuracy: 0.9266 - val_loss: 0.2145 - val_accuracy: 0.9305\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2258 - accuracy: 0.9273 - val_loss: 0.2141 - val_accuracy: 0.9306\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2249 - accuracy: 0.9279 - val_loss: 0.2141 - val_accuracy: 0.9315\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2220 - accuracy: 0.9283 - val_loss: 0.2134 - val_accuracy: 0.9312\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2229 - accuracy: 0.9275 - val_loss: 0.2131 - val_accuracy: 0.9311\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2220 - accuracy: 0.9272 - val_loss: 0.2133 - val_accuracy: 0.9317\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2221 - accuracy: 0.9278 - val_loss: 0.2127 - val_accuracy: 0.9318\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2227 - accuracy: 0.9273 - val_loss: 0.2124 - val_accuracy: 0.9320\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2199 - accuracy: 0.9288 - val_loss: 0.2126 - val_accuracy: 0.9323\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2205 - accuracy: 0.9281 - val_loss: 0.2121 - val_accuracy: 0.9323\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.92 - 1s 6ms/step - loss: 0.2199 - accuracy: 0.9281 - val_loss: 0.2116 - val_accuracy: 0.9320\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2195 - accuracy: 0.9275 - val_loss: 0.2116 - val_accuracy: 0.9318\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2189 - accuracy: 0.9278 - val_loss: 0.2115 - val_accuracy: 0.9317\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2196 - accuracy: 0.9284 - val_loss: 0.2117 - val_accuracy: 0.9324\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2193 - accuracy: 0.9289 - val_loss: 0.2110 - val_accuracy: 0.9320\n",
      "Epoch 27/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2164 - accuracy: 0.9284 - val_loss: 0.2107 - val_accuracy: 0.9320\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2180 - accuracy: 0.9294 - val_loss: 0.2103 - val_accuracy: 0.9321\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2167 - accuracy: 0.9280 - val_loss: 0.2102 - val_accuracy: 0.9321\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2154 - accuracy: 0.9285 - val_loss: 0.2101 - val_accuracy: 0.9321\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2158 - accuracy: 0.9281 - val_loss: 0.2099 - val_accuracy: 0.9321\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2144 - accuracy: 0.9296 - val_loss: 0.2102 - val_accuracy: 0.9324\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2165 - accuracy: 0.9288 - val_loss: 0.2098 - val_accuracy: 0.9324\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2162 - accuracy: 0.9281 - val_loss: 0.2095 - val_accuracy: 0.9321\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2163 - accuracy: 0.9289 - val_loss: 0.2100 - val_accuracy: 0.9324\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2156 - accuracy: 0.9284 - val_loss: 0.2097 - val_accuracy: 0.9324\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2153 - accuracy: 0.9283 - val_loss: 0.2100 - val_accuracy: 0.9321\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2159 - accuracy: 0.9287 - val_loss: 0.2093 - val_accuracy: 0.9321\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2165 - accuracy: 0.9279 - val_loss: 0.2093 - val_accuracy: 0.9321\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2140 - accuracy: 0.9294 - val_loss: 0.2092 - val_accuracy: 0.9320\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2154 - accuracy: 0.9288 - val_loss: 0.2092 - val_accuracy: 0.9320\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2124 - accuracy: 0.9287 - val_loss: 0.2090 - val_accuracy: 0.9324\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2129 - accuracy: 0.9298 - val_loss: 0.2091 - val_accuracy: 0.9318\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2147 - accuracy: 0.9281 - val_loss: 0.2090 - val_accuracy: 0.9317\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2137 - accuracy: 0.9295 - val_loss: 0.2088 - val_accuracy: 0.9318\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2127 - accuracy: 0.9294 - val_loss: 0.2087 - val_accuracy: 0.9320\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2132 - accuracy: 0.9290 - val_loss: 0.2088 - val_accuracy: 0.9321\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2131 - accuracy: 0.9292 - val_loss: 0.2085 - val_accuracy: 0.9320\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2125 - accuracy: 0.9289 - val_loss: 0.2085 - val_accuracy: 0.9320\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2119 - accuracy: 0.9298 - val_loss: 0.2085 - val_accuracy: 0.9321\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2129 - accuracy: 0.9295 - val_loss: 0.2085 - val_accuracy: 0.9321\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2119 - accuracy: 0.9288 - val_loss: 0.2084 - val_accuracy: 0.9324\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2113 - accuracy: 0.9290 - val_loss: 0.2082 - val_accuracy: 0.9324\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2107 - accuracy: 0.9297 - val_loss: 0.2082 - val_accuracy: 0.9321\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2107 - accuracy: 0.9292 - val_loss: 0.2085 - val_accuracy: 0.9325\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2097 - accuracy: 0.9296 - val_loss: 0.2082 - val_accuracy: 0.9323\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2120 - accuracy: 0.9294 - val_loss: 0.2084 - val_accuracy: 0.9324\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2115 - accuracy: 0.9291 - val_loss: 0.2082 - val_accuracy: 0.9323\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2112 - accuracy: 0.9294 - val_loss: 0.2082 - val_accuracy: 0.9320\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2122 - accuracy: 0.9297 - val_loss: 0.2083 - val_accuracy: 0.9324\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2106 - accuracy: 0.9299 - val_loss: 0.2081 - val_accuracy: 0.9323\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.2119 - accuracy: 0.9291 - val_loss: 0.2080 - val_accuracy: 0.9324\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 8ms/step - loss: 0.2108 - accuracy: 0.9302 - val_loss: 0.2080 - val_accuracy: 0.9323\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 8ms/step - loss: 0.2087 - accuracy: 0.9298 - val_loss: 0.2079 - val_accuracy: 0.9324\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 8ms/step - loss: 0.2093 - accuracy: 0.9296 - val_loss: 0.2080 - val_accuracy: 0.9327\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.2108 - accuracy: 0.9292 - val_loss: 0.2079 - val_accuracy: 0.9327\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2096 - accuracy: 0.9298 - val_loss: 0.2079 - val_accuracy: 0.9330\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2080 - accuracy: 0.9298 - val_loss: 0.2079 - val_accuracy: 0.9331\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2086 - accuracy: 0.9300 - val_loss: 0.2077 - val_accuracy: 0.9330\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2106 - accuracy: 0.9307 - val_loss: 0.2077 - val_accuracy: 0.9328\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2095 - accuracy: 0.9292 - val_loss: 0.2076 - val_accuracy: 0.9323\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2096 - accuracy: 0.9304 - val_loss: 0.2075 - val_accuracy: 0.9324\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2082 - accuracy: 0.9304 - val_loss: 0.2077 - val_accuracy: 0.9330\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2095 - accuracy: 0.9294 - val_loss: 0.2078 - val_accuracy: 0.9330\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2079 - accuracy: 0.9301 - val_loss: 0.2078 - val_accuracy: 0.9328\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2085 - accuracy: 0.9303 - val_loss: 0.2078 - val_accuracy: 0.9330\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2093 - accuracy: 0.9300 - val_loss: 0.2078 - val_accuracy: 0.9328\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2087 - accuracy: 0.9306 - val_loss: 0.2075 - val_accuracy: 0.9330\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2071 - accuracy: 0.9297 - val_loss: 0.2078 - val_accuracy: 0.9330\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2087 - accuracy: 0.9298 - val_loss: 0.2074 - val_accuracy: 0.9333\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2058 - accuracy: 0.9312 - val_loss: 0.2074 - val_accuracy: 0.9331\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2080 - accuracy: 0.9295 - val_loss: 0.2075 - val_accuracy: 0.9337\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2077 - accuracy: 0.9299 - val_loss: 0.2075 - val_accuracy: 0.9336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2094 - accuracy: 0.9297 - val_loss: 0.2074 - val_accuracy: 0.9334\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2071 - accuracy: 0.9306 - val_loss: 0.2074 - val_accuracy: 0.9333\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2086 - accuracy: 0.9303 - val_loss: 0.2073 - val_accuracy: 0.9339\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2081 - accuracy: 0.9298 - val_loss: 0.2072 - val_accuracy: 0.9330\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2062 - accuracy: 0.9305 - val_loss: 0.2074 - val_accuracy: 0.9337\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2056 - accuracy: 0.9309 - val_loss: 0.2075 - val_accuracy: 0.9336\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2086 - accuracy: 0.9297 - val_loss: 0.2073 - val_accuracy: 0.9339\n",
      "Epoch 91/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2058 - accuracy: 0.9313 - val_loss: 0.2073 - val_accuracy: 0.9337\n",
      "Epoch 92/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2083 - accuracy: 0.9303 - val_loss: 0.2074 - val_accuracy: 0.9336\n",
      "Epoch 93/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2067 - accuracy: 0.9298 - val_loss: 0.2073 - val_accuracy: 0.9337\n",
      "Epoch 94/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2078 - accuracy: 0.9292 - val_loss: 0.2073 - val_accuracy: 0.9337\n",
      "Epoch 95/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2070 - accuracy: 0.9303 - val_loss: 0.2073 - val_accuracy: 0.9337\n",
      "Epoch 96/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2052 - accuracy: 0.9313 - val_loss: 0.2072 - val_accuracy: 0.9334\n",
      "Epoch 97/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2072 - accuracy: 0.9300 - val_loss: 0.2073 - val_accuracy: 0.9334\n",
      "Epoch 98/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2044 - accuracy: 0.9315 - val_loss: 0.2073 - val_accuracy: 0.9331\n",
      "Epoch 99/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2058 - accuracy: 0.9303 - val_loss: 0.2074 - val_accuracy: 0.9330\n",
      "Epoch 100/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2055 - accuracy: 0.9312 - val_loss: 0.2074 - val_accuracy: 0.9333\n",
      "Epoch 101/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2048 - accuracy: 0.9309 - val_loss: 0.2073 - val_accuracy: 0.9333\n",
      "Epoch 102/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2044 - accuracy: 0.9308 - val_loss: 0.2072 - val_accuracy: 0.9333\n",
      "Epoch 103/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9315 - val_loss: 0.2072 - val_accuracy: 0.9334\n",
      "Epoch 104/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2050 - accuracy: 0.9303 - val_loss: 0.2073 - val_accuracy: 0.9334\n",
      "Epoch 105/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2053 - accuracy: 0.9317 - val_loss: 0.2072 - val_accuracy: 0.9334\n",
      "Epoch 106/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2046 - accuracy: 0.9307 - val_loss: 0.2072 - val_accuracy: 0.9331\n",
      "Epoch 107/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9297 - val_loss: 0.2074 - val_accuracy: 0.9334\n",
      "Epoch 108/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9308 - val_loss: 0.2075 - val_accuracy: 0.9333\n",
      "Epoch 109/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2061 - accuracy: 0.9304 - val_loss: 0.2072 - val_accuracy: 0.9333\n",
      "Epoch 110/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2038 - accuracy: 0.9317 - val_loss: 0.2073 - val_accuracy: 0.9333\n",
      "Epoch 111/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2061 - accuracy: 0.9305 - val_loss: 0.2071 - val_accuracy: 0.9333\n",
      "Epoch 112/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2035 - accuracy: 0.9323 - val_loss: 0.2071 - val_accuracy: 0.9334\n",
      "Epoch 113/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2054 - accuracy: 0.9310 - val_loss: 0.2072 - val_accuracy: 0.9331\n",
      "Epoch 114/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2045 - accuracy: 0.9310 - val_loss: 0.2073 - val_accuracy: 0.9331\n",
      "Epoch 115/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2040 - accuracy: 0.9310 - val_loss: 0.2074 - val_accuracy: 0.9330\n",
      "Epoch 116/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2033 - accuracy: 0.9311 - val_loss: 0.2072 - val_accuracy: 0.9333\n",
      "Epoch 117/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2048 - accuracy: 0.9297 - val_loss: 0.2072 - val_accuracy: 0.9333\n",
      "Epoch 118/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2045 - accuracy: 0.9312 - val_loss: 0.2073 - val_accuracy: 0.9333\n",
      "Epoch 119/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2029 - accuracy: 0.9326 - val_loss: 0.2073 - val_accuracy: 0.9333\n",
      "Epoch 120/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2042 - accuracy: 0.9309 - val_loss: 0.2074 - val_accuracy: 0.9331\n",
      "Epoch 121/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2037 - accuracy: 0.9307 - val_loss: 0.2075 - val_accuracy: 0.9333\n",
      "Epoch 122/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2038 - accuracy: 0.9302 - val_loss: 0.2072 - val_accuracy: 0.9334\n",
      "Epoch 123/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2049 - accuracy: 0.9308 - val_loss: 0.2071 - val_accuracy: 0.9336\n",
      "Epoch 124/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2036 - accuracy: 0.9317 - val_loss: 0.2072 - val_accuracy: 0.9331\n",
      "Epoch 125/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2026 - accuracy: 0.9312 - val_loss: 0.2073 - val_accuracy: 0.9333\n",
      "Epoch 126/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2040 - accuracy: 0.9320 - val_loss: 0.2073 - val_accuracy: 0.9330\n",
      "Epoch 127/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2034 - accuracy: 0.9314 - val_loss: 0.2072 - val_accuracy: 0.9333\n",
      "Epoch 128/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.9320 - val_loss: 0.2074 - val_accuracy: 0.9328\n",
      "Epoch 129/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2039 - accuracy: 0.9301 - val_loss: 0.2073 - val_accuracy: 0.9330\n",
      "Epoch 130/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2032 - accuracy: 0.9310 - val_loss: 0.2074 - val_accuracy: 0.9333\n",
      "Epoch 131/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2043 - accuracy: 0.9314 - val_loss: 0.2072 - val_accuracy: 0.9334\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3331 - accuracy: 0.9197 - val_loss: 0.2793 - val_accuracy: 0.9221\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2723 - accuracy: 0.9222 - val_loss: 0.2518 - val_accuracy: 0.9219\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2525 - accuracy: 0.9238 - val_loss: 0.2375 - val_accuracy: 0.9272\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2439 - accuracy: 0.9260 - val_loss: 0.2309 - val_accuracy: 0.9297\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2365 - accuracy: 0.9273 - val_loss: 0.2272 - val_accuracy: 0.9297\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2324 - accuracy: 0.9274 - val_loss: 0.2246 - val_accuracy: 0.9299\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2310 - accuracy: 0.9269 - val_loss: 0.2228 - val_accuracy: 0.9296\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2291 - accuracy: 0.9267 - val_loss: 0.2214 - val_accuracy: 0.9296\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2288 - accuracy: 0.9271 - val_loss: 0.2204 - val_accuracy: 0.9292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2262 - accuracy: 0.9279 - val_loss: 0.2195 - val_accuracy: 0.9293\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2240 - accuracy: 0.9288 - val_loss: 0.2190 - val_accuracy: 0.9293\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2242 - accuracy: 0.9282 - val_loss: 0.2184 - val_accuracy: 0.9293\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2222 - accuracy: 0.9278 - val_loss: 0.2181 - val_accuracy: 0.9294\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2216 - accuracy: 0.9286 - val_loss: 0.2178 - val_accuracy: 0.9292\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2205 - accuracy: 0.9287 - val_loss: 0.2173 - val_accuracy: 0.9292\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2213 - accuracy: 0.9289 - val_loss: 0.2169 - val_accuracy: 0.9289\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2205 - accuracy: 0.9293 - val_loss: 0.2166 - val_accuracy: 0.9286\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2184 - accuracy: 0.9283 - val_loss: 0.2163 - val_accuracy: 0.9289\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2175 - accuracy: 0.9285 - val_loss: 0.2162 - val_accuracy: 0.9290\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2171 - accuracy: 0.9297 - val_loss: 0.2160 - val_accuracy: 0.9289\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2169 - accuracy: 0.9284 - val_loss: 0.2159 - val_accuracy: 0.9290\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2166 - accuracy: 0.9293 - val_loss: 0.2155 - val_accuracy: 0.9290\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2150 - accuracy: 0.9293 - val_loss: 0.2154 - val_accuracy: 0.9289\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2156 - accuracy: 0.9296 - val_loss: 0.2153 - val_accuracy: 0.9290\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2142 - accuracy: 0.9293 - val_loss: 0.2154 - val_accuracy: 0.9289\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2147 - accuracy: 0.9299 - val_loss: 0.2151 - val_accuracy: 0.9289\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2151 - accuracy: 0.9294 - val_loss: 0.2151 - val_accuracy: 0.9289\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2151 - accuracy: 0.9306 - val_loss: 0.2148 - val_accuracy: 0.9292\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2159 - accuracy: 0.9297 - val_loss: 0.2147 - val_accuracy: 0.9289\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2161 - accuracy: 0.9296 - val_loss: 0.2147 - val_accuracy: 0.9292\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2135 - accuracy: 0.9295 - val_loss: 0.2145 - val_accuracy: 0.9293\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2140 - accuracy: 0.9302 - val_loss: 0.2145 - val_accuracy: 0.9289\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2134 - accuracy: 0.9294 - val_loss: 0.2143 - val_accuracy: 0.9287\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2127 - accuracy: 0.9297 - val_loss: 0.2143 - val_accuracy: 0.9293\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2121 - accuracy: 0.9301 - val_loss: 0.2141 - val_accuracy: 0.9293\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2131 - accuracy: 0.9297 - val_loss: 0.2142 - val_accuracy: 0.9292\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2119 - accuracy: 0.9299 - val_loss: 0.2140 - val_accuracy: 0.9293\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2122 - accuracy: 0.9302 - val_loss: 0.2141 - val_accuracy: 0.9294\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2124 - accuracy: 0.9302 - val_loss: 0.2139 - val_accuracy: 0.9296\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2112 - accuracy: 0.9305 - val_loss: 0.2138 - val_accuracy: 0.9297\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2123 - accuracy: 0.9304 - val_loss: 0.2138 - val_accuracy: 0.9293\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2131 - accuracy: 0.9293 - val_loss: 0.2138 - val_accuracy: 0.9293\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2115 - accuracy: 0.9301 - val_loss: 0.2138 - val_accuracy: 0.9293\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2096 - accuracy: 0.9302 - val_loss: 0.2136 - val_accuracy: 0.9292\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2117 - accuracy: 0.9303 - val_loss: 0.2136 - val_accuracy: 0.9294\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2105 - accuracy: 0.9302 - val_loss: 0.2138 - val_accuracy: 0.9293\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2105 - accuracy: 0.9302 - val_loss: 0.2136 - val_accuracy: 0.9293\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9308 - val_loss: 0.2135 - val_accuracy: 0.9294\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2109 - accuracy: 0.9299 - val_loss: 0.2134 - val_accuracy: 0.9293\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2090 - accuracy: 0.9311 - val_loss: 0.2134 - val_accuracy: 0.9293\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2100 - accuracy: 0.9304 - val_loss: 0.2133 - val_accuracy: 0.9293\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2088 - accuracy: 0.9305 - val_loss: 0.2133 - val_accuracy: 0.9292\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2099 - accuracy: 0.9309 - val_loss: 0.2132 - val_accuracy: 0.9294\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2094 - accuracy: 0.9296 - val_loss: 0.2132 - val_accuracy: 0.9293\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2081 - accuracy: 0.9304 - val_loss: 0.2131 - val_accuracy: 0.9292\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2091 - accuracy: 0.9307 - val_loss: 0.2132 - val_accuracy: 0.9293\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9306 - val_loss: 0.2131 - val_accuracy: 0.9292\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2077 - accuracy: 0.9312 - val_loss: 0.2131 - val_accuracy: 0.9294\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2085 - accuracy: 0.9298 - val_loss: 0.2130 - val_accuracy: 0.9292\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9304 - val_loss: 0.2131 - val_accuracy: 0.9294\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2059 - accuracy: 0.9309 - val_loss: 0.2131 - val_accuracy: 0.9296\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2082 - accuracy: 0.9303 - val_loss: 0.2131 - val_accuracy: 0.9294\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2068 - accuracy: 0.9312 - val_loss: 0.2131 - val_accuracy: 0.9292\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2062 - accuracy: 0.9303 - val_loss: 0.2131 - val_accuracy: 0.9294\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2061 - accuracy: 0.9307 - val_loss: 0.2130 - val_accuracy: 0.9296\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2087 - accuracy: 0.9311 - val_loss: 0.2130 - val_accuracy: 0.9293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2069 - accuracy: 0.9303 - val_loss: 0.2131 - val_accuracy: 0.9293\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9308 - val_loss: 0.2129 - val_accuracy: 0.9292\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2079 - accuracy: 0.9308 - val_loss: 0.2129 - val_accuracy: 0.9296\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2065 - accuracy: 0.9303 - val_loss: 0.2130 - val_accuracy: 0.9290\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2052 - accuracy: 0.9309 - val_loss: 0.2130 - val_accuracy: 0.9294\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2079 - accuracy: 0.9313 - val_loss: 0.2130 - val_accuracy: 0.9296\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9310 - val_loss: 0.2131 - val_accuracy: 0.9294\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2069 - accuracy: 0.9301 - val_loss: 0.2129 - val_accuracy: 0.9290\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2075 - accuracy: 0.9306 - val_loss: 0.2130 - val_accuracy: 0.9296\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2056 - accuracy: 0.9320 - val_loss: 0.2129 - val_accuracy: 0.9296\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2048 - accuracy: 0.9314 - val_loss: 0.2129 - val_accuracy: 0.9297\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2053 - accuracy: 0.9315 - val_loss: 0.2130 - val_accuracy: 0.9297\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2055 - accuracy: 0.9315 - val_loss: 0.2130 - val_accuracy: 0.9296\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2049 - accuracy: 0.9316 - val_loss: 0.2130 - val_accuracy: 0.9299\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2063 - accuracy: 0.9317 - val_loss: 0.2131 - val_accuracy: 0.9297\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2057 - accuracy: 0.9312 - val_loss: 0.2130 - val_accuracy: 0.9294\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2062 - accuracy: 0.9309 - val_loss: 0.2131 - val_accuracy: 0.9300\n",
      "Epoch 84/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2045 - accuracy: 0.9316 - val_loss: 0.2130 - val_accuracy: 0.9297\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2067 - accuracy: 0.9314 - val_loss: 0.2130 - val_accuracy: 0.9299\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2041 - accuracy: 0.9324 - val_loss: 0.2129 - val_accuracy: 0.9297\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2069 - accuracy: 0.9311 - val_loss: 0.2129 - val_accuracy: 0.9297\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9313 - val_loss: 0.2129 - val_accuracy: 0.9296\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2045 - accuracy: 0.9308 - val_loss: 0.2129 - val_accuracy: 0.9299\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2047 - accuracy: 0.9313 - val_loss: 0.2129 - val_accuracy: 0.9300\n",
      "Epoch 91/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2047 - accuracy: 0.9315 - val_loss: 0.2128 - val_accuracy: 0.9302\n",
      "Epoch 92/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2034 - accuracy: 0.9314 - val_loss: 0.2128 - val_accuracy: 0.9300\n",
      "Epoch 93/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2069 - accuracy: 0.9311 - val_loss: 0.2129 - val_accuracy: 0.9300\n",
      "Epoch 94/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2041 - accuracy: 0.9316 - val_loss: 0.2128 - val_accuracy: 0.9299\n",
      "Epoch 95/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2031 - accuracy: 0.9313 - val_loss: 0.2128 - val_accuracy: 0.9300\n",
      "Epoch 96/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2057 - accuracy: 0.9317 - val_loss: 0.2127 - val_accuracy: 0.9299\n",
      "Epoch 97/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2043 - accuracy: 0.9316 - val_loss: 0.2128 - val_accuracy: 0.9303\n",
      "Epoch 98/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2048 - accuracy: 0.9309 - val_loss: 0.2127 - val_accuracy: 0.9302\n",
      "Epoch 99/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2032 - accuracy: 0.9317 - val_loss: 0.2128 - val_accuracy: 0.9305\n",
      "Epoch 100/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2021 - accuracy: 0.9321 - val_loss: 0.2127 - val_accuracy: 0.9303\n",
      "Epoch 101/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2026 - accuracy: 0.9324 - val_loss: 0.2127 - val_accuracy: 0.9303\n",
      "Epoch 102/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2035 - accuracy: 0.9315 - val_loss: 0.2127 - val_accuracy: 0.9305\n",
      "Epoch 103/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9322 - val_loss: 0.2127 - val_accuracy: 0.9302\n",
      "Epoch 104/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2036 - accuracy: 0.9324 - val_loss: 0.2127 - val_accuracy: 0.9305\n",
      "Epoch 105/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2049 - accuracy: 0.9309 - val_loss: 0.2128 - val_accuracy: 0.9306\n",
      "Epoch 106/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2037 - accuracy: 0.9315 - val_loss: 0.2128 - val_accuracy: 0.9308\n",
      "Epoch 107/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2026 - accuracy: 0.9315 - val_loss: 0.2128 - val_accuracy: 0.9305\n",
      "Epoch 108/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2027 - accuracy: 0.9308 - val_loss: 0.2129 - val_accuracy: 0.9305\n",
      "Epoch 109/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9312 - val_loss: 0.2129 - val_accuracy: 0.9309\n",
      "Epoch 110/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2015 - accuracy: 0.9318 - val_loss: 0.2128 - val_accuracy: 0.9306\n",
      "Epoch 111/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2042 - accuracy: 0.9312 - val_loss: 0.2128 - val_accuracy: 0.9309\n",
      "Epoch 112/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2024 - accuracy: 0.9318 - val_loss: 0.2129 - val_accuracy: 0.9306\n",
      "Epoch 113/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2006 - accuracy: 0.9332 - val_loss: 0.2130 - val_accuracy: 0.9308\n",
      "Epoch 114/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2009 - accuracy: 0.9316 - val_loss: 0.2131 - val_accuracy: 0.9309\n",
      "Epoch 115/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2022 - accuracy: 0.9319 - val_loss: 0.2130 - val_accuracy: 0.9308\n",
      "Epoch 116/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2021 - accuracy: 0.9328 - val_loss: 0.2131 - val_accuracy: 0.9305\n",
      "Epoch 117/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2024 - accuracy: 0.9319 - val_loss: 0.2130 - val_accuracy: 0.9308\n",
      "Epoch 118/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2010 - accuracy: 0.9328 - val_loss: 0.2130 - val_accuracy: 0.9309\n",
      "Epoch 119/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2007 - accuracy: 0.9323 - val_loss: 0.2131 - val_accuracy: 0.9306\n",
      "Epoch 120/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2027 - accuracy: 0.9309 - val_loss: 0.2131 - val_accuracy: 0.9309\n",
      "Epoch 121/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2023 - accuracy: 0.9323 - val_loss: 0.2131 - val_accuracy: 0.9302\n",
      "Epoch 122/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2019 - accuracy: 0.9320 - val_loss: 0.2131 - val_accuracy: 0.9302\n",
      "Epoch 123/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2002 - accuracy: 0.9314 - val_loss: 0.2132 - val_accuracy: 0.9305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3628 - accuracy: 0.9016 - val_loss: 0.2900 - val_accuracy: 0.9221\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2772 - accuracy: 0.9221 - val_loss: 0.2551 - val_accuracy: 0.9234\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2499 - accuracy: 0.9239 - val_loss: 0.2391 - val_accuracy: 0.9266\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2397 - accuracy: 0.9268 - val_loss: 0.2328 - val_accuracy: 0.9278\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.92 - 1s 4ms/step - loss: 0.2345 - accuracy: 0.9270 - val_loss: 0.2288 - val_accuracy: 0.9286\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2308 - accuracy: 0.9278 - val_loss: 0.2262 - val_accuracy: 0.9290\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2281 - accuracy: 0.9274 - val_loss: 0.2245 - val_accuracy: 0.9290\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2264 - accuracy: 0.9271 - val_loss: 0.2232 - val_accuracy: 0.9290\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2242 - accuracy: 0.9291 - val_loss: 0.2223 - val_accuracy: 0.9286\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2228 - accuracy: 0.9282 - val_loss: 0.2214 - val_accuracy: 0.9289\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2216 - accuracy: 0.9289 - val_loss: 0.2207 - val_accuracy: 0.9296\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2235 - accuracy: 0.9280 - val_loss: 0.2203 - val_accuracy: 0.9284\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2193 - accuracy: 0.9301 - val_loss: 0.2202 - val_accuracy: 0.9284\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2205 - accuracy: 0.9287 - val_loss: 0.2193 - val_accuracy: 0.9289\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2204 - accuracy: 0.9292 - val_loss: 0.2188 - val_accuracy: 0.9294\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2190 - accuracy: 0.9284 - val_loss: 0.2188 - val_accuracy: 0.9289\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2178 - accuracy: 0.9297 - val_loss: 0.2183 - val_accuracy: 0.9290\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2183 - accuracy: 0.9296 - val_loss: 0.2184 - val_accuracy: 0.9292\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2174 - accuracy: 0.9292 - val_loss: 0.2180 - val_accuracy: 0.9293\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2170 - accuracy: 0.9297 - val_loss: 0.2177 - val_accuracy: 0.9292\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2184 - accuracy: 0.9290 - val_loss: 0.2176 - val_accuracy: 0.9294\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2175 - accuracy: 0.9294 - val_loss: 0.2174 - val_accuracy: 0.9293\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2145 - accuracy: 0.9296 - val_loss: 0.2173 - val_accuracy: 0.9292\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2152 - accuracy: 0.9295 - val_loss: 0.2173 - val_accuracy: 0.9296\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2158 - accuracy: 0.9290 - val_loss: 0.2171 - val_accuracy: 0.9294\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2140 - accuracy: 0.9301 - val_loss: 0.2167 - val_accuracy: 0.9293\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2136 - accuracy: 0.9290 - val_loss: 0.2166 - val_accuracy: 0.9294\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2140 - accuracy: 0.9297 - val_loss: 0.2165 - val_accuracy: 0.9293\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2154 - accuracy: 0.9295 - val_loss: 0.2163 - val_accuracy: 0.9296\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2140 - accuracy: 0.9302 - val_loss: 0.2161 - val_accuracy: 0.9297\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2120 - accuracy: 0.9296 - val_loss: 0.2161 - val_accuracy: 0.9296\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2140 - accuracy: 0.9301 - val_loss: 0.2159 - val_accuracy: 0.9297\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2121 - accuracy: 0.9307 - val_loss: 0.2158 - val_accuracy: 0.9297\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2128 - accuracy: 0.9299 - val_loss: 0.2157 - val_accuracy: 0.9300\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2109 - accuracy: 0.9307 - val_loss: 0.2157 - val_accuracy: 0.9297\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2128 - accuracy: 0.9296 - val_loss: 0.2155 - val_accuracy: 0.9297\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2117 - accuracy: 0.9304 - val_loss: 0.2156 - val_accuracy: 0.9297\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2110 - accuracy: 0.9302 - val_loss: 0.2155 - val_accuracy: 0.9300\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2100 - accuracy: 0.9305 - val_loss: 0.2153 - val_accuracy: 0.9300\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2107 - accuracy: 0.9303 - val_loss: 0.2154 - val_accuracy: 0.9302\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2104 - accuracy: 0.9315 - val_loss: 0.2151 - val_accuracy: 0.9303\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9309 - val_loss: 0.2151 - val_accuracy: 0.9303\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2112 - accuracy: 0.9307 - val_loss: 0.2151 - val_accuracy: 0.9300\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2101 - accuracy: 0.9309 - val_loss: 0.2150 - val_accuracy: 0.9300\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2111 - accuracy: 0.9302 - val_loss: 0.2150 - val_accuracy: 0.9297\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2103 - accuracy: 0.9301 - val_loss: 0.2149 - val_accuracy: 0.9299\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2097 - accuracy: 0.9307 - val_loss: 0.2150 - val_accuracy: 0.9299\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2081 - accuracy: 0.9307 - val_loss: 0.2150 - val_accuracy: 0.9306\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2093 - accuracy: 0.9311 - val_loss: 0.2148 - val_accuracy: 0.9300\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2094 - accuracy: 0.9316 - val_loss: 0.2148 - val_accuracy: 0.9306\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2085 - accuracy: 0.9306 - val_loss: 0.2148 - val_accuracy: 0.9302\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2078 - accuracy: 0.9319 - val_loss: 0.2148 - val_accuracy: 0.9303\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2088 - accuracy: 0.9302 - val_loss: 0.2147 - val_accuracy: 0.9305\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2091 - accuracy: 0.9303 - val_loss: 0.2147 - val_accuracy: 0.9306\n",
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2088 - accuracy: 0.9305 - val_loss: 0.2145 - val_accuracy: 0.9306\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2081 - accuracy: 0.9295 - val_loss: 0.2146 - val_accuracy: 0.9299\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2084 - accuracy: 0.9305 - val_loss: 0.2146 - val_accuracy: 0.9300\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2086 - accuracy: 0.9309 - val_loss: 0.2148 - val_accuracy: 0.9306\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2068 - accuracy: 0.9317 - val_loss: 0.2147 - val_accuracy: 0.9306\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2078 - accuracy: 0.9323 - val_loss: 0.2146 - val_accuracy: 0.9303\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2091 - accuracy: 0.9306 - val_loss: 0.2146 - val_accuracy: 0.9305\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2078 - accuracy: 0.9318 - val_loss: 0.2146 - val_accuracy: 0.9303\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2070 - accuracy: 0.9309 - val_loss: 0.2145 - val_accuracy: 0.9305\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2065 - accuracy: 0.9319 - val_loss: 0.2145 - val_accuracy: 0.9303\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2083 - accuracy: 0.9312 - val_loss: 0.2144 - val_accuracy: 0.9305\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2067 - accuracy: 0.9316 - val_loss: 0.2144 - val_accuracy: 0.9303\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2057 - accuracy: 0.9320 - val_loss: 0.2144 - val_accuracy: 0.9305\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2056 - accuracy: 0.9327 - val_loss: 0.2144 - val_accuracy: 0.9305\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2068 - accuracy: 0.9312 - val_loss: 0.2145 - val_accuracy: 0.9302\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2064 - accuracy: 0.9322 - val_loss: 0.2145 - val_accuracy: 0.9299\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2053 - accuracy: 0.9312 - val_loss: 0.2144 - val_accuracy: 0.9300\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2062 - accuracy: 0.9311 - val_loss: 0.2143 - val_accuracy: 0.9302\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2058 - accuracy: 0.9323 - val_loss: 0.2144 - val_accuracy: 0.9302\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2072 - accuracy: 0.9307 - val_loss: 0.2144 - val_accuracy: 0.9300\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2064 - accuracy: 0.9315 - val_loss: 0.2144 - val_accuracy: 0.9303\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2067 - accuracy: 0.9320 - val_loss: 0.2145 - val_accuracy: 0.9303\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9313 - val_loss: 0.2144 - val_accuracy: 0.9302\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2041 - accuracy: 0.9318 - val_loss: 0.2146 - val_accuracy: 0.9302\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2031 - accuracy: 0.9316 - val_loss: 0.2144 - val_accuracy: 0.9303\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2071 - accuracy: 0.9315 - val_loss: 0.2143 - val_accuracy: 0.9302\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2055 - accuracy: 0.9319 - val_loss: 0.2143 - val_accuracy: 0.9300\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2071 - accuracy: 0.9313 - val_loss: 0.2141 - val_accuracy: 0.9305\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2048 - accuracy: 0.9315 - val_loss: 0.2142 - val_accuracy: 0.9303\n",
      "Epoch 84/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2041 - accuracy: 0.9311 - val_loss: 0.2142 - val_accuracy: 0.9306\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2047 - accuracy: 0.9317 - val_loss: 0.2142 - val_accuracy: 0.9306\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2037 - accuracy: 0.9309 - val_loss: 0.2141 - val_accuracy: 0.9308\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2056 - accuracy: 0.9321 - val_loss: 0.2141 - val_accuracy: 0.9308\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2040 - accuracy: 0.9313 - val_loss: 0.2140 - val_accuracy: 0.9308\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2046 - accuracy: 0.9314 - val_loss: 0.2141 - val_accuracy: 0.9308\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2038 - accuracy: 0.9317 - val_loss: 0.2141 - val_accuracy: 0.9308\n",
      "Epoch 91/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2041 - accuracy: 0.9325 - val_loss: 0.2142 - val_accuracy: 0.9305\n",
      "Epoch 92/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2031 - accuracy: 0.9316 - val_loss: 0.2141 - val_accuracy: 0.9303\n",
      "Epoch 93/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2035 - accuracy: 0.9321 - val_loss: 0.2141 - val_accuracy: 0.9306\n",
      "Epoch 94/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2040 - accuracy: 0.9316 - val_loss: 0.2141 - val_accuracy: 0.9308\n",
      "Epoch 95/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2043 - accuracy: 0.9303 - val_loss: 0.2141 - val_accuracy: 0.9306\n",
      "Epoch 96/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2023 - accuracy: 0.9323 - val_loss: 0.2140 - val_accuracy: 0.9306\n",
      "Epoch 97/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2034 - accuracy: 0.9328 - val_loss: 0.2141 - val_accuracy: 0.9303\n",
      "Epoch 98/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2028 - accuracy: 0.9322 - val_loss: 0.2142 - val_accuracy: 0.9305\n",
      "Epoch 99/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2038 - accuracy: 0.9321 - val_loss: 0.2143 - val_accuracy: 0.9311\n",
      "Epoch 100/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2015 - accuracy: 0.9331 - val_loss: 0.2145 - val_accuracy: 0.9308\n",
      "Epoch 101/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2034 - accuracy: 0.9309 - val_loss: 0.2144 - val_accuracy: 0.9302\n",
      "Epoch 102/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2037 - accuracy: 0.9320 - val_loss: 0.2144 - val_accuracy: 0.9306\n",
      "Epoch 103/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2028 - accuracy: 0.9320 - val_loss: 0.2145 - val_accuracy: 0.9306\n",
      "Epoch 104/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2024 - accuracy: 0.9324 - val_loss: 0.2145 - val_accuracy: 0.9305\n",
      "Epoch 105/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2031 - accuracy: 0.9322 - val_loss: 0.2145 - val_accuracy: 0.9305\n",
      "Epoch 106/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2038 - accuracy: 0.9311 - val_loss: 0.2146 - val_accuracy: 0.9303\n",
      "Epoch 107/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2035 - accuracy: 0.9311 - val_loss: 0.2146 - val_accuracy: 0.9305\n",
      "Epoch 108/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2028 - accuracy: 0.9319 - val_loss: 0.2146 - val_accuracy: 0.9305\n",
      "Epoch 109/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2035 - accuracy: 0.9324 - val_loss: 0.2146 - val_accuracy: 0.9303\n",
      "Epoch 110/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2027 - accuracy: 0.9322 - val_loss: 0.2146 - val_accuracy: 0.9303\n",
      "Epoch 111/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2026 - accuracy: 0.9319 - val_loss: 0.2147 - val_accuracy: 0.9300\n",
      "Epoch 112/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2013 - accuracy: 0.9315 - val_loss: 0.2147 - val_accuracy: 0.9302\n",
      "Epoch 113/300\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.2023 - accuracy: 0.9330 - val_loss: 0.2148 - val_accuracy: 0.9305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/300\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.2014 - accuracy: 0.9326 - val_loss: 0.2149 - val_accuracy: 0.9299\n",
      "Epoch 115/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2036 - accuracy: 0.9318 - val_loss: 0.2149 - val_accuracy: 0.9305\n",
      "Epoch 116/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2006 - accuracy: 0.9327 - val_loss: 0.2149 - val_accuracy: 0.9302\n",
      "Epoch 1/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.3420 - accuracy: 0.8994 - val_loss: 0.2798 - val_accuracy: 0.9185\n",
      "Epoch 2/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2686 - accuracy: 0.9233 - val_loss: 0.2504 - val_accuracy: 0.9187\n",
      "Epoch 3/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2477 - accuracy: 0.9246 - val_loss: 0.2358 - val_accuracy: 0.9216\n",
      "Epoch 4/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2366 - accuracy: 0.9268 - val_loss: 0.2294 - val_accuracy: 0.9252\n",
      "Epoch 5/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2325 - accuracy: 0.9287 - val_loss: 0.2266 - val_accuracy: 0.9252\n",
      "Epoch 6/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2276 - accuracy: 0.9291 - val_loss: 0.2246 - val_accuracy: 0.9256\n",
      "Epoch 7/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2281 - accuracy: 0.9290 - val_loss: 0.2236 - val_accuracy: 0.9259\n",
      "Epoch 8/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2259 - accuracy: 0.9292 - val_loss: 0.2227 - val_accuracy: 0.9256\n",
      "Epoch 9/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2240 - accuracy: 0.9296 - val_loss: 0.2218 - val_accuracy: 0.9261\n",
      "Epoch 10/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2232 - accuracy: 0.9294 - val_loss: 0.2213 - val_accuracy: 0.9261\n",
      "Epoch 11/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2211 - accuracy: 0.9300 - val_loss: 0.2209 - val_accuracy: 0.9265\n",
      "Epoch 12/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2204 - accuracy: 0.9300 - val_loss: 0.2202 - val_accuracy: 0.9266\n",
      "Epoch 13/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2217 - accuracy: 0.9300 - val_loss: 0.2198 - val_accuracy: 0.9265\n",
      "Epoch 14/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2212 - accuracy: 0.9288 - val_loss: 0.2195 - val_accuracy: 0.9266\n",
      "Epoch 15/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2199 - accuracy: 0.9299 - val_loss: 0.2192 - val_accuracy: 0.9265\n",
      "Epoch 16/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2194 - accuracy: 0.9301 - val_loss: 0.2189 - val_accuracy: 0.9266\n",
      "Epoch 17/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2168 - accuracy: 0.9300 - val_loss: 0.2185 - val_accuracy: 0.9266\n",
      "Epoch 18/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2174 - accuracy: 0.9302 - val_loss: 0.2184 - val_accuracy: 0.9271\n",
      "Epoch 19/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2177 - accuracy: 0.9292 - val_loss: 0.2181 - val_accuracy: 0.9271\n",
      "Epoch 20/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2183 - accuracy: 0.9301 - val_loss: 0.2178 - val_accuracy: 0.9272\n",
      "Epoch 21/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2183 - accuracy: 0.9298 - val_loss: 0.2176 - val_accuracy: 0.9272\n",
      "Epoch 22/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2163 - accuracy: 0.9302 - val_loss: 0.2175 - val_accuracy: 0.9271\n",
      "Epoch 23/300\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.2162 - accuracy: 0.9296 - val_loss: 0.2172 - val_accuracy: 0.9268\n",
      "Epoch 24/300\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.2171 - accuracy: 0.9303 - val_loss: 0.2171 - val_accuracy: 0.9275\n",
      "Epoch 25/300\n",
      "159/159 [==============================] - 1s 8ms/step - loss: 0.2156 - accuracy: 0.9304 - val_loss: 0.2172 - val_accuracy: 0.9272\n",
      "Epoch 26/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2153 - accuracy: 0.9308 - val_loss: 0.2170 - val_accuracy: 0.9268\n",
      "Epoch 27/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2156 - accuracy: 0.9305 - val_loss: 0.2167 - val_accuracy: 0.9275\n",
      "Epoch 28/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2137 - accuracy: 0.9304 - val_loss: 0.2166 - val_accuracy: 0.9272\n",
      "Epoch 29/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2148 - accuracy: 0.9302 - val_loss: 0.2165 - val_accuracy: 0.9274\n",
      "Epoch 30/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2124 - accuracy: 0.9309 - val_loss: 0.2164 - val_accuracy: 0.9269\n",
      "Epoch 31/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2145 - accuracy: 0.9300 - val_loss: 0.2163 - val_accuracy: 0.9274\n",
      "Epoch 32/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2137 - accuracy: 0.9307 - val_loss: 0.2163 - val_accuracy: 0.9275\n",
      "Epoch 33/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2138 - accuracy: 0.9312 - val_loss: 0.2162 - val_accuracy: 0.9275\n",
      "Epoch 34/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2123 - accuracy: 0.9304 - val_loss: 0.2162 - val_accuracy: 0.9277\n",
      "Epoch 35/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2128 - accuracy: 0.9307 - val_loss: 0.2160 - val_accuracy: 0.9271\n",
      "Epoch 36/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2123 - accuracy: 0.9308 - val_loss: 0.2159 - val_accuracy: 0.9275\n",
      "Epoch 37/300\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2126 - accuracy: 0.9302 - val_loss: 0.2157 - val_accuracy: 0.9272\n",
      "Epoch 38/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2105 - accuracy: 0.9311 - val_loss: 0.2157 - val_accuracy: 0.9272\n",
      "Epoch 39/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2122 - accuracy: 0.9305 - val_loss: 0.2155 - val_accuracy: 0.9272\n",
      "Epoch 40/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9307 - val_loss: 0.2155 - val_accuracy: 0.9277\n",
      "Epoch 41/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2114 - accuracy: 0.9306 - val_loss: 0.2155 - val_accuracy: 0.9274\n",
      "Epoch 42/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2107 - accuracy: 0.9310 - val_loss: 0.2154 - val_accuracy: 0.9271\n",
      "Epoch 43/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2108 - accuracy: 0.9316 - val_loss: 0.2154 - val_accuracy: 0.9271\n",
      "Epoch 44/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2119 - accuracy: 0.9312 - val_loss: 0.2154 - val_accuracy: 0.9271\n",
      "Epoch 45/300\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2108 - accuracy: 0.9308 - val_loss: 0.2154 - val_accuracy: 0.9277\n",
      "Epoch 46/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9307 - val_loss: 0.2153 - val_accuracy: 0.9277\n",
      "Epoch 47/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2109 - accuracy: 0.9312 - val_loss: 0.2152 - val_accuracy: 0.9275\n",
      "Epoch 48/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2105 - accuracy: 0.9311 - val_loss: 0.2152 - val_accuracy: 0.9274\n",
      "Epoch 49/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2110 - accuracy: 0.9312 - val_loss: 0.2152 - val_accuracy: 0.9277\n",
      "Epoch 50/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9311 - val_loss: 0.2151 - val_accuracy: 0.9274\n",
      "Epoch 51/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9321 - val_loss: 0.2150 - val_accuracy: 0.9280\n",
      "Epoch 52/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9318 - val_loss: 0.2151 - val_accuracy: 0.9277\n",
      "Epoch 53/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9313 - val_loss: 0.2149 - val_accuracy: 0.9280\n",
      "Epoch 54/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9314 - val_loss: 0.2149 - val_accuracy: 0.9280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2099 - accuracy: 0.9313 - val_loss: 0.2150 - val_accuracy: 0.9278\n",
      "Epoch 56/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9316 - val_loss: 0.2149 - val_accuracy: 0.9281\n",
      "Epoch 57/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9311 - val_loss: 0.2149 - val_accuracy: 0.9278\n",
      "Epoch 58/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9308 - val_loss: 0.2148 - val_accuracy: 0.9281\n",
      "Epoch 59/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9321 - val_loss: 0.2148 - val_accuracy: 0.9280\n",
      "Epoch 60/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2091 - accuracy: 0.9315 - val_loss: 0.2147 - val_accuracy: 0.9280\n",
      "Epoch 61/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9320 - val_loss: 0.2147 - val_accuracy: 0.9280\n",
      "Epoch 62/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9320 - val_loss: 0.2147 - val_accuracy: 0.9281\n",
      "Epoch 63/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9311 - val_loss: 0.2146 - val_accuracy: 0.9278\n",
      "Epoch 64/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9315 - val_loss: 0.2146 - val_accuracy: 0.9281\n",
      "Epoch 65/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9330 - val_loss: 0.2147 - val_accuracy: 0.9284\n",
      "Epoch 66/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9322 - val_loss: 0.2145 - val_accuracy: 0.9281\n",
      "Epoch 67/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9322 - val_loss: 0.2144 - val_accuracy: 0.9283\n",
      "Epoch 68/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9319 - val_loss: 0.2144 - val_accuracy: 0.9283\n",
      "Epoch 69/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9312 - val_loss: 0.2145 - val_accuracy: 0.9284\n",
      "Epoch 70/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2064 - accuracy: 0.9317 - val_loss: 0.2144 - val_accuracy: 0.9283\n",
      "Epoch 71/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9322 - val_loss: 0.2144 - val_accuracy: 0.9283\n",
      "Epoch 72/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9317 - val_loss: 0.2145 - val_accuracy: 0.9280\n",
      "Epoch 73/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9319 - val_loss: 0.2145 - val_accuracy: 0.9280\n",
      "Epoch 74/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9311 - val_loss: 0.2145 - val_accuracy: 0.9281\n",
      "Epoch 75/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9317 - val_loss: 0.2144 - val_accuracy: 0.9284\n",
      "Epoch 76/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9312 - val_loss: 0.2145 - val_accuracy: 0.9283\n",
      "Epoch 77/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9318 - val_loss: 0.2145 - val_accuracy: 0.9284\n",
      "Epoch 78/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9319 - val_loss: 0.2145 - val_accuracy: 0.9283\n",
      "Epoch 79/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9321 - val_loss: 0.2145 - val_accuracy: 0.9283\n",
      "Epoch 80/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9328 - val_loss: 0.2146 - val_accuracy: 0.9284\n",
      "Epoch 81/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9316 - val_loss: 0.2146 - val_accuracy: 0.9284\n",
      "Epoch 82/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9326 - val_loss: 0.2146 - val_accuracy: 0.9284\n",
      "Epoch 83/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9322 - val_loss: 0.2145 - val_accuracy: 0.9287\n",
      "Epoch 84/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9326 - val_loss: 0.2146 - val_accuracy: 0.9284\n",
      "Epoch 85/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9323 - val_loss: 0.2146 - val_accuracy: 0.9283\n",
      "Epoch 86/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9319 - val_loss: 0.2144 - val_accuracy: 0.9284\n",
      "Epoch 87/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9317 - val_loss: 0.2145 - val_accuracy: 0.9284\n",
      "Epoch 88/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9323 - val_loss: 0.2144 - val_accuracy: 0.9283\n",
      "Epoch 89/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9322 - val_loss: 0.2145 - val_accuracy: 0.9284\n",
      "Epoch 90/300\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2066 - accuracy: 0.9317 - val_loss: 0.2146 - val_accuracy: 0.9284\n"
     ]
    }
   ],
   "source": [
    "model1_a = Model2KNN()\n",
    "pred_train_1a , preds_test_1a = predict_cv_classfier(model1_a, train_x, train_y, test_x)\n",
    "\n",
    "model_1b = Model1xgb()\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_1b, train_x, train_y, test_x)\n",
    "\n",
    "model_1c = Model1NNproba()\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_1c, train_x_nn, train_y, test_x_nn)\n",
    "\n",
    "\n",
    "model_1d = Model1ramdom()\n",
    "pred_train_1d, pred_test_1d = predict_cv(model_1d, train_x, train_y, test_x)\n",
    "\n",
    "\n",
    "model_1e = Model1xgb2()\n",
    "pred_train_1e, pred_test_1e = predict_cv(model_1e, train_x, train_y, test_x)\n",
    "\n",
    "model_1f = Model1NN2proba()\n",
    "pred_train_1f, pred_test_1f = predict_cv(model_1f, train_x_nn, train_y, test_x_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.1836\n",
      "logloss: 0.2068\n",
      "logloss: 0.2133\n",
      "logloss: 0.2492\n",
      "logloss: 0.2129\n",
      "logloss: 0.2120\n"
     ]
    }
   ],
   "source": [
    "print(f'logloss: {log_loss(train_y, pred_train_1a, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1b, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1c, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1d, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1e, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1f, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_2 = pd.DataFrame({'pred_1a': pred_train_1a, 'pred_1b': pred_train_1b, 'pred_1c':pred_train_1c,'pred_1d':pred_train_1d, 'pred_1e':pred_train_1e, 'pred_1f': pred_train_1f})\n",
    "test_x_2 = pd.DataFrame({'pred_1a': preds_test_1a, 'pred_1b': pred_test_1b, 'pred_1c': pred_test_1c,'pred_1d':pred_test_1d, 'pred_1e':pred_test_1e, 'pred_1f': pred_test_1f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.2100\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model3logistic()\n",
    "pred_train_2, pred_test_2 = predict_cv(model_2, train_x_2, train_y, test_x_2)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV5bnA8d+TjUASdgi7rKKgKBBRXIMrqL3Wuu/aeimtS1er1d7qbb1trd5WbVXqdW9VWq1VtIp7REUFUVbZ930JEUiAbOe5f7xv8HA8CSchk5OTeb6fz/nkzMw7M897cs48M+/MvCOqijHGmPBKS3YAxhhjkssSgTHGhJwlAmOMCTlLBMYYE3KWCIwxJuQsERhjTMhZIjDGmJCzRGCMMSFniaAeRGSliOwWkVIR2SgiT4hIbkyZY0XkHRHZKSLbReRlERkSU6atiNwrIqv9spb64c5NW6P6E5GHRWR81HChiKiI/CymXKGIrI0zf5GIXBs1fLCIPCciW/3nNUdEfiwi6bWs/1YRWeE/t7Ui8vfGrF8QRORIEZkpIrv83yPrKNtRRP7uP4+tIvK0iLT10zqLyIciUiwiX4rIRyJyXNS8IiJ3isg6/1kWicjQmGX/S0TKRGSViFxaSwy3+//pqVHjXvOfec2rQkTmRk0/VkSm++/9HBE5PmaZXUTkGR93iYg8HTXt9yKyRkR2+Lhui5p2Qsx6S31s5x1onUUkS0Se979rFZHCmJjbi8iTIrLZv+6Imd5XRN71/9eFMZ/XWSLyga/vRhH5PxHJi/9fbwZU1V4JvoCVwKn+fTdgNvA/UdNHA6XAD4A8oCNwJ1AC9PdlsoAZwJvAEFwy7gr8F3BmgLFnNNJyVgO9ooYfB4qB+THlCoG1ceYvAq717wf4z+YPQHc/bjDwDNA+zrxXAQuAAVH/g/HN8XOKWl4WsAr4EdAKuNEPZ9VS/kHgDaAt0A54C/iDn5btP580QIBvAttqYgYuBNYD/YF04LfAZ1HLfhb4O5ALHA9sB4bGrH8AMNcv59Q66lUE/NK/7whsBS7w673c/187RJV/3/+f2wGZwPCoaYOBHP++JzAf+FYt6y0EdkaVb3Cd/f/mh378BqAwZl2PA88BbYC+wDLgmqjpH/k6tQbOA74EuvhplwJj/bwdgNeAiY353WrU72myA0ilF1GJwA//Hvh31PD7wINx5nsNeMq/vxbYBOTWY71DcYljm5/3Vj/+CeDOqHKFRG18fbw3A3OAcuAXwPMxy74PuN+/bwc86n8U63BJLD2q7DBgTtRwG/+jvBioAApqiyVqfBFfJYK/RX9+CXwOfwburWN6R//jXY/bEL0YNe0/gaX+M5wM9IiapsB1wBJghR93NjDL/7inAcMa+J053X+WEjVuNTC2lvKvAd+PGr4OeD1OuTTgGz72rn7czcA/Yr43e/z7HP8/Ojhq+l+B38VZ/5mx3/WYMn2BaqBf1GcVuyOwGPhO1GewMvq7VMfn1ROXiH5Wy/THgcejhg+4zn78Wr6eCLYCR0UN3wq8798fjPtN5UVNfx+YUEvc3wLmNuQ71BQvaxpqIBHpBYzDbVwQkTbAsbg9iFj/AE7z708FpqhqaYLrycPtFU4BegADgbfrEeolwFlAe9yP4MyopoZ03B7VM77sk0CVX8dw3A/42qhlnQn8O2r4PNwR0HPA68CV9YgL3GfxfD3KfwxcKSI3iUhBnOajv+KS01DcUdYfAUTkZNye4oVAd9we+aSYeb8JHA0MEZERwGPAd4FOwF+AySLSKl5QIvKKiNxSS8xDcckzulOvOX58PA8AZ4tIBxHpgPuMX4tZ3xxgDy6hPaKqm/2kScBAcc1tmbgjqCl+2sFAtaoujlrU7Og4ROQCoEJVX60lthpX4jaIK2pm9a99wgQO8++PARYBT/pmrRkiclJMnW4RkVLcBjmHr76T0WXaAOfjvqc1DqjOCZCY9zV1GgosV9WdCS77RNyRTrNkiaD+XhSRncAaYDNwux/fEfd5bogzzwagpv2/Uy1lanM2sFFV/1dV96jqTlX9pB7z36+qa1R1t6quAj7DbfQATgZ2qerHIpKPS2w/VNUyv3H5I25vv8ZZQPRG4irg76pajfvhXuJ/jImq12ehqn8DbgDOAN4DNtdsgEWku49/gqqWqGqlqr7nZ70MeExVP1PVcuDnwGgR6Ru1+N+q6jZV3Y07eviLqn6iqtWq+iRu7++YWuI6W1V/V0vYubjmiGjbcU2H8XyGa7Io9q9qXHNR9PqG4ZqOLgU+iJq0AbdXugjYjWuq+VEicYg71/UbXFPJ/lyJOxqtMQ3oISKXiEimiFyFa2Jq46f3wu1UvItrzvtf4CWJOifmP788YAQuocfGCi4pbsX97w+4zgmYAtwiInkiMhD4dlSdEl62iJyG+638MsH1NjlLBPX3TVXNwzV9HMJXG/gSIILb44zVHfcFBvfjjlemNr1xbZMNtSZm+BncUQK4DUnNntdBuLbbDf4E15e4PeGu4E6c4eo7zQ/3BsYANSf9XsK1YZ/lh6v88mJlApX+fX0/C1T1aVU9FXeEMwH4lYicgfuctqlqSZzZeuCOAmqWUerX3TOqTPTndBDwk5rPwX8Wvf1y6qsUt9GO1hbXpBbPc7hmlTxfbhmuCW0ffqfgWdyG6gg/+nbgKB9rNvDfwDt+T3p/cfw38Neovfy4/EngbkQdyalqMXAO8GNc0+VY3FFszcUCu4GVqvqoT9CTcJ/3cdHLVudzX/6/46z+KlwTa/TR1YHUeX9u9LEswX2/n42qU0LLFpFjcL+x82OOTJoVSwQN5Pc2nwDu8cNluJNHF8QpfiFfNee8BZwhIjkJrmoNbu8qnjK+2kMB9wP9Wqgxw88Bhb5p61y+SgRrcHu9nVW1vX+1VdWaQ90zgLf93j/AFbjvz8sishFYjvsh1jQPrQY6S9RVVSIiuI1szUb5LdxeXr35DcpzuGaWw3z8HX3CirXer7cmjhzc0ci66EVGvV+DuwigfdSrjd/w1td8YJive41h1N5McATuaKTMJ6yJuCa52mTiTpTWzPt3VV2rqlWq+gTuROUQXHLJEJFBMeuqieMU4EZ/hctG3Ib1HyJyc8z6rgJeiG3aVNX3VPUoVe2I+24MBqb7yXP4+vewLhnEfOf9jkch8FRM2QOpc538EeJlqtrN/w7Souo0H+gfcyXQPssWkeG45rtvq2p9mnObXrJPUqTSi6+fLO6C2xgf6YeP98M34vboOuBOuH4JDPJlWuGuGpqC28NOw22UbiXOVUN+ORtwh+yt/PDRftp/AgtxzVLdcG3osSeLv3bCD9fm/Cbwecz4l3Anj9v6uAYAJ/lpTwFXRpVdCNzh11vz+g9cMunky0zDtXnn+th/5mPK9tMH4E7e3g108+MG4vaA4101dDXuiCPPxzcOt8d2vJ/+b1xi64DbQJ7ox58CbAGO9HHcB3wQtVwFBkYNF+CSwdG4duGcmvU24DtTc9XQD/y6r6fuq4beBf6EuxKlNa5Z6EM/7Rj/Hcvy027G7YH28NNvxzUV5fvP5wrc97G9nz4Jt1ebg9sbj76CplPM/3INbqcmNyq21rjv8slx4h7uP/O2wL01MftpHXFHzFfhruw53//fO/s4v+v/ZwKMwn3fb4xZ/q3A1DjrbXCdo36P2bg9/dP9e4n6fnbyMY/DHdVHz/sxbkcwG7dTFX3V0GG4o6OLkr3dSuh7muwAUulFnA0r8BDwz6jh43FXxpQCO3Abp8Ni5mnnfyxrfLlluMvQOtWy3sNwRxQlwEbgFj8+G3dp3A7cXtePSCwRXIHb+N0UJ66H/I9iO/A57hyB+B9nzdUpx+BOVnaJs+z5wPX+fW/cEchG/yN6HRgSU36wL1Ps1zkbl/S+doUJ7sqLD/3nsAN3dcnVUdM74k4kbvJlXoiaNsF/ztuAV9j3Eth9EoEfNxaXsL/0dX+OWhIBLrHeWsf3ZjgwE5e0PmPfSycvI+qKG6Af8LL/PLbhdhhqdiJO8p/PTj/tPXyyi/o+PODj3eHXNTbm83kRt6FcDVxaz+/6JbgkJnHKP+v/f9v9d7JrzPQT/P+rFPgUOMGPT/N13OanLcZt9CVm/oX4q5Bixh9QnX09NebV10+ruTR1F+4KsjNi5u2L+63vxp2jiN5JfBzXVFwa9ZofG39zedVkPmNqJSKjgD+r6qhkx2KMaXx2jsAk6vb9FzHGpCI7IjDGmJCzIwJjjAm5jGQHUF+dO3fWvn37NmjesrIycnISvWqzZbA6h4PVORwOpM4zZ87cqqpd4k1LuUTQt29fPv300wbNW1RURGFhYeMG1MxZncPB6hwOB1JnEVlV2zRrGjLGmJCzRGCMMSFnicAYY0LOEoExxoScJQJjjAm5wBKBiDzmn/M5r5bpIiL3i3te7xz/MBBjjDFNLMgjgidwHXfVZhwwyL/G4zo7M8YY08QCu49AVafGPAEq1jl89ZCJj0WkvYh0V9X6PL3LGGOSQlWpiijFpRWU7Kpg2ZZS0kSIqKIKEd99T0SVSMR1axpRBT8toqC4v4s27qBjm6z9rjNrRxWFAdQlmTeU9WTfp0Kt9eO+lghEZDzuqIH8/HyKiooatMLS0tIGz5uqrM7hYHWunaqyZbeyvVzZWBbxG2D2/nUb7ehxbkO+sUzJTIMqheoI7KxU5m6pJj3NzVMdQDdtsQ9+jnVqLw3k/5zMRBCvznE/WlV9GHgYoKCgQBt6Z53diRgOVudwePCfb9Otx0CqIkok4vbOI6pUR5QFG3bQOjOdGStLWFVcRllF9f4XWIuuea3ITE8jI13o1VHJbZVJ4eAuZKankZkmVEaUgzq2IS87gx7tW5OVkUaaAAhpAmkiiP8LkJbmxoufjkBWehrtEzgiCOr/nMxEsBb34JIavXAPgTDGhNTmHXuYvnIbeyojLNq4A4DpK0to1zqTquoIVdXKtl0VLN3sn5Q5Y3ady+vWNpv2bbIYd3gnThjUmR7tW9MxJ4vcVhl7N87uVbOB3nfjnZWexr5PGW2ZkpkIJgPXi8gk3CMBt9v5AWPCYU9lNR8vL+a9xVv4dGUJuyurv9q4x8jLziBNhEFdc8lIF7q3y6ZrXis66g7+c9woOuZkkZEupIuQniZkpKWRni7ktkq5rtSSJrBPSkSexT1surOIrMU92CQTQFUnAq/iHsq9FPcouGuCisUY07RKy6tYubWMPZXVLNy4k1XFZbyzcDOV1crqbbu+Vr5Xh9acNiSfXh1ac2j3thzdryPZmel0yW1FWlr8PfKioiKO6N0+6KqEQpBXDV2yn+kKXBfU+o0xwVu2pZSpi7cwY+U2iksr2LKznOVby2otf9zATozu34k9VdUM69WeEwd1ZkCX3Fo39qZp2LGTMeZrVHXvnnx5VYQtO8vZWlqBCCzbXEpldYT3Fm8hEnN5R4922Yw7rButs9IZ0r0tB+fnkZWRxoAuuXRok0lGunVm0BxZIjAmhCIRZWtpOeVVEbaWlvP+kq1sK6ugvCrC0s07mbGypNZ5W2ems7uympEHdSA9TbhuzECOH9iZdNurT1mWCIxpISIRZfnWMlZsLaO0vJKFG3eyYMNOqiMRPl6+jbzsDCIRpbJa2V0Z/3LKLnmtyEpPY0j3tozq15HjBnamX+ccWmWk0a5NJm2zM5u4VqYpWCIwJoWVV1Xzr8/W8ejHu7l6yqtxy7TOTGd0/04ADOyaS2a6kJmeRkVVhMHd8miVmU5edgaj+3ciOzO9KcM3zYQlAmNSyOYde/h8zZc89sEK5q3bvs+NUn06tuGbw3syvE97OuVk0a1tNh1yssi0dnmzH5YIjGnmFm/ayRPTVvLMJ6v3Gd8xJ4vvnNCfttkZ5O9exTdOH5OkCE2qs0RgTDNTc8XOfW8tYebqErbsLN877czDu3Hm4d05tHtbBnTJ3Tu+qGh1vEUZkxBLBMY0oV0VVSzZVMqeymqWbSlj0cYdVEWUN7/YRFl5FZXVSkV1ZJ95xg7txkWjelN4cJdQdHdgmp4lAmMCFIko//h0DUs2lzJl3kbWfbk7brmDOrVhSI+2HNq9revgLM11qTD2sG628TeBs0RgTAA+X13Crf+ax5ptuygtrwJcNwqj+3fiuIGdGN6nA1kZaRzUsQ1d8lrZxt4klSUCYxpIVSkuq2Duuu2sLdnNi5+vY1dFNQs27NhbJr9tK3502sFcOfogu3rHNFuWCIxJQFV1hA+XFTNjxTZemr2OzLS0WvvUOeWQrnRvn80ph+YzZnDXJo7UmPqzRGBMLSqqIrzw2VrumrKQkl2V+0xrm53BhQW9yExP4/Ce7Ti8Vzv6dc6hTZb9pEzqsW+tMTGmLd3KPW8s4rPVXwLQrnUmpw/J55BueZwzvCf9O+dYm75pUSwRmFBTVT5YupVJM9ZQXa28u2gz5VXu8s1WGWlcfWxffnL6YLIyrH3ftFyWCEwofba6hDtf+WLvXj9AXqsMDunelg5tMrnjG0Pp2zkniREa03QsEZjQWFuyi0feX8G0ZVtZvMk9FrFd60zOPLw7E07qz0GdbMNvwskSgWnxSsureHn2en7+wlwA0gS+Nbwn3yscwKD8vCRHZ0zyWSIwLU55lfL8zLW8NGsd7y/Zund8eprw50uGM+7w7kmMzpjmxxKBaTFUlcmz1/ODt3YBswF3wvfYAZ04dUg+ZwztRufcVskN0phmyBKBSWk791QybVkxL89ezytzNuwdf+uZh3DRUX1o19qeqGXM/lgiMClp++5Knpy2kj+8uXjvuDSBi0f1YVjWFi4+cUASozMmtVgiMCkjElFmri7h1698wZy12/eOv+HkgZxzZE8GdHE3ehUVFSUvSGNSkCUC0+xVR5S/frSSO17+Yu+4Nlnp/HzcIZw1rAcdc7KSF5wxLYAlAtMsLd28k7umLGLa0q37PJf36mP7ct6IXhzeq10SozOmZbFEYJoFVeXTVSV8sryYP72zdG83D22y0ik4qANjDunKxUf1ppNd9WNMo7NEYJJKVbn3rSXc9/aSfcYP7JrLT08fzNjDuiUpMmPCwxKBSZqpi7dwx+T5e/v1P21IPjeePIghPdqSnma9exrTVCwRmCa3p7Ka3766gCc/WgW4dv9fnHUoGfYEL2OSwhKBaVJ/eW8Zv31tIeC6fJg0/hiO6tsxyVEZE26WCEzgSsoquO6Zz/h4eTERdeNuOmMw3y8cYA94MaYZCDQRiMhY4D4gHXhEVX8XM70d8Degj4/lHlV9PMiYTNMpK6/ikfdX8Me3vrr799zhPfmvs4fYtf/GNCOBJQIRSQceAE4D1gIzRGSyqn4RVew64AtV/YaIdAEWicjTqloRVFymabw8ez23/HMOZRXViMDtZw/hqmP72hGAMc1QkEcEo4ClqrocQEQmAecA0YlAgTxxW4dcYBtQFWBMJkBLNu3kxVnreG/xFuat2wHAXecdzjlH9iQ7Mz3J0RljaiOqGsyCRc4HxqrqtX74CuBoVb0+qkweMBk4BMgDLlLVf8dZ1nhgPEB+fv7ISZMmNSim0tJScnNzGzRvqmqqOs/cVMWfPi/fO3xkl3QuOzSLLm2a/kog+z+Hg9W5fsaMGTNTVQviTQvyiCBeG0Bs1jkDmAWcDAwA3hSR91V1xz4zqT4MPAxQUFCghYWFDQqoqKiIhs6bqoKu85R5G/j1KwtY92U5InD/xcMZd1i3pF4Kav/ncLA6N54gE8FaoHfUcC9gfUyZa4DfqTssWSoiK3BHB9MDjMs0gu27Khn9u7fZ5fsBGtWvIxMvH2kngY1JQUEmghnAIBHpB6wDLgYujSmzGjgFeF9E8oHBwPIAYzIHKBJR7n9nCfe+5bqEOH5gZ/73wiPIb5ud5MiMMQ0VWCJQ1SoRuR54HXf56GOqOl9EJvjpE4FfA0+IyFxcU9LNqrq11oWapFm5tYwnpq3krx+votrfDHDLuEOYcJI9AMaYVBfofQSq+irwasy4iVHv1wOnBxmDOXBvfrGJ/3zq073DZwzN576Lh9uVQMa0EHZnsalTZXWEOybPB+Dpa4/m2AGd7F4AY1oYSwQmLlXl9fmb+K+X5rFlZzk/Oe1gjhvYOdlhGWMCYInA7GN18S5+8PfP+Xz1l3vHXXxUbyYU2rkAY1oqSwRmr0feX86d/14AQLvWmZw7vCcTThpAt3Z2RZAxLZklAkNxaTmn/3EqxWWui6ebzhjMdWMGJjkqY0xTsUQQcpGIctkjn1BcVkHb7Axe/cEJ9OrQJtlhGWOakCWCkLv7jUUs3LiTUw/tyiNXHZXscIwxSWCJIMSOv+sd1pbspnNuFhMvH5nscIwxSWKJIIQ2bt/DMb99e+/wv75/nD0v2JgQs0QQMu8t3sJVj7k+/TrnZlF00xhyW9nXwJgwS3gLICI5qloWZDAmOHPWfsmdryxg+sptANx48kB+fPrgJEdljGkO9psIRORY4BHcE8T6iMgRwHdV9ftBB2cO3PLt1fzmj++xeFMpAKP6duT2/xjC0B7tkhyZMaa5SOSI4I+4B8hMBlDV2SJyYqBRmQOmqlz52HTeX7IHcM1AD10+kqP6dkxyZMaY5iahpiFVXRPT0Vh1MOGYxrDuy91c8/h0Fm8qpVU6PHbN0dZPkDGmVokkgjW+eUhFJAu4EVgQbFimoaqqI1z0l49YW7KbMw/vxrndd1gSMMbUKZFrBicA1wE9cY+fPBKw8wPNUFV1hPMemsbakt388NRBPHjZSDLTrMtoY0zdEjkiGKyql0WPEJHjgA+DCck0xKriMq5/5nPmrtvO8QM788NTD052SMaYFJFIIvgTMCKBcSZJ7n1r8d5nCJ8xNN/uEjbG1EutiUBERgPHAl1E5MdRk9rinkFskmzF1jK+8+QMlm8pIzszjSevGcXR/TslOyxjTIqp64ggC3fvQAaQFzV+B3B+kEGZ/Zs8ez03Pvs5AKcNyeeBS0eQlWHdRBhj6q/WRKCq7wHvicgTqrqqCWMyddi+q5LbXpzLK3M2AHDPBUdw/sheSY7KGJPKEjlHsEtE7gaGAnsfVaWqJwcWlYnrgyVbufzRTwDolJPFI1cVMLxPhyRHZYxJdYkkgqeBvwNn4y4lvQrYEmRQ5us279zDd//6KQC/PmcoV4zum9yAjDEtRiKNyp1U9VGgUlXfU9VvA8cEHJeJEoko4+59n7KKau6/ZLglAWNMo0rkiKDS/90gImcB6wFrlG5Cs9Z+SXFZBd8rHMB/HNEj2eEYY1qYRBLBnSLSDvgJ7v6BtsAPA43K7FVaXsW3HpwGwJWjD0pyNMaYlmi/iUBVX/FvtwNjYO+dxSZgK7aW8a0H3Q3c3zm+H93btU5yRMaYlqiuG8rSgQtxfQxNUdV5InI2cCvQGhjeNCGG0/bdlVww8SNKdlVy65mHMP7EAckOyRjTQtV1RPAo0BuYDtwvIquA0cAtqvpiUwQXVnsqqzntD++xtbScR68q4JRD85MdkjGmBasrERQAw1Q1IiLZwFZgoKpubJrQwmnHnkqG3fEGAEf17WBJwBgTuLouH61Q1QiAqu4BFtc3CYjIWBFZJCJLReSWWsoUisgsEZkvIu/VZ/ktTVV1ZG+3EScf0pV/fHd0kiMyxoRBXUcEh4jIHP9egAF+WABV1WF1LdifY3gAOA33HIMZIjJZVb+IKtMeeBAYq6qrRaTrAdQlpa3ZtovT/ziV3ZXVXFjQi9+ff0SyQzLGhERdieDQA1z2KGCpqi4HEJFJwDnAF1FlLgVeUNXVAKq6+QDXmbL+941F7K6s5tvH9eMXZx3oR2+MMYkTVQ1mwSLn4/b0r/XDVwBHq+r1UWXuBTJx/RjlAfep6lNxljUeGA+Qn58/ctKkSQ2KqbS0lNzc3AbNG6RXllXw/JJKRuanc8Pw7P3PUA/Ntc5BsjqHg9W5fsaMGTNTVQviTUvo4fUNFO8ZibFZJwMYCZyCuyT1IxH5WFUX7zOT6sPAwwAFBQVaWFjYoICKiopo6LxBeXvBJp6f8im5rTJ4bMLJtGud2ajLb451DprVORyszo0nyESwFnf5aY1euO4pYstsVdUyoExEpgJHAIsJgZ+/MJdnp6+mTVY6b//kpEZPAsYYk4iEnmQiIq1FZHA9lz0DGCQi/UQkC7gYmBxT5iXgBBHJEJE2wNHAgnquJ+XUPGT+2emrOaRbHq/eeAL5bRu3ScgYYxK130QgIt8AZgFT/PCRIhK7Qf8aVa0Crgdex23c/6Gq80VkgohM8GUW+OXOwd249oiqzmtoZVLFVY9PZ+aqEtIEXr7hePp2zkl2SMaYEEukaegO3BVARQCqOktE+iaycFV9FXg1ZtzEmOG7gbsTWV5L8PspC/lwaTGZ6cKM204lM90eL2mMSa5EEkGVqm4XiXfu19THkk07ebBoGT3bt+adn55Eq4z0ZIdkjDEJnSOYJyKXAukiMkhE/gRMCziuFuez1SWc9sepADx0+QhLAsaYZiORRHAD7jr/cuAZXHfU9jyCenh34ea9zxT4/fnDGNarfZIjMsaYryTSNDRYVW8Dbgs6mJZoT2U1Nz0/G4CHLhvBuMO7JzkiY4zZVyJHBH8QkYUi8msRGRp4RC3Mn95ZwtbSCu654AhLAsaYZmm/iUBVxwCFwBbgYRGZKyK/CDqwlmDJpp088O4y+nfJ4bwRPZMdjjHGxJXQtYuqulFV7wcm4O4p+GWgUbUAqsq3n5wBwB8uPBK76soY01wlckPZoSJyh4jMA/6Mu2KoV+CRpTBVZcw9RazZtptLRvXmyN52ctgY03wlcrL4ceBZ4HRVje0ryMQoLa/igokfsbJ4F60z0/nNuYcnOyRjjKnTfhOBqh7TFIG0BJGI8u3HZ7Bgww5G9e3IE98+ypqEjDHNXq2JQET+oaoXishc9u0+OqEnlIXRX6YuZ/rKbYw7rBsPXT4y2eEYY0xC6joi+IH/e3ZTBJLq5q7dzl1TFgLw4GUjkhyNMcYkrtaTxaq6wb/9vqquin4B32+a8FLHox8sB+BX5wy15iBjTEpJ5PLR0+KMG9fYgaQyVWX22u307tiaK0f3TXY4xhhTL7UmAhH5nj8/MFhE5kS9VuCeH2C8B4uWsWJrGVcf2y/ZoRhjTL3VdY7gGeA14LfALQwXCGkAABQOSURBVFHjd6rqtkCjSiEzV23j7tcX0aNdNtcc2zfZ4RhjTL3VlQhUVVeKyHWxE0SkoyUD5963lgDwp0tHkJZm5waMMalnf0cEZwMzcZePRm/lFOgfYFwp4blP1/D+kq0M69WOkQd1SHY4xhjTILUmAlU92/+1hu84tpVVcNPz7lTJRLtnwBiTwhLpa+g4Ecnx7y8XkT+ISJ/gQ2vefvPqAvf33MPp0b51kqMxxpiGS+Ty0YeAXSJyBPAzYBXw10CjauZUlednriWvVQaXHh36nGiMSXGJJIIqVVXgHOA+Vb0PyAs2rObtZ75JaPyJoT9NYoxpARLpfXSniPwcuAI4QUTSgcxgw2q+dldU89zMtQB896QBSY7GGGMOXCJHBBfhHlz/bVXdCPQE7g40qmbs+c9cErjtzEPJykjouT7GGNOsJfKoyo3A00A7ETkb2KOqTwUeWTNUHVH+68V5ZKQJF4/qnexwjDGmUSRy1dCFwHTgAuBC4BMROT/owJqj7/1tJgDXnzyQvOzQto4ZY1qYRM4R3AYcpaqbAUSkC/AW8HyQgTU3s9d8yRtfbCK/bStuPHlQssMxxphGk0gjd1pNEvCKE5yvRfn96+5ZAxMvH2ldSRhjWpREjgimiMjruOcWgzt5/GpwITU/t780jw+XFnPJqN4M72NdSRhjWpZEnll8k4h8Czge19/Qw6r6r8AjayZ2V1Tz5EerAPjZGYckORpjjGl8dT2zeBBwDzAAmAv8VFXXNVVgzcWLs1yVrxszgA45WUmOxhhjGl9dbf2PAa8A5+F6IP1TfRcuImNFZJGILBWRW+ood5SIVDfHq5FembMegO8XDkxyJMYYE4y6mobyVPX//PtFIvJZfRbs70B+APeoy7XADBGZrKpfxCl3F/B6fZbfFJZtKeXDpcWM6NOenFaJnE4xxpjUU9fWLVtEhvPVcwhaRw+r6v4SwyhgqaouBxCRSbj+ir6IKXcD8E/gqHrGHriJRcsAuPObhyc5EmOMCY64/uTiTBB5t475VFVPrnPBrplnrKpe64evAI5W1eujyvTEPQDnZOBR4BVV/dr9CSIyHhgPkJ+fP3LSpEl1Vqo2paWl5ObmJlRWVbn+nV20yRDuPqlNg9bXHNSnzi2F1TkcrM71M2bMmJmqWhBvWl0PphnToLV9Jd7F9rFZ517gZlWtFqn92nxVfRh4GKCgoEALCwsbFFBRURGJzvvURyspq5zPj04/hMITUreX0frUuaWwOoeD1bnxBNnwvRaI7pCnF7A+pkwBMMkngc7AmSJSpaovBhjXflVVR7jrtYX075zD5ccclMxQjDEmcEEmghnAIBHpB6wDLgYujS4Q/RhMEXkC1zSU1CQA8MHSrZRVVPODUweRnZme7HCMMSZQgSUCVa0SketxVwOlA4+p6nwRmeCnTwxq3Qfq0Q9WANgD6Y0xobDfRCCu3eYyoL+q/so/r7ibqk7f37yq+iox3VHUlgBU9eqEIg5YdUT5dGUJfTq2oVeH1D1JbIwxiUqk87gHgdHAJX54J+7+gBbp9fkb2V1ZzXVj7OljxphwSKRp6GhVHSEinwOoaomItNi+Fh4sWgrA6UO6JTkSY4xpGokcEVT6u38V9j6PIBJoVEmycOMO5q3bwZDuba1fIWNMaCSSCO4H/gV0FZH/AT4AfhNoVEnyT/9Q+nsuOCLJkRhjTNNJpBvqp0VkJnAK7iaxb6rqgsAjS4J3Fm7miN7tGdKjbbJDMcaYJpPIM4v7ALuAl4HJQJkf16LMX7+dZVvKGN2/U7JDMcaYJpXIyeJ/484PCJAN9AMWAUMDjKvJ/WPGGgC+NaJnkiMxxpimlUjT0D5db4rICOC7gUWUJM/NXMvR/TpycH5eskMxxpgmVe+H0Pvup5tdl9EHYsmmneyqqObYAZ2THYoxxjS5RO4s/nHUYBowAtgSWERJMH3lNgBOObRrkiMxxpiml8g5gui2kircOYN/BhNOcqwu3kV6mnBod7tayBgTPnUmAn8jWa6q3tRE8STFe4u3MKBLDulptT8TwRhjWqpazxGISIaqVuOaglqsSERZuHEnHe1OYmNMSNV1RDAdlwRmichk4DmgrGaiqr4QcGxNYt767QCcemh+kiMxxpjkSOQcQUegGPdc4Zr7CRRoEYngrS82AVA4uEuSIzHGmOSoKxF09VcMzeOrBFAj/hPvU9DM1SV0zm3FgC7hegi2McbUqCsRpAO5JPYQ+pS0ZWc5Hy4t5srRB+Gfm2yMMaFTVyLYoKq/arJIkmD6Cnf/wBlD7dkDxpjwquvO4ha/i/zavA0AjOhjzyY2xoRXXYnglCaLIknWlOwmOzON1lnpyQ7FGGOSptZEoKrbmjKQphaJKMs2l3LucOtt1BgTbvXudK6lWFlcRml5FUN6tEt2KMYYk1ShTQSrt+0CoGteqyRHYowxyRXaRLByq7tJ+rCedkRgjAm30CaCKfM30jEnix7tspMdijHGJFVoE8H23VV0zWtlN5IZY0IvtImguLScI3q1T3YYxhiTdKFMBBVVEbaUltMp17qeNsaYUCaCxZt2ogp9OrZJdijGGJN0oUwEby/YDMDgbnn7KWmMMS1foIlARMaKyCIRWSoit8SZfpmIzPGvaSJyRJDx1FhZ7C4dPdwuHTXGmOASgX/e8QPAOGAIcImIDIkptgI4SVWHAb8GHg4qnmjrSnbTObcVGemhPCAyxph9BLklHAUsVdXlqloBTALOiS6gqtNUtcQPfgz0CjCemnWyaNNOjhvYKehVGWNMSkjkUZUN1RNYEzW8Fji6jvLfAV6LN0FExgPjAfLz8ykqKmpQQKWlpbz8RhHbd1eSVrqlwctJJaWlpaGoZzSrczhYnRtPkIkg4SebicgYXCI4Pt50VX0Y32xUUFCghYWFDQqoqKiI7D6Hw7sfc9LIoRSGoOfRoqIiGvp5pSqrczhYnRtPkIlgLdA7argXsD62kIgMAx4BxqlqcYDxADB18RYAjuxtN5MZYwwEe45gBjBIRPqJSBZwMTA5uoCI9AFeAK5Q1cUBxrLXxu17AOjbOacpVmeMMc1eYEcEqlolItcDrwPpwGOqOl9EJvjpE4FfAp2AB32fP1WqWhBUTAB7qqrJsquFjDFmryCbhlDVV4FXY8ZNjHp/LXBtkDHEKiuvZlB+blOu0hhjmrXQ7Rpv2VlOflvretoYY2qEKhGoKquKy+jR3hKBMcbUCFUiKClXyiqqGdjFmoaMMaZGqBLBpjJ3G0M/SwTGGLNXqBLBtj0RAHp1aJ3kSIwxpvkIVSLY4I8IOuXYA2mMMaZGqBJBVcQlgrzszCRHYowxzUeoEkHxHiUjTUhPswfWG2NMjVAlgnSB9m3saMAYY6KFKhGsK1W65Nk9BMYYEy1UiWBnhaIatydsY4wJrVAlgjSBDm3siiFjjIkWqkSwbY9ah3PGGBMjVIkAoLS8KtkhGGNMsxKaRFDt7yHo18keSGOMMdFCkwgqqlz3EpkZoamyMcYkJDRbxfKqagB7OpkxxsQIzVZxV4VLBGV2jsAYY/YRmkRQc46ge3vredQYY6KFJhFUVrtzBBnWz5AxxuwjNImg5oggI90SgTHGRAtNIqis9onAjgiMMWYfoUkEe/xVQxlpoamyMcYkJDRbxZr7CGoSgjHGGCc0iSBNXJNQ+9bW6ZwxxkQLTSKoOVlsLUPGGLOv0GwWa55DkC52stgYY6KFJhFUa80RgSUCY4yJFp5EUNM0ZEcExhizj9AkgponVKbbEYExxuwjNIngqyOCJAdijDHNTKCJQETGisgiEVkqIrfEmS4icr+fPkdERgQVy95zBNY0ZIwx+wgsEYhIOvAAMA4YAlwiIkNiio0DBvnXeOChoOJRSwTGGBNXkEcEo4ClqrpcVSuAScA5MWXOAZ5S52OgvYh0DyIY3/monSMwxpgYGQEuuyewJmp4LXB0AmV6AhuiC4nIeNwRA/n5+RQVFdU7mPUl1QzvpMyfNYMN2aE5NUJpaWmDPq9UZnUOB6tz4wkyEcTb9dYGlEFVHwYeBigoKNDCwsJ6B1MIDCoqoiHzprIiq3MoWJ3DIag6B7lrvBboHTXcC1jfgDLGGGMCFGQimAEMEpF+IpIFXAxMjikzGbjSXz10DLBdVTfELsgYY0xwAmsaUtUqEbkeeB1IBx5T1fkiMsFPnwi8CpwJLAV2AdcEFY8xxpj4gjxHgKq+itvYR4+bGPVegeuCjMEYY0zdwnP5jDHGmLgsERhjTMhZIjDGmJCzRGCMMSEnNX3wpAoR2QKsauDsnYGtjRhOKrA6h4PVORwOpM4HqWqXeBNSLhEcCBH5VFULkh1HU7I6h4PVORyCqrM1DRljTMhZIjDGmJALWyJ4ONkBJIHVORyszuEQSJ1DdY7AGGPM14XtiMAYY0wMSwTGGBNyLTIRiMhYEVkkIktF5JY400VE7vfT54jIiGTE2ZgSqPNlvq5zRGSaiByRjDgb0/7qHFXuKBGpFpHzmzK+ICRSZxEpFJFZIjJfRN5r6hgbWwLf7XYi8rKIzPZ1TulejEXkMRHZLCLzapne+NsvVW1RL1yX18uA/kAWMBsYElPmTOA13BPSjgE+SXbcTVDnY4EO/v24MNQ5qtw7uF5wz0923E3wf24PfAH08cNdkx13E9T5VuAu/74LsA3ISnbsB1DnE4ERwLxapjf69qslHhGMApaq6nJVrQAmAefElDkHeEqdj4H2ItK9qQNtRPuts6pOU9USP/gx7mlwqSyR/zPADcA/gc1NGVxAEqnzpcALqroaQFVTvd6J1FmBPBERIBeXCKqaNszGo6pTcXWoTaNvv1piIugJrIkaXuvH1bdMKqlvfb6D26NIZfuts4j0BM4FJtIyJPJ/PhjoICJFIjJTRK5ssuiCkUid/wwcinvM7VzgB6oaaZrwkqLRt1+BPpgmSSTOuNhrZBMpk0oSro+IjMElguMDjSh4idT5XuBmVa12O4spL5E6ZwAjgVOA1sBHIvKxqi4OOriAJFLnM4BZwMnAAOBNEXlfVXcEHVySNPr2qyUmgrVA76jhXrg9hfqWSSUJ1UdEhgGPAONUtbiJYgtKInUuACb5JNAZOFNEqlT1xaYJsdEl+t3eqqplQJmITAWOAFI1ESRS52uA36lrQF8qIiuAQ4DpTRNik2v07VdLbBqaAQwSkX4ikgVcDEyOKTMZuNKffT8G2K6qG5o60Ea03zqLSB/gBeCKFN47jLbfOqtqP1Xtq6p9geeB76dwEoDEvtsvASeISIaItAGOBhY0cZyNKZE6r8YdASEi+cBgYHmTRtm0Gn371eKOCFS1SkSuB17HXXHwmKrOF5EJfvpE3BUkZwJLgV24PYqUlWCdfwl0Ah70e8hVmsI9NyZY5xYlkTqr6gIRmQLMASLAI6oa9zLEVJDg//nXwBMiMhfXbHKzqqZs99Qi8ixQCHQWkbXA7UAmBLf9si4mjDEm5Fpi05Axxph6sERgjDEhZ4nAGGNCzhKBMcaEnCUCY4wJOUsEplnyvYXOinr1raNsaSOs7wkRWeHX9ZmIjG7AMh4RkSH+/a0x06YdaIx+OTWfyzzf42b7/ZQ/UkTObIx1m5bLLh81zZKIlKpqbmOXrWMZTwCvqOrzInI6cI+qDjuA5R1wTPtbrog8CSxW1f+po/zVQIGqXt/YsZiWw44ITEoQkVwRedvvrc8Vka/1NCoi3UVkatQe8wl+/Oki8pGf9zkR2d8Geiow0M/7Y7+seSLyQz8uR0T+7fu/nyciF/nxRSJSICK/A1r7OJ7200r9379H76H7I5HzRCRdRO4WkRni+pj/bgIfy0f4zsZEZJS450x87v8O9nfi/gq4yMdykY/9Mb+ez+N9jiaEkt33tr3sFe8FVOM6EpsF/At3F3xbP60z7q7KmiPaUv/3J8Bt/n06kOfLTgVy/PibgV/GWd8T+OcVABcAn+A6b5sL5OC6N54PDAfOA/4vat52/m8Rbu97b0xRZWpiPBd40r/PwvUi2RoYD/zCj28FfAr0ixNnaVT9ngPG+uG2QIZ/fyrwT//+auDPUfP/Brjcv2+P64MoJ9n/b3sl99XiupgwLcZuVT2yZkBEMoHfiMiJuK4TegL5wMaoeWYAj/myL6rqLBE5CRgCfOi71sjC7UnHc7eI/ALYguuh9RTgX+o6cENEXgBOAKYA94jIXbjmpPfrUa/XgPtFpBUwFpiqqrt9c9Qw+eopau2AQcCKmPlbi8gsoC8wE3gzqvyTIjII1xNlZi3rPx34DxH5qR/OBvqQ2v0RmQNkicCkistwT58aqaqVIrIStxHbS1Wn+kRxFvBXEbkbKAHeVNVLEljHTar6fM2AiJwar5CqLhaRkbj+Xn4rIm+o6q8SqYSq7hGRIlzXyRcBz9asDrhBVV/fzyJ2q+qRItIOeAW4Drgf19/Ou6p6rj+xXlTL/AKcp6qLEonXhIOdIzCpoh2w2SeBMcBBsQVE5CBf5v+AR3GP+/sYOE5Eatr824jIwQmucyrwTT9PDq5Z530R6QHsUtW/Aff49cSq9Ecm8UzCdRR2Aq4zNfzf79XMIyIH+3XGparbgRuBn/p52gHr/OSro4ruxDWR1XgduEH84ZGIDK9tHSY8LBGYVPE0UCAin+KODhbGKVMIzBKRz3Ht+Pep6hbchvFZEZmDSwyHJLJCVf0Md+5gOu6cwSOq+jlwODDdN9HcBtwZZ/aHgTk1J4tjvIF7Lu1b6h6/CO45EV8An4l7aPlf2M8Ru49lNq5r5t/jjk4+xJ0/qPEuMKTmZDHuyCHTxzbPD5uQs8tHjTEm5OyIwBhjQs4SgTHGhJwlAmOMCTlLBMYYE3KWCIwxJuQsERhjTMhZIjDGmJD7fxeIrUB27oYIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(train_y,pred_train_2)\n",
    "auc_score = roc_auc_score(train_y,pred_train_2)\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC curve/AUC Score : {auc_score}')\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.797084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.062920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.035643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.002280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.060592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18045</th>\n",
       "      <td>18045</td>\n",
       "      <td>0.011949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18046</th>\n",
       "      <td>18046</td>\n",
       "      <td>0.005162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18047</th>\n",
       "      <td>18047</td>\n",
       "      <td>0.095813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18048</th>\n",
       "      <td>18048</td>\n",
       "      <td>0.013155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18049</th>\n",
       "      <td>18049</td>\n",
       "      <td>0.096498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18050 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         y\n",
       "0          0  0.797084\n",
       "1          1  0.062920\n",
       "2          2  0.035643\n",
       "3          3  0.002280\n",
       "4          4  0.060592\n",
       "...      ...       ...\n",
       "18045  18045  0.011949\n",
       "18046  18046  0.005162\n",
       "18047  18047  0.095813\n",
       "18048  18048  0.013155\n",
       "18049  18049  0.096498\n",
       "\n",
       "[18050 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\test.csv')\n",
    "id = test['id']\n",
    "pred = pd.DataFrame(pred_test_2)\n",
    "submit = pd.concat([id,pred], axis=1)\n",
    "submit.columns = ['id', 'y']\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('stack5.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python37164bit745322e800af484d9e7663a15d4e0767"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
