{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso,Ridge\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers.advanced_activations import ReLU, PReLU\n",
    "from keras.optimizers import SGD, Adam\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\dataset\\\\train_x_xgboost.csv')\n",
    "train_y = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\dataset\\\\train_y_xgboost.csv')\n",
    "test_x = pd.read_csv('C:\\\\Users\\\\odoru\\\\SIGNATE_time_deposit_account\\\\dataset\\\\test_x_xgboost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_nn = pd.read_csv('.//dataset//train_x_NN.csv')\n",
    "train_y_nn = pd.read_csv('.//dataset//train_y_NN.csv')\n",
    "test_x_nn = pd.read_csv('.//dataset//test_x_NN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Model1xgb,Model1xgb2, Model1NNproba,Model1NN2proba,Model1ramdom,Model2KMeans,Model2KNN,Model3logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv_classfier(model,train_x, train_y, test_x):\n",
    "    \n",
    "\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state= 71)\n",
    "    for i , (tr_idx, va_idx) in enumerate (kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "\n",
    "    tmp = np.stack(preds_test, axis =1)\n",
    "    mode_test, mode_counts = mode(tmp, axis=1)\n",
    "\n",
    "    preds_test = mode_test\n",
    "    preds_size = preds_test.shape[0]\n",
    "    preds_test = preds_test.reshape(preds_size,)\n",
    "    \n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv(model, train_x, train_y, test_x):\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "    \n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "    for i , (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "        \n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "    \n",
    "    preds_test = np.mean(preds_test, axis=0)\n",
    "    \n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:271: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:271: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:271: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n",
      "C:\\Users\\odoru\\SIGNATE_time_deposit_account\\models.py:271: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self.model.fit(tr_x, tr_y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.2561\n",
      "logloss: 6.7286\n"
     ]
    }
   ],
   "source": [
    "model1_a = Model2KNN()\n",
    "pred_train_1a , preds_test_1a = predict_cv_classfier(model1_a, train_x, train_y, test_x)\n",
    "\n",
    "model1_b = Model2KMeans()\n",
    "pred_train_1b, preds_test_1b = predict_cv_classfier(model1_b, train_x, train_y, test_x)\n",
    "\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1a, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1b, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ",Model1NN2proba,Model1ramdom,Model2KMeans,Model2KNN,Model3logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:38:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06799\teval-error:0.07055\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06824\teval-error:0.07041\n",
      "[2]\ttrain-error:0.06760\teval-error:0.07070\n",
      "[3]\ttrain-error:0.06819\teval-error:0.07026\n",
      "[4]\ttrain-error:0.06716\teval-error:0.07011\n",
      "[5]\ttrain-error:0.06770\teval-error:0.06922\n",
      "[6]\ttrain-error:0.06731\teval-error:0.06937\n",
      "[7]\ttrain-error:0.06750\teval-error:0.06937\n",
      "[8]\ttrain-error:0.06741\teval-error:0.06967\n",
      "[9]\ttrain-error:0.06735\teval-error:0.06922\n",
      "[10]\ttrain-error:0.06701\teval-error:0.06864\n",
      "[11]\ttrain-error:0.06691\teval-error:0.06834\n",
      "[12]\ttrain-error:0.06677\teval-error:0.06804\n",
      "[13]\ttrain-error:0.06701\teval-error:0.06760\n",
      "[14]\ttrain-error:0.06696\teval-error:0.06731\n",
      "[15]\ttrain-error:0.06701\teval-error:0.06686\n",
      "[16]\ttrain-error:0.06657\teval-error:0.06672\n",
      "[17]\ttrain-error:0.06686\teval-error:0.06701\n",
      "[18]\ttrain-error:0.06677\teval-error:0.06657\n",
      "[19]\ttrain-error:0.06662\teval-error:0.06716\n",
      "[20]\ttrain-error:0.06657\teval-error:0.06657\n",
      "[21]\ttrain-error:0.06657\teval-error:0.06657\n",
      "[22]\ttrain-error:0.06637\teval-error:0.06642\n",
      "[23]\ttrain-error:0.06657\teval-error:0.06642\n",
      "[24]\ttrain-error:0.06632\teval-error:0.06657\n",
      "[25]\ttrain-error:0.06608\teval-error:0.06672\n",
      "[26]\ttrain-error:0.06613\teval-error:0.06686\n",
      "[27]\ttrain-error:0.06603\teval-error:0.06731\n",
      "[28]\ttrain-error:0.06583\teval-error:0.06701\n",
      "[29]\ttrain-error:0.06568\teval-error:0.06716\n",
      "[30]\ttrain-error:0.06573\teval-error:0.06672\n",
      "[31]\ttrain-error:0.06544\teval-error:0.06627\n",
      "[32]\ttrain-error:0.06534\teval-error:0.06598\n",
      "[33]\ttrain-error:0.06524\teval-error:0.06627\n",
      "[34]\ttrain-error:0.06504\teval-error:0.06627\n",
      "[35]\ttrain-error:0.06509\teval-error:0.06583\n",
      "[36]\ttrain-error:0.06475\teval-error:0.06598\n",
      "[37]\ttrain-error:0.06460\teval-error:0.06598\n",
      "[38]\ttrain-error:0.06455\teval-error:0.06539\n",
      "[39]\ttrain-error:0.06445\teval-error:0.06524\n",
      "[40]\ttrain-error:0.06426\teval-error:0.06524\n",
      "[41]\ttrain-error:0.06401\teval-error:0.06539\n",
      "[42]\ttrain-error:0.06386\teval-error:0.06509\n",
      "[43]\ttrain-error:0.06357\teval-error:0.06539\n",
      "[44]\ttrain-error:0.06312\teval-error:0.06524\n",
      "[45]\ttrain-error:0.06298\teval-error:0.06553\n",
      "[46]\ttrain-error:0.06308\teval-error:0.06568\n",
      "[47]\ttrain-error:0.06288\teval-error:0.06568\n",
      "[48]\ttrain-error:0.06273\teval-error:0.06568\n",
      "[49]\ttrain-error:0.06278\teval-error:0.06568\n",
      "[50]\ttrain-error:0.06258\teval-error:0.06568\n",
      "[51]\ttrain-error:0.06234\teval-error:0.06583\n",
      "[52]\ttrain-error:0.06180\teval-error:0.06568\n",
      "[53]\ttrain-error:0.06170\teval-error:0.06553\n",
      "[54]\ttrain-error:0.06150\teval-error:0.06568\n",
      "[55]\ttrain-error:0.06130\teval-error:0.06583\n",
      "[56]\ttrain-error:0.06125\teval-error:0.06539\n",
      "[57]\ttrain-error:0.06125\teval-error:0.06524\n",
      "[58]\ttrain-error:0.06135\teval-error:0.06524\n",
      "[59]\ttrain-error:0.06145\teval-error:0.06539\n",
      "[60]\ttrain-error:0.06091\teval-error:0.06495\n",
      "[61]\ttrain-error:0.06066\teval-error:0.06524\n",
      "[62]\ttrain-error:0.06052\teval-error:0.06524\n",
      "[63]\ttrain-error:0.06047\teval-error:0.06553\n",
      "[64]\ttrain-error:0.06052\teval-error:0.06568\n",
      "[65]\ttrain-error:0.06042\teval-error:0.06583\n",
      "[66]\ttrain-error:0.06022\teval-error:0.06539\n",
      "[67]\ttrain-error:0.06003\teval-error:0.06495\n",
      "[68]\ttrain-error:0.05988\teval-error:0.06509\n",
      "[69]\ttrain-error:0.06012\teval-error:0.06480\n",
      "[70]\ttrain-error:0.05998\teval-error:0.06509\n",
      "[71]\ttrain-error:0.05988\teval-error:0.06539\n",
      "[72]\ttrain-error:0.05963\teval-error:0.06539\n",
      "[73]\ttrain-error:0.05953\teval-error:0.06509\n",
      "[74]\ttrain-error:0.05924\teval-error:0.06524\n",
      "[75]\ttrain-error:0.05914\teval-error:0.06524\n",
      "[76]\ttrain-error:0.05914\teval-error:0.06539\n",
      "[77]\ttrain-error:0.05889\teval-error:0.06539\n",
      "[78]\ttrain-error:0.05880\teval-error:0.06539\n",
      "[79]\ttrain-error:0.05874\teval-error:0.06539\n",
      "[80]\ttrain-error:0.05840\teval-error:0.06583\n",
      "[81]\ttrain-error:0.05811\teval-error:0.06553\n",
      "[82]\ttrain-error:0.05806\teval-error:0.06553\n",
      "[83]\ttrain-error:0.05796\teval-error:0.06553\n",
      "[84]\ttrain-error:0.05781\teval-error:0.06568\n",
      "[85]\ttrain-error:0.05776\teval-error:0.06568\n",
      "[86]\ttrain-error:0.05761\teval-error:0.06568\n",
      "[87]\ttrain-error:0.05766\teval-error:0.06539\n",
      "[88]\ttrain-error:0.05737\teval-error:0.06553\n",
      "[89]\ttrain-error:0.05727\teval-error:0.06553\n",
      "Stopping. Best iteration:\n",
      "[69]\ttrain-error:0.06012\teval-error:0.06480\n",
      "\n",
      "[13:38:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06780\teval-error:0.07188\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06790\teval-error:0.07173\n",
      "[2]\ttrain-error:0.06785\teval-error:0.07114\n",
      "[3]\ttrain-error:0.06780\teval-error:0.07129\n",
      "[4]\ttrain-error:0.06775\teval-error:0.07114\n",
      "[5]\ttrain-error:0.06770\teval-error:0.07129\n",
      "[6]\ttrain-error:0.06750\teval-error:0.07070\n",
      "[7]\ttrain-error:0.06741\teval-error:0.07129\n",
      "[8]\ttrain-error:0.06735\teval-error:0.07114\n",
      "[9]\ttrain-error:0.06716\teval-error:0.07085\n",
      "[10]\ttrain-error:0.06691\teval-error:0.07114\n",
      "[11]\ttrain-error:0.06677\teval-error:0.07041\n",
      "[12]\ttrain-error:0.06647\teval-error:0.06982\n",
      "[13]\ttrain-error:0.06642\teval-error:0.06996\n",
      "[14]\ttrain-error:0.06617\teval-error:0.06996\n",
      "[15]\ttrain-error:0.06608\teval-error:0.06908\n",
      "[16]\ttrain-error:0.06627\teval-error:0.06922\n",
      "[17]\ttrain-error:0.06622\teval-error:0.06922\n",
      "[18]\ttrain-error:0.06603\teval-error:0.06922\n",
      "[19]\ttrain-error:0.06578\teval-error:0.06922\n",
      "[20]\ttrain-error:0.06598\teval-error:0.06952\n",
      "[21]\ttrain-error:0.06603\teval-error:0.06982\n",
      "[22]\ttrain-error:0.06593\teval-error:0.06967\n",
      "[23]\ttrain-error:0.06593\teval-error:0.06937\n",
      "[24]\ttrain-error:0.06583\teval-error:0.06952\n",
      "[25]\ttrain-error:0.06553\teval-error:0.06952\n",
      "[26]\ttrain-error:0.06568\teval-error:0.06952\n",
      "[27]\ttrain-error:0.06563\teval-error:0.06952\n",
      "[28]\ttrain-error:0.06544\teval-error:0.06967\n",
      "[29]\ttrain-error:0.06544\teval-error:0.06952\n",
      "[30]\ttrain-error:0.06544\teval-error:0.06952\n",
      "[31]\ttrain-error:0.06499\teval-error:0.06967\n",
      "[32]\ttrain-error:0.06480\teval-error:0.06982\n",
      "[33]\ttrain-error:0.06455\teval-error:0.06937\n",
      "[34]\ttrain-error:0.06470\teval-error:0.06937\n",
      "[35]\ttrain-error:0.06460\teval-error:0.06937\n",
      "Stopping. Best iteration:\n",
      "[15]\ttrain-error:0.06608\teval-error:0.06908\n",
      "\n",
      "[13:38:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06775\teval-error:0.07262\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06741\teval-error:0.07306\n",
      "[2]\ttrain-error:0.06745\teval-error:0.07306\n",
      "[3]\ttrain-error:0.06745\teval-error:0.07262\n",
      "[4]\ttrain-error:0.06735\teval-error:0.07203\n",
      "[5]\ttrain-error:0.06735\teval-error:0.07173\n",
      "[6]\ttrain-error:0.06711\teval-error:0.07188\n",
      "[7]\ttrain-error:0.06711\teval-error:0.07173\n",
      "[8]\ttrain-error:0.06711\teval-error:0.07129\n",
      "[9]\ttrain-error:0.06696\teval-error:0.07085\n",
      "[10]\ttrain-error:0.06667\teval-error:0.07085\n",
      "[11]\ttrain-error:0.06652\teval-error:0.07055\n",
      "[12]\ttrain-error:0.06657\teval-error:0.07085\n",
      "[13]\ttrain-error:0.06632\teval-error:0.07085\n",
      "[14]\ttrain-error:0.06627\teval-error:0.07085\n",
      "[15]\ttrain-error:0.06642\teval-error:0.07129\n",
      "[16]\ttrain-error:0.06647\teval-error:0.07114\n",
      "[17]\ttrain-error:0.06622\teval-error:0.07085\n",
      "[18]\ttrain-error:0.06622\teval-error:0.07114\n",
      "[19]\ttrain-error:0.06642\teval-error:0.07114\n",
      "[20]\ttrain-error:0.06642\teval-error:0.07100\n",
      "[21]\ttrain-error:0.06632\teval-error:0.07100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\ttrain-error:0.06622\teval-error:0.07100\n",
      "[23]\ttrain-error:0.06622\teval-error:0.07100\n",
      "[24]\ttrain-error:0.06632\teval-error:0.07055\n",
      "[25]\ttrain-error:0.06637\teval-error:0.07041\n",
      "[26]\ttrain-error:0.06627\teval-error:0.07070\n",
      "[27]\ttrain-error:0.06617\teval-error:0.07026\n",
      "[28]\ttrain-error:0.06632\teval-error:0.07055\n",
      "[29]\ttrain-error:0.06608\teval-error:0.07070\n",
      "[30]\ttrain-error:0.06593\teval-error:0.07055\n",
      "[31]\ttrain-error:0.06568\teval-error:0.07041\n",
      "[32]\ttrain-error:0.06553\teval-error:0.07085\n",
      "[33]\ttrain-error:0.06534\teval-error:0.07070\n",
      "[34]\ttrain-error:0.06519\teval-error:0.07026\n",
      "[35]\ttrain-error:0.06495\teval-error:0.07070\n",
      "[36]\ttrain-error:0.06499\teval-error:0.07100\n",
      "[37]\ttrain-error:0.06485\teval-error:0.07070\n",
      "[38]\ttrain-error:0.06460\teval-error:0.07085\n",
      "[39]\ttrain-error:0.06431\teval-error:0.07070\n",
      "[40]\ttrain-error:0.06406\teval-error:0.07100\n",
      "[41]\ttrain-error:0.06391\teval-error:0.07100\n",
      "[42]\ttrain-error:0.06376\teval-error:0.07085\n",
      "[43]\ttrain-error:0.06376\teval-error:0.07085\n",
      "[44]\ttrain-error:0.06342\teval-error:0.07041\n",
      "[45]\ttrain-error:0.06332\teval-error:0.07055\n",
      "[46]\ttrain-error:0.06327\teval-error:0.07055\n",
      "[47]\ttrain-error:0.06298\teval-error:0.07041\n",
      "Stopping. Best iteration:\n",
      "[27]\ttrain-error:0.06617\teval-error:0.07026\n",
      "\n",
      "[13:38:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.06686\teval-error:0.07572\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.06677\teval-error:0.07542\n",
      "[2]\ttrain-error:0.06642\teval-error:0.07439\n",
      "[3]\ttrain-error:0.06627\teval-error:0.07410\n",
      "[4]\ttrain-error:0.06667\teval-error:0.07439\n",
      "[5]\ttrain-error:0.06627\teval-error:0.07454\n",
      "[6]\ttrain-error:0.06642\teval-error:0.07498\n",
      "[7]\ttrain-error:0.06598\teval-error:0.07454\n",
      "[8]\ttrain-error:0.06608\teval-error:0.07454\n",
      "[9]\ttrain-error:0.06578\teval-error:0.07410\n",
      "[10]\ttrain-error:0.06539\teval-error:0.07424\n",
      "[11]\ttrain-error:0.06549\teval-error:0.07469\n",
      "[12]\ttrain-error:0.06544\teval-error:0.07454\n",
      "[13]\ttrain-error:0.06553\teval-error:0.07424\n",
      "[14]\ttrain-error:0.06558\teval-error:0.07410\n",
      "[15]\ttrain-error:0.06534\teval-error:0.07439\n",
      "[16]\ttrain-error:0.06509\teval-error:0.07424\n",
      "[17]\ttrain-error:0.06475\teval-error:0.07424\n",
      "[18]\ttrain-error:0.06480\teval-error:0.07439\n",
      "[19]\ttrain-error:0.06480\teval-error:0.07439\n",
      "[20]\ttrain-error:0.06480\teval-error:0.07439\n",
      "[21]\ttrain-error:0.06470\teval-error:0.07410\n",
      "[22]\ttrain-error:0.06450\teval-error:0.07380\n",
      "[23]\ttrain-error:0.06440\teval-error:0.07395\n",
      "[24]\ttrain-error:0.06435\teval-error:0.07410\n",
      "[25]\ttrain-error:0.06401\teval-error:0.07380\n",
      "[26]\ttrain-error:0.06416\teval-error:0.07424\n",
      "[27]\ttrain-error:0.06411\teval-error:0.07454\n",
      "[28]\ttrain-error:0.06396\teval-error:0.07424\n",
      "[29]\ttrain-error:0.06362\teval-error:0.07424\n",
      "[30]\ttrain-error:0.06366\teval-error:0.07454\n",
      "[31]\ttrain-error:0.06337\teval-error:0.07380\n",
      "[32]\ttrain-error:0.06322\teval-error:0.07380\n",
      "[33]\ttrain-error:0.06308\teval-error:0.07365\n",
      "[34]\ttrain-error:0.06312\teval-error:0.07336\n",
      "[35]\ttrain-error:0.06312\teval-error:0.07336\n",
      "[36]\ttrain-error:0.06308\teval-error:0.07321\n",
      "[37]\ttrain-error:0.06303\teval-error:0.07336\n",
      "[38]\ttrain-error:0.06278\teval-error:0.07306\n",
      "[39]\ttrain-error:0.06229\teval-error:0.07336\n",
      "[40]\ttrain-error:0.06229\teval-error:0.07336\n",
      "[41]\ttrain-error:0.06209\teval-error:0.07351\n",
      "[42]\ttrain-error:0.06189\teval-error:0.07321\n",
      "[43]\ttrain-error:0.06150\teval-error:0.07336\n",
      "[44]\ttrain-error:0.06125\teval-error:0.07306\n",
      "[45]\ttrain-error:0.06111\teval-error:0.07306\n",
      "[46]\ttrain-error:0.06125\teval-error:0.07321\n",
      "[47]\ttrain-error:0.06111\teval-error:0.07336\n",
      "[48]\ttrain-error:0.06086\teval-error:0.07380\n",
      "[49]\ttrain-error:0.06076\teval-error:0.07351\n",
      "[50]\ttrain-error:0.06066\teval-error:0.07306\n",
      "[51]\ttrain-error:0.06052\teval-error:0.07291\n",
      "[52]\ttrain-error:0.06042\teval-error:0.07277\n",
      "[53]\ttrain-error:0.06042\teval-error:0.07321\n",
      "[54]\ttrain-error:0.06032\teval-error:0.07306\n",
      "[55]\ttrain-error:0.05988\teval-error:0.07306\n",
      "[56]\ttrain-error:0.05988\teval-error:0.07321\n",
      "[57]\ttrain-error:0.05988\teval-error:0.07321\n",
      "[58]\ttrain-error:0.05968\teval-error:0.07306\n",
      "[59]\ttrain-error:0.05958\teval-error:0.07306\n",
      "[60]\ttrain-error:0.05943\teval-error:0.07306\n",
      "[61]\ttrain-error:0.05904\teval-error:0.07291\n",
      "[62]\ttrain-error:0.05899\teval-error:0.07277\n",
      "[63]\ttrain-error:0.05889\teval-error:0.07262\n",
      "[64]\ttrain-error:0.05870\teval-error:0.07262\n",
      "[65]\ttrain-error:0.05820\teval-error:0.07247\n",
      "[66]\ttrain-error:0.05825\teval-error:0.07247\n",
      "[67]\ttrain-error:0.05815\teval-error:0.07262\n",
      "[68]\ttrain-error:0.05815\teval-error:0.07247\n",
      "[69]\ttrain-error:0.05786\teval-error:0.07233\n",
      "[70]\ttrain-error:0.05756\teval-error:0.07218\n",
      "[71]\ttrain-error:0.05751\teval-error:0.07233\n",
      "[72]\ttrain-error:0.05756\teval-error:0.07218\n",
      "[73]\ttrain-error:0.05737\teval-error:0.07203\n",
      "[74]\ttrain-error:0.05737\teval-error:0.07203\n",
      "[75]\ttrain-error:0.05717\teval-error:0.07188\n",
      "[76]\ttrain-error:0.05717\teval-error:0.07188\n",
      "[77]\ttrain-error:0.05678\teval-error:0.07218\n",
      "[78]\ttrain-error:0.05658\teval-error:0.07218\n",
      "[79]\ttrain-error:0.05653\teval-error:0.07218\n",
      "[80]\ttrain-error:0.05648\teval-error:0.07218\n",
      "[81]\ttrain-error:0.05599\teval-error:0.07233\n",
      "[82]\ttrain-error:0.05584\teval-error:0.07233\n",
      "[83]\ttrain-error:0.05579\teval-error:0.07247\n",
      "[84]\ttrain-error:0.05570\teval-error:0.07262\n",
      "[85]\ttrain-error:0.05560\teval-error:0.07247\n",
      "[86]\ttrain-error:0.05555\teval-error:0.07247\n",
      "[87]\ttrain-error:0.05530\teval-error:0.07203\n",
      "[88]\ttrain-error:0.05535\teval-error:0.07233\n",
      "[89]\ttrain-error:0.05525\teval-error:0.07218\n",
      "[90]\ttrain-error:0.05520\teval-error:0.07203\n",
      "[91]\ttrain-error:0.05530\teval-error:0.07218\n",
      "[92]\ttrain-error:0.05515\teval-error:0.07233\n",
      "[93]\ttrain-error:0.05505\teval-error:0.07188\n",
      "[94]\ttrain-error:0.05501\teval-error:0.07188\n",
      "[95]\ttrain-error:0.05505\teval-error:0.07188\n",
      "Stopping. Best iteration:\n",
      "[75]\ttrain-error:0.05717\teval-error:0.07188\n",
      "\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2403 - accuracy: 0.9254 - val_loss: 0.2074 - val_accuracy: 0.9333\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2152 - accuracy: 0.9302 - val_loss: 0.2053 - val_accuracy: 0.9339\n",
      "Epoch 3/100\n",
      "128/159 [=======================>......] - ETA: 0s - loss: 0.2054 - accuracy: 0.9323"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-58ed7202ff08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel1NNproba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpred_train_1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_test_1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_x_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_x_nn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-64fbb2dbc47d>\u001b[0m in \u001b[0;36mpredict_cv\u001b[1;34m(model, train_x, train_y, test_x)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mtr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mva_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mva_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtr_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mva_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mva_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mva_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mva_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mva_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\SIGNATE_time_deposit_account\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, tr_x, tr_y, va_x, va_y)\u001b[0m\n\u001b[0;32m    111\u001b[0m     history = model.fit(tr_x,tr_y,\n\u001b[0;32m    112\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mva_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mva_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     callbacks=[early_stopping])\n\u001b[0m\u001b[0;32m    114\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_1c = Model1xgb()\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_1c, train_x, train_y, test_x)\n",
    "\n",
    "model_1d = Model1NNproba()\n",
    "pred_train_1d, pred_test_1d = predict_cv(model_1d, train_x_nn, train_y, test_x_nn)\n",
    "\n",
    "\n",
    "model_1e = Model1ramdom()\n",
    "pred_train_1e, pred_test_1e = predict_cv(model_1e, train_x, train_y, test_x)\n",
    "\n",
    "\n",
    "model_1f = Model1xgb2()\n",
    "pred_train_1f, pred_test_1f = predict_cv(model_1f, train_x, train_y, test_x)\n",
    "\n",
    "model_1g = Model1NN2proba()\n",
    "pred_train_1g, pred_test_1g = predict_cv(model_1e, train_x_nn, train_y, test_x_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2447 - accuracy: 0.9237 - val_loss: 0.2122 - val_accuracy: 0.9315\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2158 - accuracy: 0.9292 - val_loss: 0.2097 - val_accuracy: 0.9330\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.9298 - val_loss: 0.2125 - val_accuracy: 0.9315\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9309 - val_loss: 0.2097 - val_accuracy: 0.9323\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9320 - val_loss: 0.2077 - val_accuracy: 0.9317\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9319 - val_loss: 0.2083 - val_accuracy: 0.9327\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2000 - accuracy: 0.9330 - val_loss: 0.2085 - val_accuracy: 0.9334\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.1986 - accuracy: 0.9334 - val_loss: 0.2086 - val_accuracy: 0.9334\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1968 - accuracy: 0.9331 - val_loss: 0.2082 - val_accuracy: 0.9331\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1947 - accuracy: 0.9341 - val_loss: 0.2098 - val_accuracy: 0.9331\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1929 - accuracy: 0.9336 - val_loss: 0.2099 - val_accuracy: 0.9331\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1915 - accuracy: 0.9346 - val_loss: 0.2103 - val_accuracy: 0.9336\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.1879 - accuracy: 0.9352 - val_loss: 0.2155 - val_accuracy: 0.9342\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1851 - accuracy: 0.9363 - val_loss: 0.2190 - val_accuracy: 0.9293\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1834 - accuracy: 0.9374 - val_loss: 0.2156 - val_accuracy: 0.9334\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1817 - accuracy: 0.9378 - val_loss: 0.2156 - val_accuracy: 0.9324\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1794 - accuracy: 0.9374 - val_loss: 0.2163 - val_accuracy: 0.9333\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1766 - accuracy: 0.9377 - val_loss: 0.2177 - val_accuracy: 0.9311\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1737 - accuracy: 0.9398 - val_loss: 0.2207 - val_accuracy: 0.9325\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1727 - accuracy: 0.9394 - val_loss: 0.2211 - val_accuracy: 0.9305\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1689 - accuracy: 0.9415 - val_loss: 0.2257 - val_accuracy: 0.9318\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1683 - accuracy: 0.9407 - val_loss: 0.2229 - val_accuracy: 0.9297\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1643 - accuracy: 0.9415 - val_loss: 0.2256 - val_accuracy: 0.9318\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1627 - accuracy: 0.9415 - val_loss: 0.2247 - val_accuracy: 0.9306\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1605 - accuracy: 0.9440 - val_loss: 0.2285 - val_accuracy: 0.9290\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2425 - accuracy: 0.9231 - val_loss: 0.2171 - val_accuracy: 0.9300\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2128 - accuracy: 0.9299 - val_loss: 0.2140 - val_accuracy: 0.9306\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2089 - accuracy: 0.9311 - val_loss: 0.2131 - val_accuracy: 0.9297\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2055 - accuracy: 0.9323 - val_loss: 0.2153 - val_accuracy: 0.9305\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9327 - val_loss: 0.2165 - val_accuracy: 0.9299\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2004 - accuracy: 0.9330 - val_loss: 0.2178 - val_accuracy: 0.9297\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.1985 - accuracy: 0.9339 - val_loss: 0.2154 - val_accuracy: 0.9297\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.1970 - accuracy: 0.9328 - val_loss: 0.2144 - val_accuracy: 0.9300\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.1942 - accuracy: 0.9340 - val_loss: 0.2177 - val_accuracy: 0.9300\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1920 - accuracy: 0.9351 - val_loss: 0.2184 - val_accuracy: 0.9284\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1906 - accuracy: 0.9354 - val_loss: 0.2201 - val_accuracy: 0.9292\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1892 - accuracy: 0.9354 - val_loss: 0.2185 - val_accuracy: 0.9290\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1858 - accuracy: 0.9368 - val_loss: 0.2231 - val_accuracy: 0.9296\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.1837 - accuracy: 0.9378 - val_loss: 0.2222 - val_accuracy: 0.9287\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1815 - accuracy: 0.9374 - val_loss: 0.2248 - val_accuracy: 0.9275\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1781 - accuracy: 0.9383 - val_loss: 0.2244 - val_accuracy: 0.9280\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.1759 - accuracy: 0.9394 - val_loss: 0.2274 - val_accuracy: 0.9278\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.1758 - accuracy: 0.9388 - val_loss: 0.2274 - val_accuracy: 0.9272\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1723 - accuracy: 0.9391 - val_loss: 0.2322 - val_accuracy: 0.9253\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1702 - accuracy: 0.9414 - val_loss: 0.2299 - val_accuracy: 0.9280\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1686 - accuracy: 0.9417 - val_loss: 0.2302 - val_accuracy: 0.9274\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1648 - accuracy: 0.9424 - val_loss: 0.2375 - val_accuracy: 0.9265\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.1608 - accuracy: 0.9435 - val_loss: 0.2374 - val_accuracy: 0.9259\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2442 - accuracy: 0.9226 - val_loss: 0.2155 - val_accuracy: 0.9297\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2123 - accuracy: 0.9298 - val_loss: 0.2159 - val_accuracy: 0.9299\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9308 - val_loss: 0.2164 - val_accuracy: 0.9299\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9323 - val_loss: 0.2171 - val_accuracy: 0.9315\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2022 - accuracy: 0.9320 - val_loss: 0.2169 - val_accuracy: 0.9314\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 8ms/step - loss: 0.2006 - accuracy: 0.9328 - val_loss: 0.2166 - val_accuracy: 0.9303\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.1982 - accuracy: 0.9325 - val_loss: 0.2200 - val_accuracy: 0.9300\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1949 - accuracy: 0.9342 - val_loss: 0.2212 - val_accuracy: 0.9311\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1937 - accuracy: 0.9342 - val_loss: 0.2206 - val_accuracy: 0.9300\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1918 - accuracy: 0.9354 - val_loss: 0.2223 - val_accuracy: 0.9305\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1899 - accuracy: 0.9360 - val_loss: 0.2253 - val_accuracy: 0.9294\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1887 - accuracy: 0.9362 - val_loss: 0.2216 - val_accuracy: 0.9283\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1859 - accuracy: 0.9366 - val_loss: 0.2244 - val_accuracy: 0.9293\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1823 - accuracy: 0.9377 - val_loss: 0.2237 - val_accuracy: 0.9294\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1819 - accuracy: 0.9383 - val_loss: 0.2272 - val_accuracy: 0.9287\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1799 - accuracy: 0.9391 - val_loss: 0.2272 - val_accuracy: 0.9286\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1766 - accuracy: 0.9384 - val_loss: 0.2307 - val_accuracy: 0.9290\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1730 - accuracy: 0.9402 - val_loss: 0.2317 - val_accuracy: 0.9275\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1708 - accuracy: 0.9418 - val_loss: 0.2324 - val_accuracy: 0.9297\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1705 - accuracy: 0.9401 - val_loss: 0.2361 - val_accuracy: 0.9296\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1670 - accuracy: 0.9424 - val_loss: 0.2390 - val_accuracy: 0.9287\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2347 - accuracy: 0.9284 - val_loss: 0.2155 - val_accuracy: 0.9271\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2113 - accuracy: 0.9324 - val_loss: 0.2149 - val_accuracy: 0.9263\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9323 - val_loss: 0.2147 - val_accuracy: 0.9278\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9328 - val_loss: 0.2142 - val_accuracy: 0.9259\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.9343 - val_loss: 0.2146 - val_accuracy: 0.9274\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2007 - accuracy: 0.9336 - val_loss: 0.2219 - val_accuracy: 0.9262\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1963 - accuracy: 0.9343 - val_loss: 0.2201 - val_accuracy: 0.9272\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1945 - accuracy: 0.9355 - val_loss: 0.2200 - val_accuracy: 0.9266\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1925 - accuracy: 0.9360 - val_loss: 0.2199 - val_accuracy: 0.9253\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1905 - accuracy: 0.9357 - val_loss: 0.2180 - val_accuracy: 0.9262\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1877 - accuracy: 0.9370 - val_loss: 0.2289 - val_accuracy: 0.9256\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1850 - accuracy: 0.9378 - val_loss: 0.2230 - val_accuracy: 0.9247\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1845 - accuracy: 0.9379 - val_loss: 0.2244 - val_accuracy: 0.9234\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1825 - accuracy: 0.9381 - val_loss: 0.2254 - val_accuracy: 0.9256\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1811 - accuracy: 0.9382 - val_loss: 0.2294 - val_accuracy: 0.9228\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1754 - accuracy: 0.9404 - val_loss: 0.2328 - val_accuracy: 0.9234\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1742 - accuracy: 0.9394 - val_loss: 0.2298 - val_accuracy: 0.9232\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1719 - accuracy: 0.9415 - val_loss: 0.2332 - val_accuracy: 0.9231\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1683 - accuracy: 0.9417 - val_loss: 0.2392 - val_accuracy: 0.9204\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1665 - accuracy: 0.9426 - val_loss: 0.2356 - val_accuracy: 0.9230\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1653 - accuracy: 0.9431 - val_loss: 0.2376 - val_accuracy: 0.9247\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1622 - accuracy: 0.9437 - val_loss: 0.2417 - val_accuracy: 0.9235\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1601 - accuracy: 0.9448 - val_loss: 0.2456 - val_accuracy: 0.9210\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.1561 - accuracy: 0.9459 - val_loss: 0.2450 - val_accuracy: 0.9201\n",
      "logloss: 1.2561\n"
     ]
    }
   ],
   "source": [
    "model_1d = Model1NNproba()\n",
    "pred_train_1d, pred_test_1d = predict_cv(model_1d, train_x_nn, train_y, test_x_nn)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1d, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.2068\n",
      "logloss: 1.2561\n",
      "logloss: 0.2492\n",
      "logloss: 0.2129\n",
      "logloss: 0.2545\n"
     ]
    }
   ],
   "source": [
    "print(f'logloss: {log_loss(train_y, pred_train_1c, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1d, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1e, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1f, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1g, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_test_1a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-a12765f4f5e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_x_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'pred_1a'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpred_train_1a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pred_1b'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpred_train_1b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pred_1c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpred_train_1c\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'pred_1d'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpred_train_1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pred_1e'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpred_train_1e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pred_1f'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpred_train_1f\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'pred_1g'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpred_train_1g\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_x_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'pred_1a'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpred_test_1a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pred_1b'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpred_test_1b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pred_1c'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpred_test_1c\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'pred_1d'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpred_test_1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pred_1e'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpred_test_1e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pred_1f'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpred_test_1f\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'pred_1g'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpred_test_1g\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pred_test_1a' is not defined"
     ]
    }
   ],
   "source": [
    "train_x_2 = pd.DataFrame({'pred_1a': pred_train_1a, 'pred_1b': pred_train_1b, 'pred_1c':pred_train_1c,'pred_1d':pred_train_1d, 'pred_1e':pred_train_1e, 'pred_1f': pred_train_1f,'pred_1g':pred_train_1g})\n",
    "test_x_2 = pd.DataFrame({'pred_1a': pred_test_1a, 'pred_1b': pred_test_1b, 'pred_1c': pred_test_1c,'pred_1d':pred_test_1d, 'pred_1e':pred_test_1e, 'pred_1f': pred_test_1f,'pred_1g':pred_test_1g})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python37164bit745322e800af484d9e7663a15d4e0767"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
